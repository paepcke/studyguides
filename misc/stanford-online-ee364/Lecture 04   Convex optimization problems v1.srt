1
00:00:00,320 --> 00:00:03,492
In this section we're going to talk about
convex optimization problems and

2
00:00:03,492 --> 00:00:05,230
we'll start in detail.

3
00:00:05,230 --> 00:00:08,596
We'll start by talking about what's an
optimization problem, we'll talk about

4
00:00:08,596 --> 00:00:13,520
what are the parts in an optimization
problem, how do you define one.

5
00:00:13,520 --> 00:00:16,370
We'll get quickly to what's a convex
optimization problem?

6
00:00:17,770 --> 00:00:21,320
We'll talk about quasi-convex
optimization, and then, for

7
00:00:21,320 --> 00:00:24,302
a while where going to look at just common
families of

8
00:00:24,302 --> 00:00:30,560
optimization problems linear programming,
quadratic programming.

9
00:00:30,560 --> 00:00:32,235
Something called geometric programming.

10
00:00:32,235 --> 00:00:35,035
Then we'll look at generalized inequality
constraints and

11
00:00:35,035 --> 00:00:38,550
the most famous of these is semidefinite
programming.

12
00:00:38,550 --> 00:00:41,660
And finally, we'll look at the idea of
vector optimization.

13
00:00:41,660 --> 00:00:45,216
That's when your objective function is
actually a vector and not a scalar.

14
00:00:45,216 --> 00:00:46,426
Okay?

15
00:00:46,426 --> 00:00:50,370
So, let's start.

16
00:00:50,370 --> 00:00:51,430
What's an optimization problem?

17
00:00:52,490 --> 00:00:55,620
Well, an optimization problem is
something.

18
00:00:55,620 --> 00:00:58,120
It's described and written this way.

19
00:00:58,120 --> 00:01:00,325
It says minimize.

20
00:01:00,325 --> 00:01:03,715
F0 of x, that is the objective function.

21
00:01:03,715 --> 00:01:07,319
X is a vector in rn, that's called the
optimization variable, or

22
00:01:07,319 --> 00:01:13,071
another name for it, which is a great
name, is the decision variable.

23
00:01:13,071 --> 00:01:17,420
That's wonderful because it kind of tells
you that's what you have to decide.

24
00:01:18,960 --> 00:01:23,740
So f0 of x is the objective, here, you're
being told minimize.

25
00:01:23,740 --> 00:01:29,845
What that means, of course, is this these
smaller F0 of X is, the happier you are.

26
00:01:29,845 --> 00:01:33,080
It, it is, that defines what it means to
be better.

27
00:01:34,340 --> 00:01:35,540
And then, there are constraints.

28
00:01:35,540 --> 00:01:38,540
This says subject to, and you have
inequality constraints,

29
00:01:38,540 --> 00:01:43,282
these are of the form FI of X is less than
0, and there's M of these.

30
00:01:43,282 --> 00:01:45,974
And there are equality constraints.

31
00:01:45,974 --> 00:01:51,116
Also subject to h i of x is less, is equal
to 0, and there are p of these.

32
00:01:51,116 --> 00:01:54,507
So here, f0 is the objective or cost
function.

33
00:01:54,507 --> 00:01:56,283
F i these are the inqualties,

34
00:01:56,283 --> 00:02:00,692
these are called the inequality constraint
functions.

35
00:02:02,000 --> 00:02:04,230
And hi are equality constraint functions.

36
00:02:04,230 --> 00:02:05,305
And, although we'll see many,

37
00:02:05,305 --> 00:02:09,142
many examples I can say a little bit about
where some of these things come up.

38
00:02:09,142 --> 00:02:12,796
Usually f0 is an objective, or a cost, and
in any case it's something that you

39
00:02:12,796 --> 00:02:18,110
want to make small, and you're happier the
smaller it is.

40
00:02:18,110 --> 00:02:20,385
The inequality constraint functions f1,

41
00:02:20,385 --> 00:02:25,010
often these will have to do with something
like a resource limit.

42
00:02:25,010 --> 00:02:28,026
And so, this will tell you something about
a resource limit, or

43
00:02:28,026 --> 00:02:33,200
really how much under the resource limit
you are, the, the the capacity.

44
00:02:33,200 --> 00:02:36,266
And what this is usually has the
interpretation of

45
00:02:36,266 --> 00:02:39,210
don't violate a resource limit.

46
00:02:39,210 --> 00:02:42,785
hi of x, equality constraints tend to be,
again we'll see tons of examples, but

47
00:02:42,785 --> 00:02:48,080
these might arise in things like balance,
that one thing has to balance another.

48
00:02:48,080 --> 00:02:51,785
For example, a market has to clear, that
means that the total amount sold has to

49
00:02:51,785 --> 00:02:55,170
match the total amount that's being
bought.

50
00:02:55,170 --> 00:02:56,470
Something like that.

51
00:02:56,470 --> 00:02:59,888
Right, so that's where you would get
these, and we'll see lots of examples.

52
00:02:59,888 --> 00:03:02,220
oh, I should mention one thing.

53
00:03:02,220 --> 00:03:05,500
That is, that you can also maximize a
function in

54
00:03:05,500 --> 00:03:09,850
which case it's not called a cost
function.

55
00:03:09,850 --> 00:03:11,467
If you maximize an objective function,

56
00:03:11,467 --> 00:03:14,200
the objective function is often called a
utility.

57
00:03:14,200 --> 00:03:15,434
That's one name for it.

58
00:03:15,434 --> 00:03:17,930
But it can also be something much more
specific like profit, or

59
00:03:17,930 --> 00:03:19,034
something like that, or, or

60
00:03:19,034 --> 00:03:23,430
some other quantity that's obviously good
depending on the application.

61
00:03:23,430 --> 00:03:29,766
Right, and entire fields, we'll use
preferentially either minimizing

62
00:03:29,766 --> 00:03:38,140
a cost or, maximizing a a utility or
profit or something like that.

63
00:03:38,140 --> 00:03:41,590
Right, so and you can joke about what that
means about the people in those fields and

64
00:03:41,590 --> 00:03:45,820
like, you know, what their psychological
makeup is, or something.

65
00:03:45,820 --> 00:03:49,720
It's not a big deal, because if you wanted
to maximize a utility,we could then,

66
00:03:49,720 --> 00:03:52,720
we could minimize negative utility.

67
00:03:52,720 --> 00:03:56,390
And it's useful to have a standard, our
standard will be minimized.

68
00:03:56,390 --> 00:03:58,550
Because will have a lot of equations that
later involved,

69
00:03:58,550 --> 00:04:00,215
constructs that involve a minimization and

70
00:04:00,215 --> 00:04:02,735
you have to turn them around in your head
when you're maximizing and

71
00:04:02,735 --> 00:04:08,008
then you get a headache, so it's easier
just to have a fixed clear version of it.

72
00:04:08,008 --> 00:04:11,826
Okay, now the set of x, for which f i of x
is less than or

73
00:04:11,826 --> 00:04:16,450
equal to zero for all of them.

74
00:04:16,450 --> 00:04:19,844
And for which h i of x, is equal to zero
for all of them.

75
00:04:19,844 --> 00:04:21,460
Such points are called feasible.

76
00:04:21,460 --> 00:04:23,040
That's called feasible set.

77
00:04:23,040 --> 00:04:26,628
And among the, on the feasible set you
evaluate the objective,

78
00:04:26,628 --> 00:04:29,670
this is a set of numbers, right?

79
00:04:29,670 --> 00:04:33,926
It's the, it's the objective values for
all x which are feasible and

80
00:04:33,926 --> 00:04:39,810
the infimum of that in set of numbers,
that's like the minimum.

81
00:04:39,810 --> 00:04:43,822
That's called p star and that's the
optimal value of this minimization

82
00:04:43,822 --> 00:04:49,766
problem, Oh, so for people who haven't
seen it, you can read inf as min.

83
00:04:49,766 --> 00:04:52,358
Min is a completely standard function, and

84
00:04:52,358 --> 00:04:57,610
it means only one thing, it has no other
meaning in mathematics.

85
00:04:57,610 --> 00:04:59,194
That meaning is this,

86
00:04:59,194 --> 00:05:04,750
it takes as argument, a finite set of real
numbers, period.

87
00:05:05,940 --> 00:05:09,120
And it returns the smallest of them,
period.

88
00:05:09,120 --> 00:05:11,902
There's no other definition of min.

89
00:05:11,902 --> 00:05:16,390
Inf is in fact something like min
generalized to infinite sets.

90
00:05:16,390 --> 00:05:19,970
It's something like the, its the greatest
lower bound people say.

91
00:05:19,970 --> 00:05:23,623
Its the largest number that's smaller than
all of the other numbers in the set.

92
00:05:23,623 --> 00:05:30,880
And then an example would be the inf of 0,
1 is 0 for example.

93
00:05:30,880 --> 00:05:34,432
So, you would not write the min, except
very informally.

94
00:05:34,432 --> 00:05:39,310
Okay, I should make a, let's see, a couple
more comments I wanted to make.

95
00:05:39,310 --> 00:05:40,806
Oh, one is this.

96
00:05:40,806 --> 00:05:48,660
It is absolutely standard that the inf of
the empty set is plus infinity.

97
00:05:48,660 --> 00:05:53,490
Again, there is no no variation in that,
that's, that's always as is.

98
00:05:53,490 --> 00:05:58,864
And if you do that, various rules about
infimum hold in this case.

99
00:05:58,864 --> 00:06:02,060
And if a, if a set is unbounded below,
that means that, for

100
00:06:02,060 --> 00:06:06,004
example here, there are x's Which satisfy
all the constraints but for

101
00:06:06,004 --> 00:06:11,600
which f zero of x can be made as negative
as you like.

102
00:06:11,600 --> 00:06:13,426
Right?
Then you waould say the problem is

103
00:06:13,426 --> 00:06:17,980
unbounded below and we would simply say p
star is minus infinity.

104
00:06:19,040 --> 00:06:20,610
So that's the idea.

105
00:06:20,610 --> 00:06:23,795
I mean from an optimization point of view
I guess that's the best thing that can

106
00:06:23,795 --> 00:06:26,539
ever possibly happen although what it
really suggests is that your

107
00:06:26,539 --> 00:06:28,610
model is wrong.

108
00:06:28,610 --> 00:06:31,550
It hasn't been set up correctly or
something like that.

109
00:06:31,550 --> 00:06:35,160
By the way this has got a very amusing
name in some cases right?

110
00:06:35,160 --> 00:06:39,568
There's at least one case I know where if
when p star is minus infinity,

111
00:06:39,568 --> 00:06:47,000
it's referred to as Euphoric breakdown,
which I think is just a great term for it.

112
00:06:47,000 --> 00:06:52,790
It means, it means that, it means that,
that you can be as happy as you like.

113
00:06:52,790 --> 00:06:54,250
Anyway, I won't go on.

114
00:06:54,250 --> 00:06:55,765
Right.
That's b stars infinity.

115
00:06:55,765 --> 00:06:57,950
Okay.

116
00:06:57,950 --> 00:06:59,680
So, this is a optimization bottom standard
form.

117
00:06:59,680 --> 00:07:01,133
Oh, and I wanted to say one more thing.

118
00:07:01,133 --> 00:07:05,489
Never confuse the mathematical operator
min, which is a function that takes as

119
00:07:05,489 --> 00:07:11,335
argument a set of, a finite set of real
numbers and returns the minimum.

120
00:07:11,335 --> 00:07:15,001
And this word minimize, they are
absolutely different,

121
00:07:15,001 --> 00:07:20,366
although some people kind of use the same,
same word for it.

122
00:07:20,366 --> 00:07:22,160
I don't approve of that.

123
00:07:22,160 --> 00:07:25,830
It's not so bad as long as they know what
they're doing but they're different.

124
00:07:25,830 --> 00:07:26,962
Minimize is not min.

125
00:07:26,962 --> 00:07:32,800
So min is a function that takes something
like this, right?

126
00:07:32,800 --> 00:07:37,040
Zero minus one two right and it gives you
minus one.

127
00:07:37,040 --> 00:07:37,795
There's a function.

128
00:07:37,795 --> 00:07:41,980
Minimize you should think of as Is as
something that is

129
00:07:41,980 --> 00:07:45,980
part of an optimization problem.

130
00:07:45,980 --> 00:07:47,415
And the way I think of this optimization
problem,

131
00:07:47,415 --> 00:07:49,089
it is not a number; this is a number.

132
00:07:49,089 --> 00:07:51,270
This is not a number; this is an object.

133
00:07:51,270 --> 00:07:55,692
It's an, it's like, it's an optimization
problem object, if you like to think it,

134
00:07:55,692 --> 00:08:00,400
of this, in terms of, like,
object-oriented programming.

135
00:08:00,400 --> 00:08:02,974
That's an object minimized Is,

136
00:08:02,974 --> 00:08:10,320
is a key word that introduces an attribute
of an optimization object.

137
00:08:10,320 --> 00:08:11,000
That's what it is.

138
00:08:11,000 --> 00:08:16,990
So this is saying that problem, you know,
dot objective, is f0.

139
00:08:16,990 --> 00:08:18,760
That's what it's saying.

140
00:08:18,760 --> 00:08:23,776
Subject to again is something that's a
keyword that tells you what follows that

141
00:08:23,776 --> 00:08:28,412
is a set of constraints for that problem,
okay, and so you wouldn't say

142
00:08:28,412 --> 00:08:36,160
you would never say this optimization
problem has, you know, is three.

143
00:08:36,160 --> 00:08:39,930
What you can say is that its optimal value
is three.

144
00:08:39,930 --> 00:08:41,118
That makes sense.

145
00:08:41,118 --> 00:08:44,278
Okay.

146
00:08:44,278 --> 00:08:52,867
So we should talk about the idea of an
optimal and locally optimal point.

147
00:08:52,867 --> 00:08:57,160
You say X is feasible if you're in the
domain of the objective and

148
00:08:57,160 --> 00:09:01,000
you satisfy all the constraints.

149
00:09:01,000 --> 00:09:04,562
Now that implies you're in the domain of
all the constraint functions.

150
00:09:04,562 --> 00:09:06,299
Right?

151
00:09:06,299 --> 00:09:09,549
And a feasible x is optimal if its
objective value is equal to

152
00:09:09,549 --> 00:09:12,665
the optimal value of the problem.

153
00:09:12,665 --> 00:09:13,370
Okay?

154
00:09:13,370 --> 00:09:16,630
So that means well, just what it says.

155
00:09:16,630 --> 00:09:20,207
It means that X is, gets an objective
value that is as good as

156
00:09:20,207 --> 00:09:26,010
the least possible value among all other
feasible points, right?

157
00:09:26,010 --> 00:09:29,150
And we'll let X opt be the set of optimal
points.

158
00:09:29,150 --> 00:09:32,444
It could, the X opt can be empty, notice
there is no optimal point,

159
00:09:32,444 --> 00:09:38,100
it could have a single entry, could be a
singleton, as a unique optimal point.

160
00:09:38,100 --> 00:09:40,872
And it, it could actually be an a set with
two, three points, finite number of

161
00:09:40,872 --> 00:09:44,530
points; or it could be a set with an
infinite number of points, right?

162
00:09:44,530 --> 00:09:48,170
So, in convex optimization, the second one
can't happen, well, sorry, the third one.

163
00:09:48,170 --> 00:09:51,698
It can, if you have two points a-, and
then, in, for a convex problem,

164
00:09:51,698 --> 00:09:57,530
which we'll talk about shortly it means
that you have an infinite number.

165
00:09:57,530 --> 00:09:59,216
So, but we'll, we'll talk about that later
in a bit.

166
00:09:59,216 --> 00:10:00,082
Okay.

167
00:10:00,082 --> 00:10:06,120
Now, locally optimal is a point which had
the following property.

168
00:10:06,120 --> 00:10:08,266
It says that there's a positive r so

169
00:10:08,266 --> 00:10:14,700
it's that if I add the constraint, that
you are no farther than r away from x.

170
00:10:14,700 --> 00:10:20,310
So x is the point that we're going to
certify as locally optimal.

171
00:10:20,310 --> 00:10:21,970
Then x really is optimal for this problem.

172
00:10:21,970 --> 00:10:23,160
Something like that.

173
00:10:23,160 --> 00:10:27,906
So that's, that's what it that's what that
means.

174
00:10:27,906 --> 00:10:31,308
So let's see what that means, here, let's
draw a function looks like this.

175
00:10:31,308 --> 00:10:36,610
Draw in fact Our function will be this
one, x cubed minus three x.

176
00:10:36,610 --> 00:10:37,690
That looks like this.

177
00:10:37,690 --> 00:10:40,779
It's got a, it, at plus 1 it's here.

178
00:10:40,779 --> 00:10:42,605
Sorry, that's at minus one.

179
00:10:42,605 --> 00:10:43,940
Right?

180
00:10:43,940 --> 00:10:46,470
And at plus one it's got a local minimum.

181
00:10:46,470 --> 00:10:48,494
And the claim is that this is a local
minimum because if I

182
00:10:48,494 --> 00:10:52,150
were to add the constraint that you're
between here and here.

183
00:10:52,150 --> 00:10:56,693
Then for sure that value is that's x
equals 1 is the optimal point for

184
00:10:56,693 --> 00:10:59,018
that problem.

185
00:10:59,018 --> 00:10:59,722
Okay.

186
00:10:59,722 --> 00:11:02,730
Let's look at some simple examples.

187
00:11:02,730 --> 00:11:10,316
So, first it says let's minimize 1 over x
and here x has to be positive, right?

188
00:11:10,316 --> 00:11:11,280
That's because that's the domain.

189
00:11:11,280 --> 00:11:13,720
That's the declaration of the domain of f
0.

190
00:11:13,720 --> 00:11:15,785
And in this case there's no optimal point,
right?

191
00:11:15,785 --> 00:11:18,560
because we, goes something like this,
right?

192
00:11:18,560 --> 00:11:23,045
Here's here's x, and the point is that the
larger x is, the smaller 1 over x is, and

193
00:11:23,045 --> 00:11:27,340
you can make this number as small as you
like.

194
00:11:27,340 --> 00:11:28,500
You cannot make it 0.

195
00:11:28,500 --> 00:11:30,960
You want to say, you would like to make it
0 by saying x equals infinity, but

196
00:11:30,960 --> 00:11:32,979
that's not allowed.

197
00:11:32,979 --> 00:11:38,860
So the infimum of these points is 0.

198
00:11:38,860 --> 00:11:40,440
Okay?
But there is no point x for

199
00:11:40,440 --> 00:11:45,995
which 1 over x is 0, so this, this this
thing has no optimal point.

200
00:11:45,995 --> 00:11:46,608
Okay?

201
00:11:46,608 --> 00:11:54,360
Another one would be minus log x, so minus
log x would look oh, something like this.

202
00:11:54,360 --> 00:11:55,772
But it would come down at 0.

203
00:11:55,772 --> 00:11:58,860
At 1 it would go through the value 0 and
then it would keep doing down.

204
00:11:58,860 --> 00:12:00,575
Very slowly, but it keeps going down.

205
00:12:00,575 --> 00:12:04,380
And, it goes down as low as you'd like.

206
00:12:04,380 --> 00:12:07,200
That says p star minus infinity because
the infimum of all these points,

207
00:12:07,200 --> 00:12:09,795
you just take x again as big as you like.

208
00:12:09,795 --> 00:12:14,310
Next example is going to be X log X
negative entrpoy, so

209
00:12:14,310 --> 00:12:19,670
for negtive entropy here I'll draw that.

210
00:12:19,670 --> 00:12:28,110
The negetive entropy function looks like
this and goes up like that alright?

211
00:12:28,110 --> 00:12:32,666
So for this function and the domain is all
positive numbers here This really,

212
00:12:32,666 --> 00:12:36,100
really does have an optimal value.

213
00:12:36,100 --> 00:12:38,478
It's achieved at, sort of, 1 over E,

214
00:12:38,478 --> 00:12:44,412
the value 1 over E and the value is minus
1 over E, right there.

215
00:12:44,412 --> 00:12:44,993
Right?

216
00:12:44,993 --> 00:12:49,151
So, this is, this is an example of a
problem where these first 2

217
00:12:49,151 --> 00:12:53,430
are pathologies of different kinds.

218
00:12:53,430 --> 00:12:55,206
And this one is the first one,

219
00:12:55,206 --> 00:13:00,230
where it's had sort of has a
non-pathological answer, right?

220
00:13:00,230 --> 00:13:03,478
So it says, if you want to minimize
negative entropy, or we could say if

221
00:13:03,478 --> 00:13:09,150
you want to maximize entropy you would
take x equals 1 over e as optimal, right.

222
00:13:09,150 --> 00:13:12,650
Oh, I should say this log of course is a
log base e.

223
00:13:12,650 --> 00:13:16,780
Not log base 2, um, [COUGH] okay.

224
00:13:16,780 --> 00:13:18,415
This example we've already seen.

225
00:13:18,415 --> 00:13:23,130
This is the one, where it goes up and then
down and then up again.

226
00:13:23,130 --> 00:13:27,039
That's a locally optimal point, but p star
is minus infinity.

227
00:13:27,039 --> 00:13:30,638
One thing that will come up at various
times in this course is the idea of

228
00:13:30,638 --> 00:13:33,880
implicit versus explicit constraints.

229
00:13:33,880 --> 00:13:38,290
So, implicit constraints are the
constraints, as an in, we don't really say

230
00:13:38,290 --> 00:13:42,700
this, but the domain of a problem is the
intersections of the domains of the,

231
00:13:42,700 --> 00:13:46,410
all of the fi including zero, that's the
objective function and

232
00:13:46,410 --> 00:13:53,570
all the constraint functions and all the
equality constraints.

233
00:13:53,570 --> 00:13:56,090
And so we'll call that the domain of the
problem.

234
00:13:56,090 --> 00:13:58,504
And what it means is that if you ask
about,

235
00:13:58,504 --> 00:14:04,340
if you propose an x that's outside the
domain of the problem.

236
00:14:04,340 --> 00:14:08,687
It's it means it's inappropriate, it's
inappropriate because what it means is

237
00:14:08,687 --> 00:14:11,648
if you're outside the domain of the
objective, it says I,

238
00:14:11,648 --> 00:14:18,350
I can't even evaluate the objective to
tell you whether or not it's good or bad.

239
00:14:18,350 --> 00:14:26,610
Right, so now in our, when F0 is convex
and we use infinite valued extensions.

240
00:14:26,610 --> 00:14:30,230
There's a seamless way to handle this and
what we do is we simply say.

241
00:14:30,230 --> 00:14:32,400
It's plu, we return plus infinity for

242
00:14:32,400 --> 00:14:36,220
being outside the domain, that works just
fine.

243
00:14:36,220 --> 00:14:39,454
In the general case, though, you might
return a token that says something like,

244
00:14:39,454 --> 00:14:40,875
out of domain.

245
00:14:40,875 --> 00:14:43,170
Okay.

246
00:14:43,170 --> 00:14:46,530
Now on the other hand, these are explicit
constraints, right?

247
00:14:46,530 --> 00:14:49,551
So, it says, these, when you actually say
for example, you know,

248
00:14:49,551 --> 00:14:54,590
F1 of X has to be less than or equal to,
that's an explicit constraint.

249
00:14:54,590 --> 00:14:56,124
It says, please evaluate F1 and

250
00:14:56,124 --> 00:15:00,400
then compare that number to zero sorry, to
compare it to zero.

251
00:15:00,400 --> 00:15:02,990
If you are less than or equal to zero,
it's just fine.

252
00:15:02,990 --> 00:15:07,180
If you are above zero, it is completely
unacceptable.

253
00:15:07,180 --> 00:15:11,100
Right, so by the way, you can, there's a
subtle difference here, and

254
00:15:11,100 --> 00:15:15,310
probably this is not a bad way to think of
it.

255
00:15:15,310 --> 00:15:18,791
There's actually quite a different thing,
it's two different types of

256
00:15:18,791 --> 00:15:22,508
bad things happen if you propose in an
optimization problem a point which is

257
00:15:22,508 --> 00:15:28,710
out of the domain of the problem, versus
one in that is infeasible.

258
00:15:28,710 --> 00:15:32,670
Right, so, in one sense I would say that
the first one is a little bit worse.

259
00:15:32,670 --> 00:15:34,825
I mean, practically they're the same
thing.

260
00:15:34,825 --> 00:15:39,012
So, if you propose an x, and it's just,
like, you, and, and it, and

261
00:15:39,012 --> 00:15:42,093
what's returned is a message that says,
this x,

262
00:15:42,093 --> 00:15:48,610
I can't even evaluate the constraint
number 3.

263
00:15:48,610 --> 00:15:50,510
I don't even get a number, right?

264
00:15:50,510 --> 00:15:54,350
I get something like a nan, nan, which is
not a number, right?

265
00:15:54,350 --> 00:15:58,640
So then you can't compare that to 0, or
something like that and so, that sort of,

266
00:15:58,640 --> 00:16:03,062
in some sense that's worse, I, maybe this
is just, maybe this is just subjective,

267
00:16:03,062 --> 00:16:10,250
but that's worse than actually having F3,
having all the functions evaluate.

268
00:16:10,250 --> 00:16:13,230
And then having one of const, inequality
constraint functions be positive.

269
00:16:13,230 --> 00:16:14,480
So, okay.

270
00:16:15,670 --> 00:16:19,870
Now a problem is unconstrained if it has
no explicit constraints.

271
00:16:19,870 --> 00:16:24,250
Does not mean, I mean you could, you could
have implicit constraints.

272
00:16:24,250 --> 00:16:27,728
Here's an example of a function like that,
or of an example.

273
00:16:27,728 --> 00:16:32,628
Is minimize f0 of x, subject to, sorry,
minimize f0 of x,

274
00:16:32,628 --> 00:16:39,380
which is the sum of minus log bi minus ai
transpose x.

275
00:16:39,380 --> 00:16:39,900
Okay?

276
00:16:39,900 --> 00:16:42,508
So here's the, just one f0, there are no
fis.

277
00:16:42,508 --> 00:16:43,528
None.

278
00:16:43,528 --> 00:16:45,320
No hi's.

279
00:16:45,320 --> 00:16:49,784
And so here, there's there are implicit
constraints that the arguments to

280
00:16:49,784 --> 00:16:52,710
the log have to be positive.

281
00:16:52,710 --> 00:16:53,940
Right.
So you have to have bi

282
00:16:53,940 --> 00:16:56,756
strictly bigger than ai transposed x.

283
00:16:56,756 --> 00:17:02,630
If it's equal to 0, or worse negative
you're just out of the domain and log.

284
00:17:04,170 --> 00:17:07,875
If you're using the extended value
extensions and everything's implemented

285
00:17:07,875 --> 00:17:12,880
correctly, and you evaluate something
where this evaluates out to minus .2.

286
00:17:12,880 --> 00:17:18,230
Then it might just correctly return, plus
infinity for minus log at that term.

287
00:17:18,230 --> 00:17:20,380
So that's an example.

288
00:17:20,380 --> 00:17:20,880
Okay.

289
00:17:22,740 --> 00:17:26,106
So a feasibility problem is a, well it's a
simplified one, and

290
00:17:26,106 --> 00:17:29,010
it's sometimes written this way: you'd say
find x and

291
00:17:29,010 --> 00:17:33,680
then subject to a set of inequality
constraints.

292
00:17:33,680 --> 00:17:36,520
Inequality and equality as well.

293
00:17:36,520 --> 00:17:39,670
These are both optional, well I guess we
could have a short discussion about

294
00:17:39,670 --> 00:17:42,570
unconstrained feasibility problems, right.

295
00:17:42,570 --> 00:17:46,390
So those are, those are very easy because
any x is, any x is optimal.

296
00:17:46,390 --> 00:17:47,360
Okay.
So this is a,

297
00:17:47,360 --> 00:17:49,150
this is a feasibility problem.

298
00:17:49,150 --> 00:17:52,552
And actually it fits in the general
framework in a very simple way

299
00:17:52,552 --> 00:17:55,828
because it's exactly the same as the
general problem where you

300
00:17:55,828 --> 00:18:01,230
minimize an objective that's just
identically zero.

301
00:18:01,230 --> 00:18:01,960
It just works.

302
00:18:01,960 --> 00:18:05,310
Everything, the semantics, just works
perfectly, because here's what happens.

303
00:18:05,310 --> 00:18:08,126
If you have a point that is feasible for

304
00:18:08,126 --> 00:18:14,309
the feasible, I mean, if it satisfies the
constraints, right?

305
00:18:14,309 --> 00:18:18,130
Then, well, the objective function is 0.

306
00:18:18,130 --> 00:18:19,710
Right, and so if you, if,

307
00:18:19,710 --> 00:18:26,400
if this problem is feasible, the set of
feasible points will be non empty.

308
00:18:26,400 --> 00:18:30,640
And that means there'll be a point whose
objective value is 0.

309
00:18:30,640 --> 00:18:32,950
If you're feasible, the only objective
value you can have is 0.

310
00:18:32,950 --> 00:18:34,160
So, it's optimal.

311
00:18:34,160 --> 00:18:39,070
So any point, any point that's feasible is
optimal, and the converse is very simple.

312
00:18:39,070 --> 00:18:40,286
If this is infeasible,

313
00:18:40,286 --> 00:18:45,699
it says that there's no point that has
where that satisfies all the constraints.

314
00:18:45,699 --> 00:18:49,101
Right, therefore the optimal value is
define to be the infimum of

315
00:18:49,101 --> 00:18:52,188
the function which always returns 0 over
the empty set, and

316
00:18:52,188 --> 00:18:56,770
that happens to be plus indicated by
convention.

317
00:18:56,770 --> 00:18:59,795
I mean it looks strange but it actually
all just works out fine.

318
00:18:59,795 --> 00:19:04,420
Okay.

319
00:19:04,420 --> 00:19:08,600
So finally we get to the formal definition
of a convex optimization problem.

320
00:19:08,600 --> 00:19:10,440
So that's something like this.

321
00:19:10,440 --> 00:19:12,332
It says it's an optimization problem, but
it's a, so

322
00:19:12,332 --> 00:19:15,104
it inherits everything from an
optimization problem, all the notions that

323
00:19:15,104 --> 00:19:19,760
you have there, like feasibility,
optimality and everything else.

324
00:19:19,760 --> 00:19:21,500
But there are some constraints.

325
00:19:21,500 --> 00:19:24,605
The constraints are this, the objective
function and

326
00:19:24,605 --> 00:19:28,960
all inequality constraints have to be
convex functions.

327
00:19:28,960 --> 00:19:31,716
So that's one requirement, and

328
00:19:31,716 --> 00:19:38,440
the equality constraint functions must be
half-line right?

329
00:19:38,440 --> 00:19:41,212
So it's a normal for people to write it
this way, but

330
00:19:41,212 --> 00:19:46,130
if you'd like you could write this as ai
transpose x minus bi.

331
00:19:46,130 --> 00:19:53,880
you would define this to be gi of x and
that's equal to zero, something like that.

332
00:19:53,880 --> 00:19:54,927
Okay?
And so, but

333
00:19:54,927 --> 00:19:59,930
your this would be you'd define these
functions this way.

334
00:19:59,930 --> 00:20:03,404
But it's more common to write it that way,
okay?

335
00:20:03,404 --> 00:20:06,786
And if f0 is, if the objective is
quasiconvex,

336
00:20:06,786 --> 00:20:13,204
then the problem is called a quasiconvex
optimization problem.

337
00:20:13,204 --> 00:20:16,450
Now, the quality constraints here, which
have to be linear.

338
00:20:16,450 --> 00:20:20,270
Well, which is kind of informal speech for
affine, right.

339
00:20:20,270 --> 00:20:23,042
Because there's a lot of situations where
you talk about linear equalities and

340
00:20:23,042 --> 00:20:25,730
what you really mean are affine equalities
but people have been calling them

341
00:20:25,730 --> 00:20:29,809
linear equalities for hundreds of years so
we'll stick with that.

342
00:20:29,809 --> 00:20:34,262
In that case, it's, it's typical to
collect those into a matrix, right, so

343
00:20:34,262 --> 00:20:36,690
that Ax equals b.

344
00:20:36,690 --> 00:20:40,122
Each row is one equality constraint in the
problem written out

345
00:20:40,122 --> 00:20:44,420
with the equality constrainsts listed out
separately.

346
00:20:44,420 --> 00:20:46,310
Alright, so, okay.

347
00:20:46,310 --> 00:20:47,412
And people would call this someth,

348
00:20:47,412 --> 00:20:49,730
I mean you might call it a vector equality
constraint.

349
00:20:49,730 --> 00:20:50,535
It doesn't matter.

350
00:20:50,535 --> 00:20:52,750
Okay.

351
00:20:52,750 --> 00:20:55,612
Now, one very important property here is
that the feasible set of

352
00:20:55,612 --> 00:20:58,859
a convext optimization problem is convex.

353
00:20:58,859 --> 00:21:02,980
So in fact is the optimal set, right?

354
00:21:02,980 --> 00:21:04,300
So, and that's very easy to see.

355
00:21:04,300 --> 00:21:07,628
The feasible set is simply the set of X
that satisfy AX equals B,

356
00:21:07,628 --> 00:21:11,370
and then FI of X is less than or equal to
0.

357
00:21:11,370 --> 00:21:13,551
And that's going to be a convex set.

358
00:21:13,551 --> 00:21:16,660
Actually it's very easy to show directly,
but you know it anyway.

359
00:21:16,660 --> 00:21:22,800
It's a sublevel of convex sets, and it's
an intersection of that's an affine set.

360
00:21:22,800 --> 00:21:25,452
The, the, the, set of feasible points for
a x equals b and for

361
00:21:25,452 --> 00:21:27,760
each of the convex functions.

362
00:21:27,760 --> 00:21:29,795
Here, it's a sublevel set which is convex
and

363
00:21:29,795 --> 00:21:33,876
therefore it's an an intersection of m
convex sets, n plus 1.

364
00:21:33,876 --> 00:21:39,360
N sublevel sets and 1 affine set defined
by the equality constraints.

365
00:21:39,360 --> 00:21:39,960
Okay.

366
00:21:39,960 --> 00:21:43,384
So let's look at an example.

367
00:21:44,480 --> 00:21:48,010
And actually it's meant to bring out a
very imporatnt point.

368
00:21:49,010 --> 00:21:55,410
And that is that convexity is an attribute
of the description of the problem.

369
00:21:55,410 --> 00:21:57,550
So this is actually very important.

370
00:21:57,550 --> 00:21:58,525
It is not.

371
00:21:58,525 --> 00:22:01,811
So there's a more abstract definition of
convex optimization,

372
00:22:01,811 --> 00:22:04,105
which is a convex optimization problem,
is,

373
00:22:04,105 --> 00:22:09,455
is a problem where you minimize a convex
function over a convex set.

374
00:22:09,455 --> 00:22:10,710
Right?

375
00:22:10,710 --> 00:22:12,850
We'll see that this is one, this example.

376
00:22:12,850 --> 00:22:16,890
But it is not a convex optimization
problem by our stricter definition.

377
00:22:16,890 --> 00:22:19,090
It depends on the description.

378
00:22:19,090 --> 00:22:20,656
So here, let's look at the problem,

379
00:22:20,656 --> 00:22:23,920
it says minimize, it's a problem with two
variables.

380
00:22:23,920 --> 00:22:25,324
It says minimize the sum of the two
squares, but

381
00:22:25,324 --> 00:22:27,470
you know what the objective function looks
like.

382
00:22:27,470 --> 00:22:30,886
It's a, it's a bolt so it kind of goes up,
and it says minimize the norm of x or

383
00:22:30,886 --> 00:22:34,470
minimize the norm squared of x.Subject to,
the first constraint says f1 of x,

384
00:22:34,470 --> 00:22:41,050
that's going to be x1 over 1 plus x
squared that's less than or equal to 0.

385
00:22:41,050 --> 00:22:42,130
Well it doesn't take long for

386
00:22:42,130 --> 00:22:45,240
you to figure out that's not a convex
function of x 1 and x 2.

387
00:22:45,240 --> 00:22:48,070
It just isn't, okay.

388
00:22:48,070 --> 00:22:50,490
And the last equality constraint is this.

389
00:22:50,490 --> 00:22:52,836
It says x 1 plus x 2 squared is 0.

390
00:22:52,836 --> 00:22:58,440
Well, X1 plus X2 quantity squared is
definitely not a convex function.

391
00:22:58,440 --> 00:23:00,092
Would you look at it carefully and

392
00:23:00,092 --> 00:23:03,710
you realize these two constraints define a
convex set.

393
00:23:03,710 --> 00:23:06,000
Why?
Because to say X1 plus X2 squared is 0

394
00:23:06,000 --> 00:23:11,123
is the same as saying X1 plus X2 is 0, so
that's just a, that's a line.

395
00:23:11,123 --> 00:23:11,711
Right?

396
00:23:11,711 --> 00:23:16,730
This constraint x1 over 1 x2 squared less
than or equal to 0.

397
00:23:16,730 --> 00:23:20,492
This thing is positive, so you just get
rid of it, since x1 less than or

398
00:23:20,492 --> 00:23:22,760
equal to 0, right?

399
00:23:22,760 --> 00:23:28,020
So in fact the feasible set is a ray, it's
just a ray, and it's perfectly convex.

400
00:23:28,020 --> 00:23:32,370
So this problem is minimizing a convex
function over a convex set, but

401
00:23:32,370 --> 00:23:37,780
it is not a convex problem by our strict
definition, right?

402
00:23:37,780 --> 00:23:40,479
So our strict definition is extremely
simple.

403
00:23:40,479 --> 00:23:47,580
It's basically problem dot objective dot
is convex, you call that method.

404
00:23:47,580 --> 00:23:50,095
And if it's, if it's not, then it's end of
story.

405
00:23:50,095 --> 00:23:51,170
Right.

406
00:23:51,170 --> 00:23:54,130
After that you iterate over the
constraints and

407
00:23:54,130 --> 00:23:59,088
you check if every ineqaulity constraint
function is convex and if the answer is

408
00:23:59,088 --> 00:24:03,750
no, it's all over and then check every
equality constraint function and

409
00:24:03,750 --> 00:24:12,362
every single one has to be affine okay so
that's our, that's our definition.

410
00:24:12,362 --> 00:24:17,220
So we would say that this problem is
equivalent to this problem.

411
00:24:18,410 --> 00:24:20,434
And we're not going to use I mean we're
not going to go

412
00:24:20,434 --> 00:24:24,110
into a fancy formal definition of what
equivalent means.

413
00:24:24,110 --> 00:24:27,128
I think like you would in a CS Theory
class.

414
00:24:27,128 --> 00:24:29,800
Instead we'll just say, we'll have a
informal definition.

415
00:24:29,800 --> 00:24:33,496
The informal definition is this, that two
problems are equivalent if from one u

416
00:24:33,496 --> 00:24:37,520
can readily compute the solution of the
other.

417
00:24:37,520 --> 00:24:39,000
Right and vice versa right.

418
00:24:39,000 --> 00:24:42,953
So eh, here it's extremely simple the
sense in which this problem Is

419
00:24:42,953 --> 00:24:45,490
equivalent to that one.

420
00:24:45,490 --> 00:24:48,550
It's a, here's, here's the method that
does it.

421
00:24:48,550 --> 00:24:49,980
It's, you simply copy x.

422
00:24:49,980 --> 00:24:54,732
So, if you solve this problem then the
solution of that is also a well,

423
00:24:54,732 --> 00:25:00,240
a solution of that is a solution of that,
and vice versa.

424
00:25:00,240 --> 00:25:04,180
If you have a solution of this, it's a
solution of that, alright.

425
00:25:04,180 --> 00:25:06,572
So I, I guess that satisfies this general
idea that it's easy to

426
00:25:06,572 --> 00:25:09,478
construct the solut-, because there's
nothing to do.

427
00:25:09,478 --> 00:25:14,878
Okay, this problem is convex because the
objective is convex function,

428
00:25:14,878 --> 00:25:20,910
the constraint you check the inequality
constraint.

429
00:25:20,910 --> 00:25:23,540
You look at the lefthand side, the lefhand
side is x1.

430
00:25:23,540 --> 00:25:26,152
You ask whether the function x1 is convex,
it is.

431
00:25:26,152 --> 00:25:26,920
Done.

432
00:25:26,920 --> 00:25:30,230
You look at the constraint, at the quality
constraint function.

433
00:25:30,230 --> 00:25:34,580
You ask whether X1 plus X2 is an affine
function, it is, done.

434
00:25:34,580 --> 00:25:36,480
So, that said, that's a convex.

435
00:25:36,480 --> 00:25:40,766
And the, this'll be important, it'll come
up at several points.

436
00:25:40,766 --> 00:25:42,114
Okay.

437
00:25:42,114 --> 00:25:43,400
Now.

438
00:25:43,400 --> 00:25:45,996
Here's a you know, very important fact
about, and

439
00:25:45,996 --> 00:25:49,790
basically elementary fact, about convex
optimization.

440
00:25:49,790 --> 00:25:54,476
And that's this, any locally optimal point
of a convex optimization problem is

441
00:25:54,476 --> 00:25:57,284
globally optimal, alright.

442
00:25:57,284 --> 00:26:03,084
So, it's a very basic fact, it's very easy
to show.

443
00:26:03,084 --> 00:26:05,318
But it's very important, actually it's
quite interesting.

444
00:26:05,318 --> 00:26:10,016
It says that if, if you cannot improve,
if, if you find a point where you

445
00:26:10,016 --> 00:26:17,965
cannot walk, there's nowhere around you
where you can improve over what you have.

446
00:26:17,965 --> 00:26:22,960
Then you don't have to look farther
afield, I mean that's what this says.

447
00:26:22,960 --> 00:26:26,062
We'll look at the proof, and in fact
instead of the proof I

448
00:26:26,062 --> 00:26:31,271
might just draw a picture and then that'll
make everything clear.

449
00:26:31,271 --> 00:26:35,255
So here's what we're going to do, I'm
going take a point and

450
00:26:35,255 --> 00:26:38,824
I'm going to say that x is locally
optimal, here, and

451
00:26:38,824 --> 00:26:46,660
what I'll do is I'll take I'll imagine
that y is globally optimal.

452
00:26:46,660 --> 00:26:49,780
By the way, when you talk about local
optimality and you want to

453
00:26:49,780 --> 00:26:54,580
make sure you mean just optimality, you
say it is globally optimal.

454
00:26:54,580 --> 00:26:59,928
So here I'll say y is globally optimal and
not only that, it beats the local optimum.

455
00:26:59,928 --> 00:27:03,276
So this says, this says that there is a
locally optimal point x

456
00:27:03,276 --> 00:27:07,660
which is actually beaten by another point.

457
00:27:07,660 --> 00:27:08,220
It's that simple.

458
00:27:08,220 --> 00:27:13,670
What I'm going to do is draw the line
segment leading x to y and

459
00:27:13,670 --> 00:27:18,170
we'll look a a point.

460
00:27:18,170 --> 00:27:20,210
That goes on that line segment here,
right.

461
00:27:20,210 --> 00:27:22,240
So if I take theta equals zero, I start at
x,

462
00:27:22,240 --> 00:27:25,380
and as theta goes up to one, I approach y.

463
00:27:25,380 --> 00:27:29,630
And what I'll do, is I'll take the, oh I
should, I should mention something.

464
00:27:29,630 --> 00:27:35,610
Both x and y are feasible, for the convex
optimization problem.

465
00:27:35,610 --> 00:27:38,840
This z is a convex combination therefore
its feasible.

466
00:27:38,840 --> 00:27:41,000
So that there's no doubt about
feasibility.

467
00:27:41,000 --> 00:27:43,329
So we only have to worry about the
objective function.

468
00:27:43,329 --> 00:27:44,830
So lets look at the objective function.

469
00:27:44,830 --> 00:27:47,720
Lets just plot f zero as a function of
Theta.

470
00:27:47,720 --> 00:27:49,335
Well its going to look like this.

471
00:27:49,335 --> 00:27:52,970
Here's here's theta equals zero, here's
theta equals one.

472
00:27:52,970 --> 00:27:57,970
When theta equals zero I'm going to plot f
of z.

473
00:27:57,970 --> 00:27:59,808
And Z in turn depends on theta.

474
00:27:59,808 --> 00:28:05,307
So, F of, if I take 0 then that
coressponds to Z equals X and

475
00:28:05,307 --> 00:28:14,355
I get some F of X so, there we go, that's
F 0 of X here okay.

476
00:28:14,355 --> 00:28:17,310
then I look at 1 then z is y.

477
00:28:17,310 --> 00:28:18,540
and I take that.

478
00:28:18,540 --> 00:28:24,812
And by def, by our assumption here it's
smaller so this is f zero of y.

479
00:28:24,812 --> 00:28:25,514
Okay?

480
00:28:25,514 --> 00:28:34,010
But now, let's go back and look at this
the local optimality of x.

481
00:28:34,010 --> 00:28:35,060
That says.

482
00:28:35,060 --> 00:28:39,412
Yet there's a little range like that where
in that range you certainly can't,

483
00:28:39,412 --> 00:28:40,092
you are not,

484
00:28:40,092 --> 00:28:46,350
you can't do better than that Zero of X
because that X is locally optimal.

485
00:28:46,350 --> 00:28:48,870
So that say that whatever happens in the
funciton,

486
00:28:48,870 --> 00:28:52,472
it has to be above that little horizontal
segment.

487
00:28:52,472 --> 00:28:59,290
Okay, so, that's that's the idea so, now
now we got a problem.

488
00:28:59,290 --> 00:29:02,197
And it's a geometric problem I mean we
could work the proof is 3

489
00:29:02,197 --> 00:29:06,580
lines alegbraically but the picture is
actually maybe better.

490
00:29:06,580 --> 00:29:10,533
The problem is this F zero restricted to
the line segement between X and

491
00:29:10,533 --> 00:29:14,360
Z that's a convex function of theta.

492
00:29:14,360 --> 00:29:17,770
And now we got a little problem because we
have a convex fucntion of

493
00:29:17,770 --> 00:29:20,622
theta that starts out flat and somehow
ends up lower and

494
00:29:20,622 --> 00:29:25,420
you can't do that and your eyeball tells
you that.

495
00:29:25,420 --> 00:29:29,080
If you can work it out algebraically it's
3 lines and it's an equality and

496
00:29:29,080 --> 00:29:31,060
stuff like that.

497
00:29:31,060 --> 00:29:33,860
At some point there's no way a convex
function can start out flat and

498
00:29:33,860 --> 00:29:35,860
end up down here.

499
00:29:35,860 --> 00:29:36,820
Just can't do it.

500
00:29:36,820 --> 00:29:37,720
So.
Okay.

501
00:29:37,720 --> 00:29:43,800
So I'll, that's my, that's my picture,
proof, of this.

502
00:29:43,800 --> 00:29:45,040
Okay.

503
00:29:45,040 --> 00:29:49,340
Now we can work out, the optimality
criterion for a differentiable function.

504
00:29:49,340 --> 00:29:49,990
This is useful.

505
00:29:49,990 --> 00:29:50,910
It's a good way to start.

506
00:29:50,910 --> 00:29:53,613
Later in the class when we talk about
duality, we will work out

507
00:29:53,613 --> 00:29:58,900
optimality conditions for full general
case with all the constraints, everything.

508
00:29:58,900 --> 00:30:01,595
But for now, what we're going to do is
we're going to just work out

509
00:30:01,595 --> 00:30:04,235
some very simple ones actually based on an
inequality for

510
00:30:04,235 --> 00:30:07,670
differentiable functions and it's this.

511
00:30:07,670 --> 00:30:12,567
A point X is optimal, this is for the
special case of the objective being

512
00:30:12,567 --> 00:30:20,460
differentiable so it says if the following
is true the gradient of F 0 X.

513
00:30:20,460 --> 00:30:26,240
Is transposed times y minus x is bigger
than zero for all feasible y.

514
00:30:26,240 --> 00:30:28,445
So, that's the that's the condition.

515
00:30:28,445 --> 00:30:32,902
And a picture would look something like
this.

516
00:30:32,902 --> 00:30:37,810
This dark set, this is the feasible set,
okay?

517
00:30:37,810 --> 00:30:41,032
And these curved, these dashed lines here,
those are the level sets of f.

518
00:30:41,032 --> 00:30:42,054
Right?

519
00:30:42,054 --> 00:30:44,286
So, these are, this is f getting smaller,
so

520
00:30:44,286 --> 00:30:48,254
as you, as you go down these level sets
that's f getting smaller and so you're,

521
00:30:48,254 --> 00:30:52,346
the semantics of an optimization problem
is that you want to, you want to move as

522
00:30:52,346 --> 00:30:59,940
far as you can, sort of to the smallest
level curve of f0 while staying in here.

523
00:30:59,940 --> 00:31:03,495
And this, the optimal point is clearly,
it's unique and it's right there.

524
00:31:03,495 --> 00:31:05,460
Right?

525
00:31:05,460 --> 00:31:07,900
One thing you notice that, again just
visually,

526
00:31:07,900 --> 00:31:11,316
it's very easy to show even without it
without appealing to any,

527
00:31:11,316 --> 00:31:14,427
any sort of visual stuff, is visually what
you see is that the,

528
00:31:14,427 --> 00:31:21,480
is that in fact the, the tangent to x is
orthogonal to the gradient there.

529
00:31:21,480 --> 00:31:25,125
Or in other words, the gradient is an
outward normal for x, negative gradient.

530
00:31:25,125 --> 00:31:26,450
Okay?

531
00:31:26,450 --> 00:31:27,740
And so, that's what this says.

532
00:31:27,740 --> 00:31:31,340
This says that the gradient at an optimal
point, here,

533
00:31:31,340 --> 00:31:37,430
defines a supporting hyperplane to the
feasible set at that point.

534
00:31:37,430 --> 00:31:38,158
Right?
So, and

535
00:31:38,158 --> 00:31:41,339
there's some special cases we can do.

536
00:31:41,339 --> 00:31:44,899
Like, for example let's do the case where
it's unconstrained.

537
00:31:46,020 --> 00:31:47,170
So, there are no constraints.

538
00:31:47,170 --> 00:31:48,760
There's no, there's no constraints.

539
00:31:48,760 --> 00:31:50,655
So all feasible y just means all y.

540
00:31:50,655 --> 00:31:55,275
What under what conditions would it be
true that the gradient of f,

541
00:31:55,275 --> 00:32:02,550
0 of x transpose, y minus x, when would
that be bigger than 0 for all y?

542
00:32:05,140 --> 00:32:07,260
Well?
>> I don't know, let's figure it out.

543
00:32:07,260 --> 00:32:07,905
>> [INAUDIBLE] That would work, if the
gradient were identically 0.

544
00:32:07,905 --> 00:32:11,088
In fact, that's, that's the condition.
That's if and only if the gradient is 0.

545
00:32:12,170 --> 00:32:15,680
Why is that?

546
00:32:15,680 --> 00:32:21,759
Well, if the gradient weren't 0, actually
suggest a y.

547
00:32:21,759 --> 00:32:26,995
That ends the story right away.

548
00:32:26,995 --> 00:32:30,450
How about this one?

549
00:32:30,450 --> 00:32:37,990
How about Y equals minus T, times the
gradient F of X, right there.

550
00:32:37,990 --> 00:32:39,490
There you go, OK?

551
00:32:39,490 --> 00:32:43,378
So if I plugged that in, then the first
term Here is minus t,

552
00:32:43,378 --> 00:32:48,420
times the norm square of the gradient.

553
00:32:48,420 --> 00:32:49,670
Now t is a parameter.

554
00:32:49,670 --> 00:32:51,462
I can take it as big as I like, right, and

555
00:32:51,462 --> 00:32:56,690
I will, I can certainly arrange it to be
big enough to make this inequality true.

556
00:32:56,690 --> 00:32:57,190
Right?

557
00:32:59,250 --> 00:33:02,973
Therefore the only option is that that, is
that the gradient itself vanishes and

558
00:33:02,973 --> 00:33:07,400
we have reconstructed the, you know, the
high school condition, right?

559
00:33:07,400 --> 00:33:09,040
The gradient vanishes.

560
00:33:09,040 --> 00:33:14,064
Well it's a little bit different from my
school.

561
00:33:14,064 --> 00:33:15,899
Here's why.

562
00:33:15,899 --> 00:33:19,763
Because here it's a necessary and
sufficient condition, right so,

563
00:33:19,763 --> 00:33:22,960
there's it's a necessary condition.

564
00:33:22,960 --> 00:33:24,793
It's sufficient because of convexity.

565
00:33:24,793 --> 00:33:28,377
OK, so that's, we've reconstructed
gradient equal 0 is the con-, is the nec-,

566
00:33:28,377 --> 00:33:33,012
in this case the necessary and sufficient
condition for optimality.

567
00:33:33,012 --> 00:33:35,870
Okay, how about an equality constrained
problem.

568
00:33:35,870 --> 00:33:38,859
Well here, you want to minimize F 0
subject to AX equals B and

569
00:33:38,859 --> 00:33:43,538
here you can work out the, the conditions
it's not very hard.

570
00:33:43,538 --> 00:33:49,676
But it says X is optimal if and only if
there's a point in the domain where

571
00:33:49,676 --> 00:33:58,590
AX equals B and The gradient of f0, right
plus a transpose nu equals 0.

572
00:33:58,590 --> 00:34:00,869
Now, you should recognize this as
something like a,

573
00:34:00,869 --> 00:34:03,065
this is Lagrange multipliers.

574
00:34:03,065 --> 00:34:06,655
We will talk about this in complete detail
when we talk about duality.

575
00:34:06,655 --> 00:34:09,320
But, that's, so, but it's a hint.

576
00:34:09,320 --> 00:34:12,630
And this comes just from the same the same
argument.

577
00:34:12,630 --> 00:34:15,260
That basically, the argument would go
something like this.

578
00:34:15,260 --> 00:34:19,675
You must have the gradient of F, F zero of
X.

579
00:34:19,675 --> 00:34:22,790
Transposed, Y minus X.

580
00:34:22,790 --> 00:34:30,130
That has to be positive for all Y that
satisfy AX equals B.

581
00:34:30,130 --> 00:34:31,420
Okay?

582
00:34:31,420 --> 00:34:37,090
But wait a minute, because X also
satisfies Ax equals B.

583
00:34:37,090 --> 00:34:41,890
Right so, that says if I take the
difference the difference is between X and

584
00:34:41,890 --> 00:34:45,120
Y is the null space right?

585
00:34:45,120 --> 00:34:49,710
So we can re write it this way we can say
the condition is grad X 0 of X

586
00:34:49,710 --> 00:34:56,805
transpose times Z is positive for all Z in
the null space of A.

587
00:34:56,805 --> 00:34:59,145
Alright because.

588
00:34:59,145 --> 00:35:00,263
If Y satisfies,

589
00:35:00,263 --> 00:35:06,010
AX equals B it's a generally element that
satisfies that right?

590
00:35:06,010 --> 00:35:10,490
And X satisfies AX equals B and we do that
because it's our second assumption here.

591
00:35:10,490 --> 00:35:14,530
Then the differences in the null space of
A and vice versa I should add.

592
00:35:14,530 --> 00:35:15,310
Okay?

593
00:35:15,310 --> 00:35:18,110
This says that the gradient has to make a
non negative.

594
00:35:19,200 --> 00:35:21,140
With every element of the null space.

595
00:35:21,140 --> 00:35:23,956
But the null space is a vector space, so

596
00:35:23,956 --> 00:35:28,630
this couldn't, if this were positive,
right?

597
00:35:28,630 --> 00:35:35,120
If this were positive for some z, minus z
is also in the null space.

598
00:35:35,120 --> 00:35:37,580
And if I plug in minus z, I get something
negative.

599
00:35:37,580 --> 00:35:44,152
So the conclusion here is that in fact,
you have to have grad f0 of x has to be,

600
00:35:44,152 --> 00:35:53,995
it has to have a 0 inner product for all
elements in the null space of A.

601
00:35:53,995 --> 00:35:56,210
OK.

602
00:35:56,210 --> 00:35:57,190
That we can write.

603
00:35:57,190 --> 00:36:02,220
That says graph f of zero of x is n.

604
00:36:02,220 --> 00:36:05,330
The null space of a perk.

605
00:36:05,330 --> 00:36:06,720
I'm just rewriting that's a macro.

606
00:36:06,720 --> 00:36:08,120
That's the definition.

607
00:36:08,120 --> 00:36:11,964
If you make a zero in your product with
everything in a certain set You're in

608
00:36:11,964 --> 00:36:16,700
the perp of that set, the orthogonal
complement, that this.

609
00:36:16,700 --> 00:36:17,428
And this thing,

610
00:36:17,428 --> 00:36:21,300
you'll remember from linear algebra, is
the range of a transpose.

611
00:36:21,300 --> 00:36:31,140
Hey, that says that I can write grad f
zero x as a transpose times something.

612
00:36:32,440 --> 00:36:35,455
And I, and there's something I'm going to
choose, I can write anything I like, but

613
00:36:35,455 --> 00:36:38,715
I'm going to write it as, how about
negative nu, there.

614
00:36:38,715 --> 00:36:39,860
OK?

615
00:36:39,860 --> 00:36:42,180
And I'm done.

616
00:36:42,180 --> 00:36:44,104
Right?
So just using linear algebra, and

617
00:36:44,104 --> 00:36:48,800
the general optimality condition, we
re-covered high school, what is this?

618
00:36:48,800 --> 00:36:52,210
Maybe not high school, okay, Lagrange
multipliers.

619
00:36:52,210 --> 00:36:55,122
Oh except for one very important
difference, this is necessary and

620
00:36:55,122 --> 00:36:56,556
sufficient here.

621
00:36:56,556 --> 00:36:58,123
OK.
Here's a little bit more involved,

622
00:36:58,123 --> 00:37:01,898
I won't go through the derivation but its
minimization over non negative or than.

623
00:37:01,898 --> 00:37:06,110
So you want to minimize f zero of x
subject to x bigger than zero and

624
00:37:06,110 --> 00:37:12,030
if you work out the conditions its Quite
simple, it's this.

625
00:37:12,030 --> 00:37:15,610
X has to be bigger than or equal to 0, but
that, well that's feasibility.

626
00:37:15,610 --> 00:37:21,814
And the followup, whenever xi is 0, the
gradient, here, the partial derivitave

627
00:37:21,814 --> 00:37:29,870
of f0 with respect to xi, has to be bigger
than or equal to 0.

628
00:37:29,870 --> 00:37:32,430
Right, and so you can actually figure out
what that means.

629
00:37:32,430 --> 00:37:37,047
If this number where plus 1, it says that
if you propose to increase xi

630
00:37:37,047 --> 00:37:44,910
a little bit, if you move it a little bit
away, it says that the function goes up.

631
00:37:46,000 --> 00:37:49,430
What you can't have is you couldn't have
this thing negative.

632
00:37:49,430 --> 00:37:51,887
Because that, that would say then if you
move a little bit in that direction,

633
00:37:51,887 --> 00:37:55,155
the function value would go down and you
just got a better point.

634
00:37:55,155 --> 00:37:56,270
Okay?

635
00:37:56,270 --> 00:37:58,416
So I think this is, I mean it's intuitive,
but

636
00:37:58,416 --> 00:38:03,176
you could just, you can work it out
directly from the conditions here.

637
00:38:03,176 --> 00:38:06,806
Well, the condition is very simple read f0
of x transposed y minus x

638
00:38:06,806 --> 00:38:11,666
has to be bigger than or equal to zero for
all feasible y.

639
00:38:11,666 --> 00:38:16,281
Ok, so we've already said a little bit
about equivalent complex problems, and

640
00:38:16,281 --> 00:38:20,487
I'll say actually just a little bit more.

641
00:38:20,487 --> 00:38:25,265
And we'll actually catalog some
interesting typical.

642
00:38:25,265 --> 00:38:27,610
Equivilant pairs of problems, right.

643
00:38:27,610 --> 00:38:30,570
So we'll use an informal notion of
equivilance.

644
00:38:30,570 --> 00:38:33,657
It's not the formal equivilence of
reduction of one problem to another that

645
00:38:33,657 --> 00:38:36,940
you see in computer science, but it could
be made formal but there's no reason for

646
00:38:36,940 --> 00:38:39,083
us to do that.

647
00:38:39,083 --> 00:38:41,903
So the idea is, two problem w-, a problem
it is equiv-,

648
00:38:41,903 --> 00:38:46,103
two problems are equivalent if you can get
the solution, if from the solution of one,

649
00:38:46,103 --> 00:38:52,250
you can get the solution of the other with
modest work, and vice versa.

650
00:38:52,250 --> 00:38:55,102
In other words, what you could do if you
want to think in a very practical way,

651
00:38:55,102 --> 00:38:56,860
you can think of this.

652
00:38:56,860 --> 00:38:58,260
If someone handed you a solver for

653
00:38:58,260 --> 00:39:02,070
one, you could write a wrapper That would
be a solver for the other.

654
00:39:02,070 --> 00:39:04,390
And you have to have wrapper go both
directions.

655
00:39:04,390 --> 00:39:04,980
Okay?

656
00:39:04,980 --> 00:39:07,815
So, in other words, if you say this
problem is equivalent to that, you have to

657
00:39:07,815 --> 00:39:10,740
be able to provide the wrapper that says
give me an instance of this problem and

658
00:39:10,740 --> 00:39:12,855
then, gimme the solution of an instance of
this problem,

659
00:39:12,855 --> 00:39:16,370
I'll get a solution of this problem.

660
00:39:16,370 --> 00:39:16,940
And vice versa.

661
00:39:16,940 --> 00:39:18,220
Okay.

662
00:39:18,220 --> 00:39:20,432
So let's look at some examples.

663
00:39:20,432 --> 00:39:22,778
By the way we're going to use all of these
things, so,

664
00:39:22,778 --> 00:39:27,660
there, there actually we're going to use
them later, there, it's quite important.

665
00:39:27,660 --> 00:39:31,115
So the first observation is this,
eliminating equality constraints.

666
00:39:31,115 --> 00:39:33,850
So the way you do that is this.

667
00:39:33,850 --> 00:39:40,630
You have ax equals b, but we, we know what
all x that satisfy ax equals b looks like.

668
00:39:40,630 --> 00:39:42,223
It's a, that's nothing but a,

669
00:39:42,223 --> 00:39:46,890
an affine set, and we can go to a free
parameter representation.

670
00:39:46,890 --> 00:39:50,985
So pre-parameter representation says we
first find a point that satisfies Ax

671
00:39:50,985 --> 00:39:52,345
equals b.

672
00:39:52,345 --> 00:39:54,475
Oh, let me ask a question.

673
00:39:54,475 --> 00:39:56,587
Suppose on that, that step fails, so I,

674
00:39:56,587 --> 00:40:01,245
I attempt to find a solution of Ax equals
b and there is none.

675
00:40:01,245 --> 00:40:02,489
What do I do?

676
00:40:02,489 --> 00:40:05,310
If Ax equals b has no solution.

677
00:40:05,310 --> 00:40:08,928
I can actually return, like, I can say I
actually don't even, I didn't even look at

678
00:40:08,928 --> 00:40:13,750
F 0 or FI, but I can tell you for sure
that your problem's not feasible.

679
00:40:13,750 --> 00:40:16,850
Because no point satisfies your quality
constraints, okay?

680
00:40:16,850 --> 00:40:20,417
Otherwise you find 1, and you compute a
matrix, F,

681
00:40:20,417 --> 00:40:25,120
whose columns are span The null space of
a.

682
00:40:25,120 --> 00:40:30,840
And the the general solution of Ax=b looks
like this, it's x=fz + x0.

683
00:40:30,840 --> 00:40:33,754
Now normally the columns of f would be
chosen to be independent, but that's

684
00:40:33,754 --> 00:40:38,370
actually totally irrelevant, in which case
they're a basis for the null space of A.

685
00:40:38,370 --> 00:40:44,250
So what it is is you compute Matrices.

686
00:40:44,250 --> 00:40:46,220
A matrix F and a vector x zero.

687
00:40:46,220 --> 00:40:49,540
X zero is by the way called a particular
solution.

688
00:40:49,540 --> 00:40:51,230
And, I don't know what the name is for F.

689
00:40:51,230 --> 00:40:53,600
A basis, basis for the null space or
something.

690
00:40:53,600 --> 00:40:54,910
I don't know.

691
00:40:54,910 --> 00:40:59,312
Anyway, so, that says that the gen, a
general vector x that says A x equals b,

692
00:40:59,312 --> 00:41:04,420
that happens if and only if there exists a
z.

693
00:41:04,420 --> 00:41:07,228
So that x is fz plus x0.

694
00:41:07,228 --> 00:41:08,140
Okay?

695
00:41:08,140 --> 00:41:13,970
I back substitute that and my new problem
looks like, like this here.

696
00:41:13,970 --> 00:41:16,420
And here we make a couple of comments.

697
00:41:16,420 --> 00:41:20,020
First of all, the following is true.

698
00:41:20,020 --> 00:41:21,880
This function is convex in z.

699
00:41:21,880 --> 00:41:27,600
Because it's pre composition of convex
function with an aft line function.

700
00:41:27,600 --> 00:41:30,266
These functions are convex in z for the
same reason.

701
00:41:30,266 --> 00:41:32,012
So, the objective and

702
00:41:32,012 --> 00:41:38,610
the inequality constraints in this
transform problem are convex.

703
00:41:38,610 --> 00:41:39,210
Okay.

704
00:41:39,210 --> 00:41:41,240
Now, no, then.

705
00:41:41,240 --> 00:41:42,065
How would it work,

706
00:41:42,065 --> 00:41:46,915
how would you solve, how would you solve
this problem if you had a solver for that?

707
00:41:46,915 --> 00:41:49,909
Well, I mean it's extremely easy.

708
00:41:49,909 --> 00:41:53,893
You take an instance of this problem, you
compute f and f0,

709
00:41:53,893 --> 00:41:58,080
you solve this problem here.

710
00:41:58,080 --> 00:42:03,170
And then, that gives you Z, and then you
reconstruct X using this formula.

711
00:42:03,170 --> 00:42:04,960
Alright?
So that's, that's the whole,

712
00:42:04,960 --> 00:42:08,300
that's how you transform this, very
simple, right?

713
00:42:08,300 --> 00:42:12,678
Oh, and you can go and and vice versa, so
that's how that works.

714
00:42:12,678 --> 00:42:14,862
oh, but I do want to emphasize, this
problem and

715
00:42:14,862 --> 00:42:19,420
this problem are equivalent, they are
absolutely not the same.

716
00:42:19,420 --> 00:42:22,799
Right.
And so, if we call this prob and prob 2,

717
00:42:22,799 --> 00:42:29,410
then for example if I say prob dot
equality constraints.

718
00:42:29,410 --> 00:42:32,325
Right, and let's suppose that lists the
equality constraints,

719
00:42:32,325 --> 00:42:34,160
what comes back is AX=B.

720
00:42:35,360 --> 00:42:39,300
What happens if I take prop two dot
equality empty.

721
00:42:39,300 --> 00:42:42,340
Yeah an empty list comes back because
there are no equality constraints.

722
00:42:42,340 --> 00:42:46,140
So that tells you for sure those two
problems are not the same.

723
00:42:46,140 --> 00:42:47,880
They are equivalent but not the same.

724
00:42:49,830 --> 00:42:54,017
OK Now, by the way a lot of people think
it's a very naive view,

725
00:42:54,017 --> 00:42:58,570
by the end of the course you'll know why.

726
00:42:58,570 --> 00:43:02,310
It's a very naive view that you should
always eliminate equality constraints.

727
00:43:02,310 --> 00:43:06,900
The naive view is that you should always
do that because look,

728
00:43:06,900 --> 00:43:10,990
this is simpler this thing.

729
00:43:10,990 --> 00:43:11,600
Right?

730
00:43:11,600 --> 00:43:13,650
In fact it has fewer variables, right?

731
00:43:13,650 --> 00:43:16,980
Because if x had dimension 100, and b has
dimension 30,

732
00:43:16,980 --> 00:43:22,360
I'll assume everything is full rank here,
z has dimension 70.

733
00:43:22,360 --> 00:43:23,118
Right?
So, so,

734
00:43:23,118 --> 00:43:25,079
it's, of course you would rather solve
this,

735
00:43:25,079 --> 00:43:27,199
because that's a problem with fewer
variables,

736
00:43:27,199 --> 00:43:31,858
it's got 70 variables as opposed to 100
variables, that's number one.

737
00:43:31,858 --> 00:43:35,394
And number 2, this one doesn't have any
quality constraints so

738
00:43:35,394 --> 00:43:39,990
it's sort of structurally it's simpler,
too.

739
00:43:39,990 --> 00:43:43,122
So you wouldn't imagine there would be any
compelling reason why

740
00:43:43,122 --> 00:43:45,790
you would prefer to solve this one and
we'll see later in

741
00:43:45,790 --> 00:43:51,640
the course there's a very compelling
reason and, in fact, it's the opposite.

742
00:43:51,640 --> 00:43:54,680
In general, you would Almost always prefer
to

743
00:43:54,680 --> 00:43:58,920
solve this because you could always do
this.

744
00:43:58,920 --> 00:44:01,230
If you do that if it were computationally
advantageous.

745
00:44:01,230 --> 00:44:02,171
We'll talk about that later.

746
00:44:02,171 --> 00:44:03,766
So okay, however that that relates to this
the next thing.

747
00:44:03,766 --> 00:44:08,041
You can actually introduce equality
constraints but

748
00:44:08,041 --> 00:44:13,646
some people refer to this as unelimination
So, to eliminate variables

749
00:44:13,646 --> 00:44:21,542
means to take an equality constraint, get
rid of it, and so on.

750
00:44:21,542 --> 00:44:23,216
To introduce equality constraints,

751
00:44:23,216 --> 00:44:26,540
you're actually doing unelimination, it's
the opposite.

752
00:44:26,540 --> 00:44:27,950
So here's an example.

753
00:44:27,950 --> 00:44:30,590
You want to minimize f0 of an affine
function subject to f i

754
00:44:30,590 --> 00:44:34,180
of an affine function, unless they're
equal to 0.

755
00:44:34,180 --> 00:44:37,760
So I just introduce A bunch of, a whole
bunch of new variables, right.

756
00:44:37,760 --> 00:44:40,078
Which are the y zero, y one, up to y m.

757
00:44:40,078 --> 00:44:42,230
And I re-write the problem this way here.

758
00:44:42,230 --> 00:44:46,460
And here's the new problem, right.

759
00:44:46,460 --> 00:44:52,940
And so again, in the niave view, this does
not look like progress, right.

760
00:44:52,940 --> 00:44:55,424
In fact, if you saw this problem you might
immediately,

761
00:44:55,424 --> 00:44:59,670
you might immediately Eliminate the y's
and end up with this thing.

762
00:44:59,670 --> 00:45:00,780
Right?
It doesn't look like

763
00:45:00,780 --> 00:45:02,360
progress because here.

764
00:45:02,360 --> 00:45:04,610
Here's a problem that had no equality
constraints and

765
00:45:04,610 --> 00:45:07,660
you have created from it an equivalent
problem that not only has equality

766
00:45:07,660 --> 00:45:10,520
constraints, it has more variables.

767
00:45:10,520 --> 00:45:13,100
Right?
Because the variables here are x and

768
00:45:13,100 --> 00:45:14,730
y 0 up to ym.

769
00:45:14,730 --> 00:45:16,170
Right?
so it doesn't look like progress.

770
00:45:16,170 --> 00:45:21,410
But, you'll see later, Things like this
actually, of very good things can happen.

771
00:45:21,410 --> 00:45:22,050
Sometimes.

772
00:45:22,050 --> 00:45:23,885
In some context, when you do this.

773
00:45:23,885 --> 00:45:25,630
Okay.

774
00:45:25,630 --> 00:45:30,250
Here's another one, is introducing slack
variables for linear inequality, so

775
00:45:30,250 --> 00:45:32,350
here I want to minimize, say, F0 of X,

776
00:45:32,350 --> 00:45:40,000
subject to linear inequalities Here, and a
very common trick here is the following.

777
00:45:40,000 --> 00:45:43,657
Is I replace these inequalities, linear
inequalities with linear equalities and

778
00:45:43,657 --> 00:45:46,350
I say ai transpose x plus si equals vi.

779
00:45:46,350 --> 00:45:48,876
Right?
So that's an and of course, and

780
00:45:48,876 --> 00:45:52,860
then I simply require si to be positive.

781
00:45:52,860 --> 00:45:55,128
And this is silly because if you look at
this thing,

782
00:45:55,128 --> 00:45:58,840
si is of course vi minus ai transpose x.

783
00:45:58,840 --> 00:46:03,501
So saying, the i transpose x is less than
b i is saying s i is bigger than or

784
00:46:03,501 --> 00:46:05,950
equal to 0.

785
00:46:05,950 --> 00:46:06,499
So, that's it.
So,

786
00:46:06,499 --> 00:46:08,390
what you would say is something like this.

787
00:46:08,390 --> 00:46:11,770
It says that if you can handle linear
equality constraints and

788
00:46:11,770 --> 00:46:17,035
non-negativity, you can handle general
linear inequality constraints.

789
00:46:17,035 --> 00:46:19,540
And this has several implications.

790
00:46:19,540 --> 00:46:22,650
One implication has to do with solvers.

791
00:46:22,650 --> 00:46:24,954
It says that instead of writing a general
purpose solver,

792
00:46:24,954 --> 00:46:28,928
you can really focus on something that
thing are easily transformed to.

793
00:46:28,928 --> 00:46:30,064
Okay.

794
00:46:30,064 --> 00:46:33,452
Another variation has to do with an
epigraph form and

795
00:46:33,452 --> 00:46:38,900
this one looks almost laughable but we'll
take a look at it.

796
00:46:40,540 --> 00:46:44,400
Instead of minimizing F zero vex subject F
Y vex less than zero X equals B.

797
00:46:44,400 --> 00:46:47,480
What we'll do is we'll introduce a single
new variable Called an epigraph variable,

798
00:46:47,480 --> 00:46:49,120
it's a new variable, t.

799
00:46:49,120 --> 00:46:54,125
And we'll simply add a constraint that
says t is bigger than of zero of x.

800
00:46:54,125 --> 00:46:56,160
Okay?

801
00:46:56,160 --> 00:46:58,120
Now I mean this is really dumb, right?

802
00:46:58,120 --> 00:47:00,772
Because look, this constraint, oh which by
the way is convex,

803
00:47:00,772 --> 00:47:03,630
it's convex in xt which are the variables.

804
00:47:03,630 --> 00:47:07,915
Because if zero of x is convex, minus t is
a convex function, it's linear.

805
00:47:07,915 --> 00:47:12,175
So, this function here is convex.

806
00:47:12,175 --> 00:47:13,620
'Kay?

807
00:47:13,620 --> 00:47:15,540
So you look at this, it's kind of dumb,

808
00:47:15,540 --> 00:47:20,490
this constraint here says nothing more
than t is bigger than f0 of x.

809
00:47:20,490 --> 00:47:22,992
T appears nowhere else in the optimization
problem.

810
00:47:22,992 --> 00:47:27,170
Therefor if you fix x and you say what's
the best value of t?

811
00:47:27,170 --> 00:47:31,210
The answer is well its t should equal f
zero of x.

812
00:47:31,210 --> 00:47:32,985
Why?
Because that's the minimum that's

813
00:47:32,985 --> 00:47:36,980
the smallest value t is allowed to go but
the objective is to minimize t.

814
00:47:38,220 --> 00:47:41,940
You could turn this around and say
something like this if someone solve,

815
00:47:41,940 --> 00:47:45,660
you would say something like this, if you
solve this problem Over x and t,

816
00:47:45,660 --> 00:47:50,276
then at the solution, t is equal to f0 of
x.

817
00:47:50,276 --> 00:47:51,112
Peroid.
Right.

818
00:47:51,112 --> 00:47:56,128
If it, if it weren't, then basically the
person who alleged to solve it is a liar.

819
00:47:56,128 --> 00:47:58,256
Right?
So that's, that's the idea.

820
00:47:58,256 --> 00:48:00,536
Now, you might say, this is ridiculous.

821
00:48:00,536 --> 00:48:01,144
Like, what?

822
00:48:01,144 --> 00:48:05,324
But actually, if you take a good look at
this, it's very interesting.

823
00:48:05,324 --> 00:48:10,416
What it says, and some people say it this
way This says, that some people write and

824
00:48:10,416 --> 00:48:18,032
say this, they would say that projective
is universal for convex optimization.

825
00:48:18,032 --> 00:48:22,022
That's what they'd say, cause what that's,
this objective is linear.

826
00:48:22,022 --> 00:48:25,900
I mean, t is a linear function of x comma
t.

827
00:48:25,900 --> 00:48:30,488
So what that says is that if you build a
solver.

828
00:48:30,488 --> 00:48:31,544
For linear objective, and

829
00:48:31,544 --> 00:48:35,400
you can handle, of course you have to be
able to handle the epigraph right?

830
00:48:35,400 --> 00:48:38,206
But if you can handle the epigraph, then
all you have to worry about is, is,

831
00:48:38,206 --> 00:48:40,782
again making a solver that does, that
handles linear objective and

832
00:48:40,782 --> 00:48:45,700
that's going to simplify a whole bunch of
things if you have linear objective.

833
00:48:45,700 --> 00:48:46,300
We'll see later.

834
00:48:46,300 --> 00:48:47,300
But that's it.

835
00:48:47,300 --> 00:48:50,655
So that's why people would say a linear
objective is universal for

836
00:48:50,655 --> 00:48:52,650
convex optimization.

837
00:48:54,890 --> 00:48:57,550
I should say something about these
transformations.

838
00:48:57,550 --> 00:49:00,622
People who do this kind of stuff mostly
know all of these transformations and

839
00:49:00,622 --> 00:49:03,358
they don't tell them, and they're not
written down anywhere -- well,

840
00:49:03,358 --> 00:49:06,286
they're written down on these slides and
in the book and everything -- but

841
00:49:06,286 --> 00:49:10,628
basically, you're just supposed to know
them.

842
00:49:10,628 --> 00:49:11,891
Right.

843
00:49:11,891 --> 00:49:14,560
So, your, and if you don't know these.

844
00:49:14,560 --> 00:49:16,300
So someone would say oh, I need a solver
for this.

845
00:49:16,300 --> 00:49:17,620
Someone would give you something else.

846
00:49:17,620 --> 00:49:22,762
It would actually solve a transformed, an
equivalent version of your problem.

847
00:49:22,762 --> 00:49:25,751
And you'd say, no, no, no, my objective is
something more complicated and

848
00:49:25,751 --> 00:49:28,215
you're just supposed to know this.

849
00:49:28,215 --> 00:49:34,347
Actually, we'll We will see a lot of these
transformations can be automated,

850
00:49:34,347 --> 00:49:38,778
and that's what CVX does it for you.

851
00:49:38,778 --> 00:49:39,870
Okay?

852
00:49:39,870 --> 00:49:42,718
All right, next simple equivalents is

853
00:49:42,718 --> 00:49:47,464
a partial,what's called a partial
minimization.

854
00:49:47,464 --> 00:49:50,638
So partial minimization says you, you have
a problem or

855
00:49:50,638 --> 00:49:54,418
your minimizing f zero Two variables,
right?

856
00:49:54,418 --> 00:49:55,550
X1 and X2, right?

857
00:49:55,550 --> 00:49:57,150
These are block variables, so

858
00:49:57,150 --> 00:50:01,929
I've simply taken X and I've blocked them
into two pieces, X1 and X2.

859
00:50:01,929 --> 00:50:06,950
And subject to say an ineq - a bunch of
inequalities only on the first one.

860
00:50:06,950 --> 00:50:09,515
I mean, and we can have equality
constraints and things, but that's fine.

861
00:50:09,515 --> 00:50:10,960
OK.

862
00:50:10,960 --> 00:50:16,300
Then what it says is, we can roughly
speaking, we can minimize F0 Over x2,

863
00:50:16,300 --> 00:50:20,420
which yields a function of x1.

864
00:50:20,420 --> 00:50:23,180
So I take f tilde of f zero tilde of x1,

865
00:50:23,180 --> 00:50:29,550
right, is this, it's the minimum over x2
of this function.

866
00:50:29,550 --> 00:50:33,738
Now that's convex because convexity is
preserved under partial minimization.

867
00:50:33,738 --> 00:50:36,970
OK and then we have a problem that looks
like this.

868
00:50:36,970 --> 00:50:38,857
By the way if you take a problem with a
big old,

869
00:50:38,857 --> 00:50:41,509
with a big sequence of these instead of
two you have n of them and

870
00:50:41,509 --> 00:50:46,600
you eliminate them one at a time, this is
dynamic programming.

871
00:50:46,600 --> 00:50:48,420
So just you've probably seen this.

872
00:50:48,420 --> 00:50:49,770
So that's just what dynamic programming
is.

873
00:50:49,770 --> 00:50:51,270
Its absolutely nothing more than that.

874
00:50:51,270 --> 00:50:54,390
You want to minimize over a bunch of
variables You know, minimize over 1,

875
00:50:54,390 --> 00:50:57,830
and then the second one, and the third,
and so on.

876
00:50:57,830 --> 00:51:00,350
So that's, it's just something like that.

877
00:51:00,350 --> 00:51:02,750
These right now are all very abstract,
these equivalences.

878
00:51:02,750 --> 00:51:04,863
So they, they probably mean nothing right
now.

879
00:51:04,863 --> 00:51:08,096
But we'll see later either in the context
of applications or

880
00:51:08,096 --> 00:51:11,878
in some other setting where there's a
target that we would say that we could

881
00:51:11,878 --> 00:51:18,580
reduce this thing to, by a transformaton
to this specific named problem.

882
00:51:18,580 --> 00:51:20,390
Then we'll see this will make more sense.

883
00:51:20,390 --> 00:51:26,162
So Quasiconvex Optimization, here
minimizing a quasiconvex

884
00:51:26,162 --> 00:51:32,139
function subject to convex inequalities,
okay?

885
00:51:32,139 --> 00:51:33,771
Now, one thing you have to watch out for

886
00:51:33,771 --> 00:51:38,180
is you can have a locally optimal point
that is not optimal.

887
00:51:38,180 --> 00:51:39,800
In quasi-convex optimization.

888
00:51:39,800 --> 00:51:43,700
So, in this case, that point there is
absolutely; the idea that

889
00:51:43,700 --> 00:51:48,260
the derivative there is 0, it's absolutely
flat.

890
00:51:48,260 --> 00:51:49,943
It is definitely locally optimal.

891
00:51:49,943 --> 00:51:53,059
So, however, it's clearly not optimal
because if

892
00:51:53,059 --> 00:51:57,087
you minimize you might can get something
like that Right, so, so

893
00:51:57,087 --> 00:52:03,786
some things are true for quasi-convex
optimization other things not.

894
00:52:03,786 --> 00:52:07,146
In particular, local optimality does not

895
00:52:07,146 --> 00:52:12,770
imply global optimality a quasi-convex
optimization.

896
00:52:12,770 --> 00:52:14,300
Okay, so how do you solve such problems?

897
00:52:14,300 --> 00:52:17,100
And the typical, the general technique is
this,

898
00:52:17,100 --> 00:52:21,915
If a function is quasi-convex, what you do
is you write it.

899
00:52:21,915 --> 00:52:28,773
in convex functions,

900
00:52:28,773 --> 00:52:32,220
right?

901
00:52:32,220 --> 00:52:36,550
So the idea is you make a function phi t,
phi sub t of x.

902
00:52:36,550 --> 00:52:39,665
It has to be convex in x for each t.

903
00:52:39,665 --> 00:52:46,100
And we arranged that the t sublevel set of
f0 is the zero sublevel set of phi t.

904
00:52:46,100 --> 00:52:48,340
In other words, you have a representation
that looks like this.

905
00:52:48,340 --> 00:52:54,710
So you represent the sublevel set of f0 by
a convex inequality.

906
00:52:54,710 --> 00:52:56,120
That's the idea.

907
00:52:56,120 --> 00:52:59,305
That, that's what I, that's what it, and
by the way you can show abstractly that

908
00:52:59,305 --> 00:53:03,250
for any quasi-convex function, there is a
such a representation.

909
00:53:03,250 --> 00:53:06,310
Frankly, that's not very interesting,
because in any particular case,

910
00:53:06,310 --> 00:53:08,375
there's something simpler.

911
00:53:08,375 --> 00:53:09,600
So here's an example.

912
00:53:09,600 --> 00:53:14,400
Let's take a ratio of a convex over a
concave function Where both are positive

913
00:53:14,400 --> 00:53:21,689
-- well, p is bigger or equal to zero and
q of x is positive on the domain of f0.

914
00:53:21,689 --> 00:53:25,000
That's a quasi-convex function.

915
00:53:25,000 --> 00:53:26,190
How do you check that?

916
00:53:26,190 --> 00:53:30,590
Well, what you want to do is figure out is
the set of x such that f0 of x

917
00:53:30,590 --> 00:53:34,140
is less than t.

918
00:53:34,140 --> 00:53:35,310
Is that thing convex?

919
00:53:35,310 --> 00:53:41,135
Now if T is negative, it's convex because
that is is what?

920
00:53:41,135 --> 00:53:45,650
It's the empty set, right?

921
00:53:45,650 --> 00:53:47,860
So this is the empty set which is convex.

922
00:53:47,860 --> 00:53:51,560
If T is positive then I'm going to
substitute for F0 P over Q so

923
00:53:51,560 --> 00:53:55,852
this is just P of F over Q of X is less
than or equal to T Q is positive So

924
00:53:55,852 --> 00:53:59,774
therefore, I can multiply through this
linear inequality, and

925
00:53:59,774 --> 00:54:07,726
I can write that as P of X, minus T Q of X
is less than 0.

926
00:54:07,726 --> 00:54:09,634
I'm done.

927
00:54:09,634 --> 00:54:13,020
Because that is a convex function.

928
00:54:13,020 --> 00:54:17,190
P is convex, Q is concave.

929
00:54:17,190 --> 00:54:21,887
T, with T positive, which is our
assumption now Is non-negative so t, q, x,

930
00:54:21,887 --> 00:54:25,408
t times q is going to be concave.

931
00:54:25,408 --> 00:54:28,350
Minus, switches conves and concave.

932
00:54:28,350 --> 00:54:29,810
Sum of convex is convex.

933
00:54:29,810 --> 00:54:32,300
This function is convex.

934
00:54:32,300 --> 00:54:33,019
Okay?
So,

935
00:54:33,019 --> 00:54:36,594
that, this would be the representation.

936
00:54:36,594 --> 00:54:38,854
This would be the fi t of x.

937
00:54:38,854 --> 00:54:43,380
Notice that it is not convex in x and t
jointly.

938
00:54:43,380 --> 00:54:48,130
But for any fixed t, which is bigger or
equal to zero, this is a convex function.

939
00:54:48,130 --> 00:54:50,745
And the sublevel said gives you the
sublevels out of f zero.

940
00:54:50,745 --> 00:54:52,330
So, that's the idea.

941
00:54:52,330 --> 00:54:54,725
Okay, so, what do you do with that?

942
00:54:54,725 --> 00:54:56,990
Well the idea is very simple.

943
00:54:56,990 --> 00:55:03,030
This says that we have a convex
representation of a su, of a sublevel set.

944
00:55:03,030 --> 00:55:07,810
And what we'll do is we'll just vary t and
check feasibility of the convex problem.

945
00:55:07,810 --> 00:55:09,150
So that's all you need to do.

946
00:55:09,150 --> 00:55:10,461
SO here it is.
If you want to do

947
00:55:10,461 --> 00:55:14,245
quazi convex optimization, it works like
this.

948
00:55:14,245 --> 00:55:17,205
We'll take, the, what we'll do is this is,

949
00:55:17,205 --> 00:55:23,460
this is the, this is the, part that
describes the sublevel set.

950
00:55:23,460 --> 00:55:27,610
The t sublevel set of the object, the
original objective 0.

951
00:55:27,610 --> 00:55:28,882
And so what we'll do is we'll,

952
00:55:28,882 --> 00:55:33,060
we'll choose, we'll a target, we'll, what
we'll do is we'll guess a t.

953
00:55:34,270 --> 00:55:36,480
We'll solve this convex feasibility
problem.

954
00:55:36,480 --> 00:55:40,030
If that feasibility problem is, well, if
it's feasible.

955
00:55:40,030 --> 00:55:41,740
Right?
If the result is feasible,

956
00:55:41,740 --> 00:55:45,460
then we have found an x [COUGH] that
satisfies all the constraints here and

957
00:55:45,460 --> 00:55:51,520
this because it satisfies this that means
F zero of X is less than or equal to T.

958
00:55:53,310 --> 00:55:56,590
If this is infeasible then we know the
following.

959
00:55:56,590 --> 00:56:00,010
We know that there is no X that satisfies
all of these constraints and

960
00:56:00,010 --> 00:56:02,540
has F zero of X less than T.

961
00:56:02,540 --> 00:56:04,058
And that tells us instantly that P star,

962
00:56:04,058 --> 00:56:07,200
the optimal value of the original problem
is bigger than T.

963
00:56:09,410 --> 00:56:10,680
I'm being informal.

964
00:56:10,680 --> 00:56:11,555
Okay?
So, if you want to do

965
00:56:11,555 --> 00:56:14,510
the careful analysis you can look in the
book or something like that.

966
00:56:14,510 --> 00:56:15,889
But I'm, I'm being informal here.

967
00:56:15,889 --> 00:56:20,020
It's actually says it's bigger than or
equal to p star.

968
00:56:20,020 --> 00:56:23,900
And if it's infeasable it says p star is
bigger than t.

969
00:56:23,900 --> 00:56:26,470
And so now you simply use the bisection
method.

970
00:56:26,470 --> 00:56:28,810
So the bisection method goes like this.

971
00:56:28,810 --> 00:56:30,526
You start with an upper and

972
00:56:30,526 --> 00:56:36,110
lower bound on possible values of the, of
the of p star here.

973
00:56:36,110 --> 00:56:38,350
You start with these upper and lower
bounds, and

974
00:56:38,350 --> 00:56:42,730
then you, you take you have an interval
lu, that contains p star.

975
00:56:42,730 --> 00:56:47,440
And you simply evaluate [COUGH] you check.

976
00:56:47,440 --> 00:56:50,340
For t, for t in the middle of that
interval and it's either feasible or not.

977
00:56:50,340 --> 00:56:53,450
And either way your interval goes down by
a factor of two.

978
00:56:53,450 --> 00:56:57,392
Okay, and this tells you that it takes you
know, exactly U minus L,

979
00:56:57,392 --> 00:57:01,580
that's your initial uncertainty in p-star.

980
00:57:01,580 --> 00:57:04,651
It takes exactly that Log 2 of that
divided by

981
00:57:04,651 --> 00:57:11,280
epsilon iterations to Converge to within
epsilon of p star.

982
00:57:11,280 --> 00:57:11,960
Right?
And in fact,

983
00:57:11,960 --> 00:57:14,188
when you terminate, here's what you'll
have.

984
00:57:14,188 --> 00:57:16,120
You'll have some very interesting things.

985
00:57:16,120 --> 00:57:17,560
You'll actually have a certificate.

986
00:57:17,560 --> 00:57:19,716
What you'll have is you'll have an x
that'll satisfy,

987
00:57:19,716 --> 00:57:22,607
it depends on the last iteration, if the
last iteration was, let's say,

988
00:57:22,607 --> 00:57:25,498
feasible You'll have an x [COUGH] with a
sublevel set where you'll,

989
00:57:25,498 --> 00:57:30,330
you'll have an x that's feasible and has
f0 of x less than t.

990
00:57:30,330 --> 00:57:32,490
That's, that's the final value of t.

991
00:57:32,490 --> 00:57:36,090
But you'll have a slightly smaller t.

992
00:57:36,090 --> 00:57:40,311
Epsilon smaller, less than epsilon smaller
t where you, you, you've solved this

993
00:57:40,311 --> 00:57:45,290
convex feas- infeasibility problem, and
found it to be infeasible.

994
00:57:45,290 --> 00:57:47,280
And so that constitutes a proof.

995
00:57:47,280 --> 00:57:49,820
That f0 could not be less than your t
minus epsilon.

996
00:57:49,820 --> 00:57:51,410
And so that's what you end up with.

997
00:57:51,410 --> 00:57:53,114
So that's how you solve a quasi convex
problem.

998
00:57:53,114 --> 00:58:02,876
Okay, what we're going to do now is we're
going to talk about problem families.

999
00:58:02,876 --> 00:58:04,130
With names.

1000
00:58:04,130 --> 00:58:06,100
Night, so we do this for a couple of
reasons.

1001
00:58:06,100 --> 00:58:09,700
One is historical and in fact it actually
has less and less value as we

1002
00:58:09,700 --> 00:58:13,780
move forward cause things like CVX will
automate a lot of the transformations for

1003
00:58:13,780 --> 00:58:19,844
you but for various reasons you should
know these problem classes.

1004
00:58:19,844 --> 00:58:22,802
You can also know them because there'd be
special solvers for

1005
00:58:22,802 --> 00:58:24,426
each of these classes right so for

1006
00:58:24,426 --> 00:58:30,430
many reasons historical if none other You
need to know about these problem classes.

1007
00:58:30,430 --> 00:58:33,020
Okay, and will start with linear program,

1008
00:58:33,020 --> 00:58:39,780
in some sense it is the simplest possible
general convex optimization problem.

1009
00:58:39,780 --> 00:58:42,500
General in the sense of having constrains
and other things.

1010
00:58:42,500 --> 00:58:45,696
So it says all functions are Fi.

1011
00:58:45,696 --> 00:58:48,420
F0 and all FI.

1012
00:58:48,420 --> 00:58:50,970
And in that case, that says you minimize
an affine function,

1013
00:58:50,970 --> 00:58:55,280
subject to linear inequality constraints,
well, affine but we say linear.

1014
00:58:55,280 --> 00:58:57,500
And linear equality constraints.

1015
00:58:57,500 --> 00:58:59,430
So that, that's a linear program.

1016
00:58:59,430 --> 00:59:05,150
Now, there's some silly things here, for
example this D is a constant.

1017
00:59:05,150 --> 00:59:07,220
And so, you don't really need it, right.

1018
00:59:07,220 --> 00:59:10,761
You could remove it, it, a d does not
affect the solution.

1019
00:59:10,761 --> 00:59:14,352
And in effect the way you write something
without the d, you don't need the d,

1020
00:59:14,352 --> 00:59:16,290
is you strip the d off, solve the problem,

1021
00:59:16,290 --> 00:59:22,565
add d back in to b star when you return,
the solution to the, to this problem.

1022
00:59:22,565 --> 00:59:23,641
Okay.

1023
00:59:24,810 --> 00:59:26,820
Now that's a, what's a convex problem.

1024
00:59:26,820 --> 00:59:28,986
And the feasible set [COUGH] is a
polyhedron,

1025
00:59:28,986 --> 00:59:33,790
because it's defined by linear equality
constraints and linear inequalities.

1026
00:59:33,790 --> 00:59:35,334
That's a, that's a polyhedron.

1027
00:59:35,334 --> 00:59:40,254
So this is a picture in r2, so, it's a
picture in r2 and You know here each of

1028
00:59:40,254 --> 00:59:48,000
these, this each of these is one is a row
of g h less than or equal to h.

1029
00:59:48,000 --> 00:59:49,160
That's what each of these is.

1030
00:59:49,160 --> 00:59:53,120
This is a problem with at least one, two,
three, four, five, six constraints and

1031
00:59:53,120 --> 00:59:56,390
c points in this direction.

1032
00:59:56,390 --> 00:59:58,964
Therefore minus c points in that direction
and

1033
00:59:58,964 --> 01:00:04,910
the semantics of optimization is Please
move as far as you can in this direction.

1034
01:00:06,470 --> 01:00:07,820
Right, while staying feasible.

1035
01:00:07,820 --> 01:00:10,450
And so there's, there's, the optimal
point.

1036
01:00:10,450 --> 01:00:12,120
In this case it turns out to be unique.

1037
01:00:12,120 --> 01:00:13,200
Right, so that's a linear program.

1038
01:00:13,200 --> 01:00:19,874
So, the picture here is simple you [COUGH]
obviously do not need any, anything

1039
01:00:19,874 --> 01:00:28,876
to solve convex optimization linear
programming problems with two variables.

1040
01:00:28,876 --> 01:00:30,162
Right?

1041
01:00:30,162 --> 01:00:33,230
So the I mean, it's good to draw it this
way.

1042
01:00:33,230 --> 01:00:34,029
That's fine.

1043
01:00:34,029 --> 01:00:36,519
But you should understand that, and

1044
01:00:36,519 --> 01:00:41,290
you can pretend to visualize a polyhedron
in r100.

1045
01:00:41,290 --> 01:00:42,900
You should at least pretend to.

1046
01:00:42,900 --> 01:00:45,260
I mean, and you know generally what it's
going to look like.

1047
01:00:45,260 --> 01:00:46,548
You know it's going to look like the,

1048
01:00:46,548 --> 01:00:49,750
the surfaces are going to be like hyper
planes and are 100.

1049
01:00:49,750 --> 01:00:52,500
And they'll be edges and there'll be
corners and points.

1050
01:00:52,500 --> 01:00:55,335
They're like vertices right but you know
we should all

1051
01:00:55,335 --> 01:01:00,080
really understand they were all faking
when they did that right?

1052
01:01:00,080 --> 01:01:05,876
Because if you take you take a polyhedron
with you know with a hundred variables And

1053
01:01:05,876 --> 01:01:11,150
50 linear inequalities, something like
that.

1054
01:01:11,150 --> 01:01:13,550
You have something, the number of vertices
the,

1055
01:01:13,550 --> 01:01:18,060
the number of edge, you know points like
this is exponential.

1056
01:01:18,060 --> 01:01:21,400
And would be for a problem that size
extremely large, right?

1057
01:01:21,400 --> 01:01:25,530
[COUGH] So, but it's still useful to
pretend that we can visualize.

1058
01:01:25,530 --> 01:01:26,754
So, it looks something like that.

1059
01:01:26,754 --> 01:01:29,824
Okay.
That's a linear program.

1060
01:01:29,824 --> 01:01:33,040
Now, what's important about linear
programming, well it's a convex problem.

1061
01:01:33,040 --> 01:01:36,380
It can be solved unbelievably well, right?

1062
01:01:36,380 --> 01:01:38,750
So, this is basically a completely mature
technology.

1063
01:01:38,750 --> 01:01:40,960
THis has been done like very well since
1948.

1064
01:01:40,960 --> 01:01:45,340
And so, if you have a linear program with
a couple thousand variables and

1065
01:01:45,340 --> 01:01:48,490
a bunch of constraints.

1066
01:01:48,490 --> 01:01:52,089
It's just that something you could solve,
I mean, depends on the number of

1067
01:01:52,089 --> 01:01:55,511
constraints and sparsity patterns and
things, but you can solve that

1068
01:01:55,511 --> 01:02:01,650
extremely fast, and with total reliability
on small things, very quickly, Okay?

1069
01:02:01,650 --> 01:02:05,580
So that, that's why you would want to know
about this.

1070
01:02:05,580 --> 01:02:06,675
So that's linear programming.

1071
01:02:06,675 --> 01:02:08,930
Okay.

1072
01:02:08,930 --> 01:02:09,940
So let's look at some examples.

1073
01:02:09,940 --> 01:02:11,380
And the first one is historical.

1074
01:02:11,380 --> 01:02:13,185
So it goes back, well, to 1948.

1075
01:02:13,185 --> 01:02:17,950
And so we're doing it just because, you
know, it's historical.

1076
01:02:17,950 --> 01:02:18,985
And here it is.

1077
01:02:18,985 --> 01:02:21,540
So the original problem was something like
this.

1078
01:02:21,540 --> 01:02:26,745
It says you want to choose quaniitites x
one through x n of n foods.

1079
01:02:26,745 --> 01:02:32,270
OK so these are the variables and your
going to make a diet out of these.

1080
01:02:32,270 --> 01:02:33,386
Right?
So it'll be a hundred,

1081
01:02:33,386 --> 01:02:37,485
three grams of this, fifty grams of this,
you know zero grams of that, something.

1082
01:02:37,485 --> 01:02:40,580
And one unit of food, let's say a gram,
costs cj.

1083
01:02:40,580 --> 01:02:46,400
And it has a nutrient amount aij.

1084
01:02:46,400 --> 01:02:50,630
Like for example, you know, nutrient one
could be protein.

1085
01:02:50,630 --> 01:02:52,853
Right, so this tells you that a gram of
this has,

1086
01:02:52,853 --> 01:02:56,210
you know, a third of a gram, 300 mg of
protein.

1087
01:02:56,210 --> 01:02:59,270
It doesn't matter, you know, nutrient two
can be a vitamin.

1088
01:02:59,270 --> 01:03:00,660
I mean, it doesn't matter.

1089
01:03:00,660 --> 01:03:01,545
You get the idea.

1090
01:03:01,545 --> 01:03:06,649
Okay, and so the idea is your going to
construct a diet which is a combi,

1091
01:03:06,649 --> 01:03:11,150
which is a mixture of these foods.

1092
01:03:11,150 --> 01:03:14,460
By the way no one, you're not supposed to
visualize this.

1093
01:03:14,460 --> 01:03:16,580
Like putting these things in a blender or
something.

1094
01:03:16,580 --> 01:03:18,650
Cause you'd come up with some brown goop
or something.

1095
01:03:18,650 --> 01:03:21,750
Anyway, so, it's not suppose to be
appetizing.

1096
01:03:21,750 --> 01:03:25,460
That's a, yeah, I guess to make it
appetizing that's a nonconvex constraint.

1097
01:03:25,460 --> 01:03:27,437
But we'll, we'll talk about that later.

1098
01:03:27,437 --> 01:03:31,985
okay, so what you want to do is find the
cheapest of healthy diet.

1099
01:03:31,985 --> 01:03:35,425
So in this case you'd minimize the
transposed x,

1100
01:03:35,425 --> 01:03:40,843
that is of course the total cost, and
subject to ax bigger than b that says

1101
01:03:40,843 --> 01:03:50,810
that you have here ax is a vector that
gives you a list of the nutrient amounts.

1102
01:03:50,810 --> 01:03:54,398
There so for example entry one in AX would
be the total protien,

1103
01:03:54,398 --> 01:03:58,952
say the next one is vitamin B entry two of
AX would be the amount of Vitamin B or

1104
01:03:58,952 --> 01:04:03,084
something like that okay?

1105
01:04:03,084 --> 01:04:08,731
And, then B here is the minimum allowed
Level of that nutrient, okay?

1106
01:04:08,731 --> 01:04:11,806
Oh, and this is rather important, we have
to have,

1107
01:04:11,806 --> 01:04:16,080
we only allowed to do non-negative
quantities.

1108
01:04:16,080 --> 01:04:18,684
Right, so again you can't do negative
quantities,

1109
01:04:18,684 --> 01:04:22,524
you can't go short as you might in finance
on a diet.

1110
01:04:22,524 --> 01:04:25,410
I mean Let's not go there, actually.

1111
01:04:25,410 --> 01:04:26,640
Okay.
We'll just, we'll leave it there.

1112
01:04:26,640 --> 01:04:27,280
But.

1113
01:04:27,280 --> 01:04:28,520
Okay.

1114
01:04:28,520 --> 01:04:29,330
Okay.

1115
01:04:29,330 --> 01:04:30,120
So that's the problem.

1116
01:04:30,120 --> 01:04:37,350
Oh, and here, this problem is still not
quite in our standard form.

1117
01:04:37,350 --> 01:04:37,851
Right?
But

1118
01:04:37,851 --> 01:04:40,870
this is the kind of thing you get used to,
people get used to.

1119
01:04:40,870 --> 01:04:41,470
They don't do it.

1120
01:04:41,470 --> 01:04:44,930
So let's go ahead and put this Fully in
our standard form.

1121
01:04:44,930 --> 01:04:46,470
I'll do it once and then maybe never
again.

1122
01:04:46,470 --> 01:04:50,360
Here it is; You would rewirte it this way.

1123
01:04:50,360 --> 01:04:56,160
Minimize, c transpose x and let's just go
all the way, plus 0.

1124
01:04:56,160 --> 01:04:59,410
[COUGH] So 0 is the d decomponent.

1125
01:04:59,410 --> 01:05:02,852
And now we have to write these as a set of
Linear inequalities.

1126
01:05:02,852 --> 01:05:03,445
Right?

1127
01:05:03,445 --> 01:05:07,735
So we'll write it this way, oh, and the
linear inequalities, you know, like all

1128
01:05:07,735 --> 01:05:12,157
inequalities our standard is that it's
less than or equal to, so I'll rewrite

1129
01:05:12,157 --> 01:05:19,500
this as minus ax I guess I'm allowed to
write it in this case like that, right?

1130
01:05:19,500 --> 01:05:24,300
I could go Ax minus B is less than or
equal to 0, like that and

1131
01:05:24,300 --> 01:05:31,833
then I can write minus X is less than or
equal to 0, right?

1132
01:05:31,833 --> 01:05:33,881
And I'm still not done.

1133
01:05:33,881 --> 01:05:37,094
I mean this is kind of goofy but let's
just do the last step and then we're, and

1134
01:05:37,094 --> 01:05:39,650
then we'll quit on this problem.

1135
01:05:39,650 --> 01:05:44,630
So, the last step is I would write that
whole thing together as minus A and

1136
01:05:44,630 --> 01:05:51,790
I times plus, or however we're, however,
it doesn't really matter.

1137
01:05:51,790 --> 01:05:54,790
Minus B 0, there.

1138
01:05:54,790 --> 01:05:56,470
There we go.
Okay, so there we go.

1139
01:05:56,470 --> 01:05:59,694
That's the official C, that's D, I forget
what that is, maybe G,

1140
01:05:59,694 --> 01:06:02,560
and maybe that's H or something.

1141
01:06:02,560 --> 01:06:04,260
And we have it in our canonical form.

1142
01:06:04,260 --> 01:06:07,362
So things like this, people don't even say
that, they just say, that's an LP, and

1143
01:06:07,362 --> 01:06:10,396
then they, it's your problem to switch
around.

1144
01:06:10,396 --> 01:06:11,821
Okay.

1145
01:06:11,821 --> 01:06:15,170
Next problem is quite.

1146
01:06:15,170 --> 01:06:16,066
This one is only for

1147
01:06:16,066 --> 01:06:20,050
historical I mean that's the only reason
we mention it, right.

1148
01:06:20,050 --> 01:06:23,190
Although, actually, it turns out an LP
like this.

1149
01:06:23,190 --> 01:06:25,527
I mean, something like a diet problemer's,
it's,

1150
01:06:25,527 --> 01:06:30,380
actual, I mean is modern versions of it
that are quite real, quite practical.

1151
01:06:30,380 --> 01:06:32,550
Eh, so one example.

1152
01:06:32,550 --> 01:06:33,995
Would be something like this.

1153
01:06:33,995 --> 01:06:38,880
Uhm, [COUGH], you should say that, you've
contract.

1154
01:06:38,880 --> 01:06:41,050
These would, these would represent
contracts.

1155
01:06:41,050 --> 01:06:45,170
X is the amount of effort you put into
some, job, or something like that.

1156
01:06:45,170 --> 01:06:48,530
And then you might want to do something
like minimize the cost.

1157
01:06:48,530 --> 01:06:51,237
Of complying with a bunch of contracts,
and it would be the same.

1158
01:06:51,237 --> 01:06:52,686
By the way, you cannot s-,

1159
01:06:52,686 --> 01:06:56,826
you really can't solve these problems by
hand if there's like more than,

1160
01:06:56,826 --> 01:07:04,190
if there's like you know, more than 20, 30
foods, and four or five nutrients.

1161
01:07:04,190 --> 01:07:06,990
I mean, you really cannot do it, I mean,
well, you could do it.

1162
01:07:06,990 --> 01:07:10,110
And in fact, I guess, in the 50s, 60s,
70s, and even 80s, maybe even 90s

1163
01:07:10,110 --> 01:07:13,698
students were tortured with With actually
solving things like this by hand, and

1164
01:07:13,698 --> 01:07:16,980
I'm not kidding.

1165
01:07:16,980 --> 01:07:22,150
That probably goes on now at some places,
possibly even here.

1166
01:07:22,150 --> 01:07:22,802
I'm not sure.
But

1167
01:07:22,802 --> 01:07:26,320
anyway, of course that's completely silly.

1168
01:07:26,320 --> 01:07:29,510
But the point is, you can actually solve
these by hand if it's tiny, but

1169
01:07:29,510 --> 01:07:32,940
even it's just small, you can't do it by
hand.

1170
01:07:32,940 --> 01:07:33,820
Anyway, it's silly.

1171
01:07:33,820 --> 01:07:34,796
You shouldn't.
Okay.

1172
01:07:34,796 --> 01:07:41,422
Next one we're going to look at is a
piecewise-linear minimization.

1173
01:07:41,422 --> 01:07:45,850
Alright, so there you want to minimize a
function which is piecewise-linear.

1174
01:07:45,850 --> 01:07:48,330
It is the maximum of a bunch of afine
functions.

1175
01:07:48,330 --> 01:07:51,188
So it looks something like this.

1176
01:07:51,188 --> 01:07:53,745
This This objective function here.

1177
01:07:53,745 --> 01:07:57,330
It's, you have a bunch of functions like
that.

1178
01:07:57,330 --> 01:08:00,711
These are affine functions and the minimum
is that piece-wise linear function and

1179
01:08:00,711 --> 01:08:03,310
you want to find a minimum of it, okay?

1180
01:08:03,310 --> 01:08:06,388
Now I want to first mention a couple of
things.

1181
01:08:06,388 --> 01:08:11,880
The first is that does not look an lp.

1182
01:08:11,880 --> 01:08:14,142
Right when yo look at this problem,

1183
01:08:14,142 --> 01:08:20,440
the objective, the whoel point of an LP is
that it's objective is linear.

1184
01:08:21,480 --> 01:08:23,970
This objective is highly non-linear.

1185
01:08:23,970 --> 01:08:26,473
There we've got a problem right there.

1186
01:08:26,473 --> 01:08:30,320
So if you ask is this an LP the answer is
it absolutely is not.

1187
01:08:30,320 --> 01:08:31,240
It's not an LP.

1188
01:08:32,550 --> 01:08:35,220
So, that's a that's, that's the first
thing you'd rem-.

1189
01:08:35,220 --> 01:08:40,257
Now, I should mention something else
you've already seen this idea that there's

1190
01:08:40,257 --> 01:08:47,138
a very easy way to create a piece wise
linear approximation of a convex function.

1191
01:08:47,138 --> 01:08:49,254
You would evaluate if it's differential,
for example,

1192
01:08:49,254 --> 01:08:53,351
you evaluate its gradient at a bunch of
places that gives you a lower bound.

1193
01:08:53,351 --> 01:08:56,980
You take the maximum of it that's still a
lower bound and it's a good approximation.

1194
01:08:56,980 --> 01:08:57,970
Everybody got that?

1195
01:08:57,970 --> 01:09:04,530
So, this is actually a cheap and dirty way
to solve a convex optimization problem.

1196
01:09:04,530 --> 01:09:05,893
You have some F zero.

1197
01:09:05,893 --> 01:09:09,070
You know you don't have any other way to
do it.

1198
01:09:09,070 --> 01:09:11,630
You evaluate its gradient or draw some
pictures.

1199
01:09:11,630 --> 01:09:14,552
but in any case you get a piecewise-linear
approximation of it.

1200
01:09:14,552 --> 01:09:19,620
And then you will see we transfer this to
an LP and solve it, okay?

1201
01:09:19,620 --> 01:09:20,660
So, here it is as an LP.

1202
01:09:20,660 --> 01:09:24,370
It's just that it's nothing but the
epigraph representation.

1203
01:09:24,370 --> 01:09:25,550
Introduce a new variable.

1204
01:09:25,550 --> 01:09:27,300
This is an LP, right?

1205
01:09:27,300 --> 01:09:32,030
So, that's what it, cause here you're
minimizing a linear function.

1206
01:09:32,030 --> 01:09:34,530
t is the linear function of xt.

1207
01:09:34,530 --> 01:09:36,790
Subject to these are linear inequalites.

1208
01:09:36,790 --> 01:09:39,779
Now again you know to get this exactly
right you'd put the t on the left hand

1209
01:09:39,779 --> 01:09:42,190
side and all this sort of stuff.

1210
01:09:42,190 --> 01:09:44,504
We're not going to do that oh and

1211
01:09:44,504 --> 01:09:49,530
most people they would actually call that
an LP.

1212
01:09:50,650 --> 01:09:52,050
Well some people would.

1213
01:09:52,050 --> 01:09:52,780
A lot of people would.

1214
01:09:52,780 --> 01:09:53,464
If, people who have to

1215
01:09:53,464 --> 01:09:56,345
deal with piecewise-linear minimization
they would say that's an LP.

1216
01:09:56,345 --> 01:10:00,040
And that's slang, it's informal.

1217
01:10:00,040 --> 01:10:06,640
And what it means is this problem is
equivalent to an LP.

1218
01:10:06,640 --> 01:10:08,740
And, and the practical implication is
enormous.

1219
01:10:08,740 --> 01:10:14,480
It says basically, since LP solvers are
extremely reliable, extremely efficient.

1220
01:10:14,480 --> 01:10:16,450
It says basically, we can solve that
problem.

1221
01:10:17,580 --> 01:10:19,008
That's the practical implication of it,

1222
01:10:19,008 --> 01:10:22,285
I mean a theoretical implications as well
but that's the practical one.

1223
01:10:22,285 --> 01:10:24,800
Okay.

1224
01:10:24,800 --> 01:10:26,872
So our next example of a linear programmer
or

1225
01:10:26,872 --> 01:10:30,008
I should say a problem that can be
transformed to a linear program is

1226
01:10:30,008 --> 01:10:34,360
the problem of the Chebyshev center of a
polyhedron.

1227
01:10:34,360 --> 01:10:35,585
So what is it?

1228
01:10:35,585 --> 01:10:40,300
Well, I have a polyhedron, so that's a,
defined by a set of linear inequalities.

1229
01:10:40,300 --> 01:10:44,320
So that's, that's, here's the linear
inequalities and here's my polyhedron.

1230
01:10:44,320 --> 01:10:47,978
And what you want the Chebyshev center of
this is defined to be the center of

1231
01:10:47,978 --> 01:10:50,995
the largest ball that fits inside.

1232
01:10:50,995 --> 01:10:53,655
Okay, so that's this point here.

1233
01:10:53,655 --> 01:10:55,627
Right?

1234
01:10:55,627 --> 01:10:58,439
In this case, that's the Chebyshev center.

1235
01:10:58,439 --> 01:11:01,488
So you really want to choose the center
and maximize r.

1236
01:11:01,488 --> 01:11:04,490
Subject to the constraint that the ball
fits inside.

1237
01:11:04,490 --> 01:11:08,057
Now actually, before we go on, I want to
mention a couple things about this.

1238
01:11:08,057 --> 01:11:09,233
The first thing is this.

1239
01:11:09,233 --> 01:11:13,713
The problem clearly has applications
immediately cause basically whats it

1240
01:11:13,713 --> 01:11:16,443
saying is another way to say this by the
way is to

1241
01:11:16,443 --> 01:11:23,030
say find the point inside the set that is
deepest inside it.

1242
01:11:23,030 --> 01:11:25,490
Has the largest distance to the outside.

1243
01:11:25,490 --> 01:11:29,711
So in other words if you were going to
target for a manufacturing process And

1244
01:11:29,711 --> 01:11:34,334
these constraints define the acceptable
region, and you wanted to have margin, so

1245
01:11:34,334 --> 01:11:38,421
that if during the margin, manufacturing
process, things varied and

1246
01:11:38,421 --> 01:11:45,749
you wanted the highest margin you would
choose the Chebyshev center.

1247
01:11:45,749 --> 01:11:46,313
Okay?

1248
01:11:46,313 --> 01:11:48,472
[COUGH].
So this is already a problem,

1249
01:11:48,472 --> 01:11:50,771
that has applications.

1250
01:11:51,790 --> 01:11:55,023
Now the second is before we get into it I
want to point something out.

1251
01:11:55,023 --> 01:11:59,049
When you think about a linear program, the
whole point about a linear program is

1252
01:11:59,049 --> 01:12:03,710
that all the functions that define it are
Affine.

1253
01:12:03,710 --> 01:12:06,552
And so what should light up in your brain,
is, is, things, or

1254
01:12:06,552 --> 01:12:10,715
the pictures you should see in your mind,
are flat things.

1255
01:12:10,715 --> 01:12:16,763
Hyperplanes possibly with edges right,
because we have mul,

1256
01:12:16,763 --> 01:12:21,691
we have inequalities and that would define
edges but

1257
01:12:21,691 --> 01:12:27,291
you should That is not, I can tell you
there are a lot of things

1258
01:12:27,291 --> 01:12:32,667
you can say about a Euclidean about a ball
and a two nor but,

1259
01:12:32,667 --> 01:12:38,043
generally speaking, if something writes
down a two norm,

1260
01:12:38,043 --> 01:12:47,210
you're not talking flat.

1261
01:12:47,210 --> 01:12:47,970
Right?

1262
01:12:47,970 --> 01:12:51,020
[COUGH] That's almost the canonical
definition of curved.

1263
01:12:51,020 --> 01:12:54,028
So, if someone writes down a ball, and
someone walks up to you on the street and

1264
01:12:54,028 --> 01:12:56,566
says I have a problem, and the first thing
they say is if they talk,

1265
01:12:56,566 --> 01:12:59,433
if they use the word Euclidean ball It's
probab, you would just think, now

1266
01:12:59,433 --> 01:13:05,380
that doesn't sound right because linear
programs pertain to thins that are flat.

1267
01:13:05,380 --> 01:13:10,436
So, all I'm trying to do is set you up to
say that this doesn't sound like This is

1268
01:13:10,436 --> 01:13:15,700
going to end up as an example of a linear
program.

1269
01:13:15,700 --> 01:13:18,700
Obviously it is, otherwise it wouldn't be
in the lecture here.

1270
01:13:18,700 --> 01:13:22,396
But, my point is, it's not at all obvious
why this would be the case or

1271
01:13:22,396 --> 01:13:25,450
that this should be the case.

1272
01:13:25,450 --> 01:13:27,578
And in fact there's good reasons why you
might imagine this didn't,

1273
01:13:27,578 --> 01:13:29,011
this wasn't going to happen.

1274
01:13:29,011 --> 01:13:32,780
All right, with that preamble, let's take
a look at the problem.

1275
01:13:32,780 --> 01:13:36,560
What does it mean for.

1276
01:13:36,560 --> 01:13:39,024
Every element of this ball, here,

1277
01:13:39,024 --> 01:13:43,890
to satisfy, a linear, a single linear
inequality.

1278
01:13:43,890 --> 01:13:48,370
And that says, here's a transpose x is
less than b.

1279
01:13:48,370 --> 01:13:53,245
And we want to know, what are the
conditions on xc, and r.

1280
01:13:53,245 --> 01:13:58,080
Under which this ball sits entirely in
that half space.

1281
01:13:58,080 --> 01:14:00,536
That's the question.

1282
01:14:00,536 --> 01:14:03,810
Okay.
Well let's find out.

1283
01:14:03,810 --> 01:14:07,700
Well that's the same as saying we'll write
the ball this way.

1284
01:14:07,700 --> 01:14:11,560
Its the same as x c plus u where norm u is
less than r.

1285
01:14:11,560 --> 01:14:12,920
That's the ball.

1286
01:14:12,920 --> 01:14:16,148
It says that all of these numbers have to
be less than bi.

1287
01:14:16,148 --> 01:14:21,550
Okay, well it, let's take a look at those
numbers.

1288
01:14:21,550 --> 01:14:25,325
Well the first, it doesn't depend on you
so that just comes right out.

1289
01:14:25,325 --> 01:14:27,603
So we want to find what's, what is the
mark,

1290
01:14:27,603 --> 01:14:32,292
what is the largest possible value of ai
transposed times u.

1291
01:14:32,292 --> 01:14:37,980
Well, and we can vary U over everything
that has length up to R.

1292
01:14:37,980 --> 01:14:42,310
That's the Koshi Schwartz inequality tells
you the following.

1293
01:14:42,310 --> 01:14:51,982
It says that A, I, transpose U this is
less than or equal to the following.

1294
01:14:51,982 --> 01:14:53,121
Norm A, I.

1295
01:14:53,121 --> 01:14:53,917
Right.

1296
01:14:53,917 --> 01:14:56,784
And then, over Mu right?

1297
01:14:56,784 --> 01:15:03,116
But that is less than R norm AI 2 that's
it shorts an inequality okay.

1298
01:15:03,116 --> 01:15:06,640
However there's the a converse to the
cosher schwarz inequality.

1299
01:15:06,640 --> 01:15:09,620
The converse when do you get equality
here?

1300
01:15:09,620 --> 01:15:13,650
And the answer is oh that's easy it's when
you.

1301
01:15:13,650 --> 01:15:15,750
Is aligned with a i.

1302
01:15:15,750 --> 01:15:19,006
In this case that means u is a i over norm
a i and

1303
01:15:19,006 --> 01:15:23,386
then we have to multiply this by r.

1304
01:15:23,386 --> 01:15:24,754
There we go.

1305
01:15:24,754 --> 01:15:29,164
So for this value of u which indeed
satisfies this it is

1306
01:15:29,164 --> 01:15:33,640
true That you get an equals here.

1307
01:15:33,640 --> 01:15:37,576
And so, that's that, that's the largest
possible value of

1308
01:15:37,576 --> 01:15:42,540
the inner product of ai and u over this
set of us.

1309
01:15:42,540 --> 01:15:44,500
Okay, and we write, write this down.

1310
01:15:44,500 --> 01:15:48,847
Again, it doesn't look like a linear
inequal, it doesn't look like an in,

1311
01:15:48,847 --> 01:15:52,750
inequality, because we see this 2.

1312
01:15:52,750 --> 01:15:56,228
But we take a deep breath and stare at
this for a while, and

1313
01:15:56,228 --> 01:16:03,850
we realize, that is sure, that's a, that's
a 2-norm, but its argument is a constant.

1314
01:16:03,850 --> 01:16:04,960
This is a number.

1315
01:16:06,120 --> 01:16:08,682
And if we look at this and we think of
just x, c, and r,

1316
01:16:08,682 --> 01:16:13,245
as sort of the variables here, that's a
linear inequality.

1317
01:16:13,245 --> 01:16:16,670
So, we have a linear program.

1318
01:16:16,670 --> 01:16:19,046
It says we should maximize r subject to,

1319
01:16:19,046 --> 01:16:24,220
that means find the largest radius,
subject to this constraint.

1320
01:16:24,220 --> 01:16:26,924
And if you were writing code, you would
put a comment there, and

1321
01:16:26,924 --> 01:16:31,680
then after the co-, on the, after the
comment, you would write the following.

1322
01:16:31,680 --> 01:16:34,840
You could say, this is the condition under
which.

1323
01:16:34,840 --> 01:16:40,000
Ai transpose x is less bi and for all x in
b xc r.

1324
01:16:40,000 --> 01:16:45,338
So that the, that's the ball with radius,

1325
01:16:45,338 --> 01:16:51,330
center xc and radius r, right?

1326
01:16:51,330 --> 01:16:52,790
And that's it.

1327
01:16:52,790 --> 01:16:53,430
It's that simple.

1328
01:16:53,430 --> 01:16:57,383
So finding the Chebyshev center of a set
Of a polyhedron given by a set of

1329
01:16:57,383 --> 01:17:00,300
linear inequalities.

1330
01:17:00,300 --> 01:17:01,720
It's a linear program, right?

1331
01:17:01,720 --> 01:17:03,860
But it has a lot of implications.

1332
01:17:03,860 --> 01:17:05,741
It says you can do design centering, and

1333
01:17:05,741 --> 01:17:09,240
things like that, using linear
programming.

1334
01:17:09,240 --> 01:17:10,962
I should say, linear programming, we'll
see that,

1335
01:17:10,962 --> 01:17:13,627
that's part of the theme of the course,
but things like linear programming is,

1336
01:17:13,627 --> 01:17:17,465
can be done very effectively even for
relatively large problems.

1337
01:17:17,465 --> 01:17:18,673
Okay.

1338
01:17:21,730 --> 01:17:24,780
Here's a, a significant sort of
generalization of linear programming is

1339
01:17:24,780 --> 01:17:27,610
what's called linear fractional
programming.

1340
01:17:27,610 --> 01:17:30,089
It's a quasi convex problem.

1341
01:17:30,089 --> 01:17:32,010
And it's this.

1342
01:17:32,010 --> 01:17:35,430
We have linear inequalities, linear
equalities.

1343
01:17:35,430 --> 01:17:39,140
And the objective is what's called the
linear fractional function.

1344
01:17:39,140 --> 01:17:40,964
It's a ratio of two Afine functions And

1345
01:17:40,964 --> 01:17:43,928
there, we do have to say, the domain is
one of the half spaces and

1346
01:17:43,928 --> 01:17:49,720
the convention is it's the half space
under which the denominator's positive.

1347
01:17:49,720 --> 01:17:50,510
Okay?
So that's a,

1348
01:17:50,510 --> 01:17:57,436
that's called a, a, some people call it a
bi affine function, I do, no they don't.

1349
01:17:57,436 --> 01:17:59,880
Oh, some people might.

1350
01:17:59,880 --> 01:18:02,727
By the way, in some In some small sections
of

1351
01:18:02,727 --> 01:18:08,744
mathematics people would actually refer to
that as an Afine function.

1352
01:18:08,744 --> 01:18:11,781
so, if you did projective geometry you
would call that afine.

1353
01:18:11,781 --> 01:18:12,369
Okay.

1354
01:18:12,369 --> 01:18:17,614
in any case, it's for us it's linear
fractional, is one name for it.

1355
01:18:17,614 --> 01:18:21,850
Okay now that is a quasi-convex
optimization problem.

1356
01:18:21,850 --> 01:18:23,564
How do we know that?

1357
01:18:23,564 --> 01:18:27,164
Well, all we have to do is look as what
does it mean to say that f

1358
01:18:27,164 --> 01:18:30,450
zero of that is less than t.

1359
01:18:30,450 --> 01:18:33,450
Right, there's the sub-level set here.

1360
01:18:33,450 --> 01:18:38,822
And f zero is this ration the denominator
is positive, so that's the set of x for

1361
01:18:38,822 --> 01:18:46,580
which, and I do, I should add that, the
denominator is positie, right.

1362
01:18:46,580 --> 01:18:50,838
Right?
And I clear it and I get c transpose x

1363
01:18:50,838 --> 01:18:56,646
plus d times t times e transpose x plus f
is less than or

1364
01:18:56,646 --> 01:19:04,350
equal In this case, let's see.

1365
01:19:04,350 --> 01:19:10,380
I, I said this is less than or equal to t
and that's less than [INAUDIBLE] 1.

1366
01:19:10,380 --> 01:19:12,630
Okay?
So that, that gives me that.

1367
01:19:12,630 --> 01:19:15,555
Sorry, did I get that right?

1368
01:19:15,555 --> 01:19:18,100
No.
There we go, now it's right.

1369
01:19:18,100 --> 01:19:20,501
Okay?
So, that's the condition and

1370
01:19:20,501 --> 01:19:22,736
I'll close the brace.

1371
01:19:22,736 --> 01:19:23,902
Okay?

1372
01:19:23,902 --> 01:19:29,636
So this is for any fixed t that
expression, that inequality is a linear

1373
01:19:29,636 --> 01:19:34,900
inequality, so that tells you that the sub
levels set is an open half

1374
01:19:34,900 --> 01:19:44,310
space intersected with a closed half
space, and that is a Convex set.

1375
01:19:44,310 --> 01:19:51,203
In fact you don't get points like this on
the boundary, but okay, that's fine.

1376
01:19:51,203 --> 01:19:53,700
Alright, so you can solve this by, by
section.

1377
01:19:53,700 --> 01:19:56,512
It turns out that there's a very clever
trick,

1378
01:19:56,512 --> 01:20:01,396
which allows you to solve this linear
Fractional program by solving a single LP

1379
01:20:01,396 --> 01:20:06,170
instead of solving oh let's say ten LPs.

1380
01:20:06,170 --> 01:20:10,076
If I solve ten LPs by bi-section I can
make my error in the objective go down by

1381
01:20:10,076 --> 01:20:12,330
a factor of 1024.

1382
01:20:12,330 --> 01:20:13,800
That's two to the ten.

1383
01:20:13,800 --> 01:20:16,499
But you can actually solve it exactly in
one.

1384
01:20:16,499 --> 01:20:19,920
I won't go into the details the arguments
a bit long.

1385
01:20:19,920 --> 01:20:21,660
But you'd have to make the argument.

1386
01:20:21,660 --> 01:20:23,660
And it basically is this.

1387
01:20:23,660 --> 01:20:27,010
You solve the following LP.

1388
01:20:27,010 --> 01:20:33,160
You minimize c transpose y plus d z
subject to g y less than h z.

1389
01:20:33,160 --> 01:20:33,844
A y equals b z so

1390
01:20:33,844 --> 01:20:38,220
these are all completely legit and in fact
these are all homogeneous.

1391
01:20:38,220 --> 01:20:42,576
Well no sorry that ones homogeneous and
the only thing that unhomogenizes it is

1392
01:20:42,576 --> 01:20:46,790
this constraint E transpose y, plus fz,
equals 1.

1393
01:20:46,790 --> 01:20:51,121
So, I won't go into in the book, it's
described in great detail how it is

1394
01:20:51,121 --> 01:20:57,554
that solving this LP actually solves this
linear-franctional problem.

1395
01:20:57,554 --> 01:21:01,013
Okay.
Generalized linear-fractional problem is

1396
01:21:01,013 --> 01:21:06,059
the maximum of a bunch of
linear-fractional functions.

1397
01:21:06,059 --> 01:21:10,809
It's the maximum anti-quasi convex
functions so it's quasiconvex.

1398
01:21:10,809 --> 01:21:12,516
Fine.
And therefore you can solve it by,

1399
01:21:12,516 --> 01:21:13,400
by section.

1400
01:21:13,400 --> 01:21:16,084
And in fact, in the, in this case in
general there's no

1401
01:21:16,084 --> 01:21:21,380
transformation that allows you to solve
this with one linear program.

1402
01:21:21,380 --> 01:21:25,810
[COUGH] Actually, that's maybe not known
or something like that.

1403
01:21:25,810 --> 01:21:26,490
But I'm asserting it.

1404
01:21:26,490 --> 01:21:28,740
Uh, [INAUDIBLE] I'll say it this way.

1405
01:21:28,740 --> 01:21:30,590
I don't know of a way to gen- to,

1406
01:21:30,590 --> 01:21:38,080
to write a generalized linear fractional
fun- problem as a single linear program.

1407
01:21:38,080 --> 01:21:41,272
OK, very, very interesting example of
this,

1408
01:21:41,272 --> 01:21:46,305
this problem is the so-called Von Neumann
growth model.

1409
01:21:46,305 --> 01:21:49,882
So in the Von Neumann growth model, the
way it works is this,

1410
01:21:49,882 --> 01:21:54,350
is we have variables x and let's say x
plus.

1411
01:21:54,350 --> 01:21:58,080
These are variables and they have to be
bigger or equal to zero.

1412
01:21:58,080 --> 01:22:03,436
So that a squiggly bigger or equal too,
their non-negative and

1413
01:22:03,436 --> 01:22:12,655
what xi represents That is the, activity
level of sector i, in an economy.

1414
01:22:12,655 --> 01:22:15,361
Then, if you put the plus there, that is,

1415
01:22:15,361 --> 01:22:22,168
that's the activity level in sector i of
the economy in the next period.

1416
01:22:22,168 --> 01:22:24,600
For example the next year, let's say.

1417
01:22:24,600 --> 01:22:25,440
Okay?
Next quarter.

1418
01:22:25,440 --> 01:22:27,040
It doesn't matter.

1419
01:22:27,040 --> 01:22:30,906
Well, it does matter if you actually do
this, but for us it doesn't matter.

1420
01:22:30,906 --> 01:22:32,607
And so that's the idea.

1421
01:22:32,607 --> 01:22:36,549
And a sector might be something like you
know, transportation or

1422
01:22:36,549 --> 01:22:40,433
defense or something like that, right?

1423
01:22:40,433 --> 01:22:44,252
OK, so here is Von Neumann's model.

1424
01:22:44,252 --> 01:22:47,312
It says it says if you look at x i plus
over x i,

1425
01:22:47,312 --> 01:22:51,450
that's a beautiful interpretation.

1426
01:22:51,450 --> 01:22:54,219
That is the growth, well if its bigger
than one,

1427
01:22:54,219 --> 01:22:58,595
that's the growth in the ith sector of the
economy.

1428
01:22:58,595 --> 01:23:01,299
Because x i plus is the economic activity
in the next period and

1429
01:23:01,299 --> 01:23:05,278
x i is in the current period and the
ratio, what was the ratio?

1430
01:23:05,278 --> 01:23:09,019
If that's 1.05, you would say that the
economy grew,

1431
01:23:09,019 --> 01:23:14,772
sorry, that sector of the economy grew by
five percent.

1432
01:23:14,772 --> 01:23:15,314
Okay?

1433
01:23:15,314 --> 01:23:19,607
Now by the way, if that's 0.96 you would
say that it shrunk by, it,

1434
01:23:19,607 --> 01:23:23,337
it contracted by four percent.

1435
01:23:23,337 --> 01:23:24,077
Okay?

1436
01:23:24,077 --> 01:23:28,991
And The Von Norman objective is this, you
take all sectors of the economy and

1437
01:23:28,991 --> 01:23:33,480
you look a the minimum across all sectors.

1438
01:23:33,480 --> 01:23:34,118
Right?
So, and

1439
01:23:34,118 --> 01:23:36,790
then that is something you want to
maximize.

1440
01:23:36,790 --> 01:23:40,786
And that sounds great, kind of egalitarian
minded, so very nice,

1441
01:23:40,786 --> 01:23:47,520
it says that basically, so for example if
this objective Is 1.04, that's great.

1442
01:23:47,520 --> 01:23:50,740
That means you have four percent growth in
all sectors.

1443
01:23:50,740 --> 01:23:51,690
That's what it means.

1444
01:23:51,690 --> 01:23:53,985
If this is .92, that's not great,

1445
01:23:53,985 --> 01:24:00,910
because it says at least one sector shrunk
by eight percent, contractive.

1446
01:24:00,910 --> 01:24:03,010
Okay?
Now we have to talk about the constraints.

1447
01:24:03,010 --> 01:24:05,880
Well, of course, they're the constraints
that X,

1448
01:24:05,880 --> 01:24:10,586
X0 that X is X plus is bigger or equal to
0.

1449
01:24:10,586 --> 01:24:11,802
The Xis are, by the way,

1450
01:24:11,802 --> 01:24:16,450
are positive already because the domain of
this implies that.

1451
01:24:16,450 --> 01:24:18,798
And so will the next constraint, but we'll
get to that.

1452
01:24:18,798 --> 01:24:24,640
Then it says, there's a constraint that
couples X and XI, and that's this.

1453
01:24:24,640 --> 01:24:28,800
So AX, A is a matrix that when you
multiply it by X,

1454
01:24:28,800 --> 01:24:32,960
it's Ith component gives you, the amount
of,

1455
01:24:32,960 --> 01:24:41,430
the amount of goods consumed, Due to
activity sector X.

1456
01:24:41,430 --> 01:24:42,532
Alright?
So that could be,

1457
01:24:42,532 --> 01:24:44,920
it doesn't matter what the goods are.

1458
01:24:44,920 --> 01:24:48,480
But, you know, it's a set of goods that
could be natural resources.

1459
01:24:48,480 --> 01:24:49,956
It doesn't matter what it is.

1460
01:24:49,956 --> 01:24:51,049
Okay?
Natural resources may be

1461
01:24:51,049 --> 01:24:52,290
a bad example actually.

1462
01:24:52,290 --> 01:24:55,660
It's the, it's the amount of, of goods.

1463
01:24:55,660 --> 01:24:57,498
This is produced.

1464
01:24:57,498 --> 01:24:58,786
Okay?

1465
01:24:58,786 --> 01:25:03,490
Then B is a matrix that when you multiply
it by an activity level,

1466
01:25:03,490 --> 01:25:11,089
tells you the amount of good consumed due
to that level of activity, right?

1467
01:25:11,089 --> 01:25:12,200
So, that's the idea.

1468
01:25:12,200 --> 01:25:16,230
So for example you take electricity would
be one of these entries, right?

1469
01:25:16,230 --> 01:25:16,730
And then.

1470
01:25:18,672 --> 01:25:20,004
b, one of the rows in b,

1471
01:25:20,004 --> 01:25:25,036
let's say the first row represents, let's
say, energy product, this would be, so,

1472
01:25:25,036 --> 01:25:32,890
the first row of b times x plus, gives you
the amount of energy which is produced.

1473
01:25:32,890 --> 01:25:35,310
That's also for example, because it It's
assumes you have to store it or

1474
01:25:35,310 --> 01:25:36,840
something like that.

1475
01:25:36,840 --> 01:25:37,858
But, okay, anyway.

1476
01:25:37,858 --> 01:25:39,392
Alright.

1477
01:25:39,392 --> 01:25:42,830
And this constraint says the following.

1478
01:25:42,830 --> 01:25:46,830
It says that the amount consumed in the
next sector has to be,

1479
01:25:46,830 --> 01:25:51,790
can be no more than the amount produced,
sorry, the amount pro, consumed in

1480
01:25:51,790 --> 01:25:59,810
the next period cannot exceed the amount
that is produced in this period.

1481
01:25:59,810 --> 01:26:03,730
That's what it means and you could add it,
you could add something else here.

1482
01:26:03,730 --> 01:26:06,754
You could add a constant which would be
some stock of stuff you had of

1483
01:26:06,754 --> 01:26:10,426
these resources you had before hand and so
now the problem is to solve this and that

1484
01:26:10,426 --> 01:26:14,098
indeed a generalized linear fractional
program because instead of Maximizing,

1485
01:26:14,098 --> 01:26:17,662
we could minimize and then it would be the
maximum and you'd switch the ratio and

1486
01:26:17,662 --> 01:26:24,230
it be the maximum of a bunch of linear
fractional functions.

1487
01:26:24,230 --> 01:26:27,250
And you'd have a generalized linear
fractional program.

1488
01:26:28,360 --> 01:26:32,752
And the idea would be to determine the
activity to maximize growth rate of

1489
01:26:32,752 --> 01:26:35,825
the slowest growing sector.

1490
01:26:35,825 --> 01:26:37,020
Okay?

1491
01:26:37,020 --> 01:26:41,460
And we can actually, that means, you can
solve it by solving some lps,

1492
01:26:41,460 --> 01:26:45,120
In fact by doing bisection on lps.

1493
01:26:45,120 --> 01:26:47,500
We'll move on to non affine problems, and

1494
01:26:47,500 --> 01:26:51,000
we're going to follow actually not really
the modern Flow, but

1495
01:26:51,000 --> 01:26:57,580
we're going to actually follow here the
historical flow of these problems.

1496
01:26:57,580 --> 01:27:00,917
And so people had branched out, big
generalization, yet

1497
01:27:00,917 --> 01:27:04,609
you still had linear inequalities, linear
inequalities, but

1498
01:27:04,609 --> 01:27:10,230
you have a quadratic objective and it has
to be convex, okay?

1499
01:27:10,230 --> 01:27:11,940
So convex quadratic.

1500
01:27:11,940 --> 01:27:14,488
You do have Something called indefinite
quadratic programs,

1501
01:27:14,488 --> 01:27:17,470
it's a totally different deal, not a
convex problem.

1502
01:27:17,470 --> 01:27:19,050
Okay?

1503
01:27:19,050 --> 01:27:21,610
And those also in general very hard to
solve.

1504
01:27:21,610 --> 01:27:24,730
Okay, so this is a convex quadratic
program, or if you just say quadratic

1505
01:27:24,730 --> 01:27:29,500
program the default is that it's convex,
when you talk to people about this.

1506
01:27:29,500 --> 01:27:32,425
Okay, so that's a quadratic program.

1507
01:27:32,425 --> 01:27:36,550
And, the, the the only difference is this,
here's your feasible set.

1508
01:27:36,550 --> 01:27:38,130
It's a polyhedron, here.

1509
01:27:40,150 --> 01:27:43,874
And the objective function now though is
quadratic and

1510
01:27:43,874 --> 01:27:47,530
the level sets are ellipsoids, right.

1511
01:27:47,530 --> 01:27:50,194
So here are some level sets drawn, these
are,

1512
01:27:50,194 --> 01:27:54,010
this is increasing values of the
objective.

1513
01:27:54,010 --> 01:27:55,900
And in fact there would be a center.

1514
01:27:55,900 --> 01:27:57,470
I don't know if it's going to be somewhere
around there.

1515
01:27:57,470 --> 01:28:00,340
and that's where this thing has it's
minimum value.

1516
01:28:00,340 --> 01:28:04,590
Assuming P as positive definite that would
be at the point P inverse Q.

1517
01:28:04,590 --> 01:28:07,650
Minus p inverse Q, that would be the point
that minimizes this unconstraint.

1518
01:28:07,650 --> 01:28:13,630
And so, the idea is to go is to slip down
these curves.

1519
01:28:13,630 --> 01:28:15,650
Go as low as you can while staying in the
set.

1520
01:28:15,650 --> 01:28:17,420
And in this case.

1521
01:28:17,420 --> 01:28:20,820
That would be the optimal point okay,
actually very interesting observation for

1522
01:28:20,820 --> 01:28:24,170
a linear program you can always find an
optimal point on one of these vertices and

1523
01:28:24,170 --> 01:28:28,040
here it's right smack in the middle of a
face.

1524
01:28:28,040 --> 01:28:32,790
That's a quadratic program and you can
solve these very well.

1525
01:28:34,320 --> 01:28:35,660
Okay, let's look at some examples.

1526
01:28:35,660 --> 01:28:37,360
Well, uh, [COUGH] here's the,

1527
01:28:37,360 --> 01:28:42,280
well the most basic context optimization
problem is, least-squares.

1528
01:28:42,280 --> 01:28:45,140
So minimize norm, A x minus b, two norm
squared.

1529
01:28:45,140 --> 01:28:46,920
It's also called regression.

1530
01:28:46,920 --> 01:28:47,750
It's, well, okay, it's least-squares.

1531
01:28:47,750 --> 01:28:52,300
And its got a linear, it's got a just an
analytical solution, right.

1532
01:28:52,300 --> 01:28:54,368
It's just It's A inverse b,

1533
01:28:54,368 --> 01:29:01,430
sorry, A dagger b and that's A transpose A
inverse, A tranpose b.

1534
01:29:01,430 --> 01:29:04,395
That's assuming A is full rank.

1535
01:29:04,395 --> 01:29:05,780
Okay?

1536
01:29:05,780 --> 01:29:10,410
So, that's if you that's if A is full rank
and skinny.

1537
01:29:10,410 --> 01:29:15,420
But in general, it's given by the
pseudo-inverse, the Moore-Penrose inverse.

1538
01:29:15,420 --> 01:29:17,920
And what we can do now is we can add
linear constraints.

1539
01:29:17,920 --> 01:29:20,340
So that's very cool.

1540
01:29:20,340 --> 01:29:23,695
So you add linear constraints to least
squares and what you get is,

1541
01:29:23,695 --> 01:29:26,250
this objective is quadratic.

1542
01:29:26,250 --> 01:29:29,399
It looks like this, it's x transpose times
a transpose a,

1543
01:29:29,399 --> 01:29:32,689
that's positive semi-definite, right?

1544
01:29:32,689 --> 01:29:38,297
Minus, and then this will be transpose x,
and this is 2 A transpose b.

1545
01:29:38,297 --> 01:29:40,190
transpose.

1546
01:29:40,190 --> 01:29:40,700
Right?

1547
01:29:40,700 --> 01:29:43,515
And then plus norm b squared.

1548
01:29:43,515 --> 01:29:44,378
Right?

1549
01:29:44,378 --> 01:29:46,410
You're minimizing, so this doesn't really
matter.

1550
01:29:46,410 --> 01:29:47,020
Okay?

1551
01:29:47,020 --> 01:29:51,280
There, that's a convex quadratic
objective.

1552
01:29:51,280 --> 01:29:52,460
And I can add constraints.

1553
01:29:52,460 --> 01:29:54,980
For example, I could bound x between
numbers.

1554
01:29:54,980 --> 01:29:57,360
I could say I can have a regression
problem.

1555
01:29:57,360 --> 01:29:59,040
And I can say, please fit,

1556
01:29:59,040 --> 01:30:04,240
my data b with a linear combination with
the columns of a.

1557
01:30:04,240 --> 01:30:05,056
But I don't want any,

1558
01:30:05,056 --> 01:30:08,080
any of the coefficients in that linear
combination that can never be more in

1559
01:30:08,080 --> 01:30:13,530
absolute value than, they have to be in
between minus one and one there we go.

1560
01:30:13,530 --> 01:30:18,318
I could say, find me the best fit here,
where the Xs have to be bigger or

1561
01:30:18,318 --> 01:30:21,340
equal to 0, right?

1562
01:30:21,340 --> 01:30:25,700
So that's basically this says, find the
closest point B to a subspace.

1563
01:30:25,700 --> 01:30:28,290
If I constraint X to be bigger or equal to
0,

1564
01:30:28,290 --> 01:30:34,580
it says find me the closest point to B in
a convex poly, in a cone.

1565
01:30:34,580 --> 01:30:39,205
Right, which is A times X where X is
bigger than or equal to 0.

1566
01:30:39,205 --> 01:30:40,657
[COUGH] Oh and another fascinating example
of this,

1567
01:30:40,657 --> 01:30:43,000
we'll look at many of these later but
here's a really cool one.

1568
01:30:44,150 --> 01:30:47,140
Let's do Lee squares and some people,
there's a name for

1569
01:30:47,140 --> 01:30:51,842
this it's called like I think isotonic
re-regression Alright.

1570
01:30:51,842 --> 01:30:58,158
That's the constraint that these are
ordered, like that.

1571
01:30:58,158 --> 01:31:01,768
Alright, there's no analytical solution
for

1572
01:31:01,768 --> 01:31:09,380
the best x that increases, but which
minimizes nor makes minus b squared.

1573
01:31:09,380 --> 01:31:11,430
There is no analytical solution for that.

1574
01:31:11,430 --> 01:31:14,785
But that's, you can solve this by a q p, a
very simple q p.

1575
01:31:14,785 --> 01:31:15,540
Right?

1576
01:31:15,540 --> 01:31:18,285
It says let's minimize this quadratic
objective,

1577
01:31:18,285 --> 01:31:22,290
that is a set of N minus 1 linear
inequality constraints.

1578
01:31:22,290 --> 01:31:25,362
Things like X 1 minus X two is less than
or equal to 0.

1579
01:31:25,362 --> 01:31:27,110
Okay, so.

1580
01:31:27,110 --> 01:31:30,905
So you can do regression, and you can add
arbitrary constraints to regression, and

1581
01:31:30,905 --> 01:31:32,500
you get a Q P.

1582
01:31:32,500 --> 01:31:36,350
Arbitrary linear constraints,
inequalities, equalities.

1583
01:31:36,350 --> 01:31:36,850
OK.

1584
01:31:38,070 --> 01:31:41,670
Now another interesting case is when you
do mean variance trade off.

1585
01:31:41,670 --> 01:31:43,028
So lets look at that.

1586
01:31:43,028 --> 01:31:49,020
Lets suppose that we have a linear program
with random costs.

1587
01:31:49,020 --> 01:31:55,500
So c transpose x is the c transpose x is
the objective Here.

1588
01:31:55,500 --> 01:31:58,560
But we're going to say that C is a random
variable.

1589
01:31:58,560 --> 01:32:01,850
In other words, you it, it's a set of
prices let's say.

1590
01:32:01,850 --> 01:32:03,070
You don't know the prices.

1591
01:32:03,070 --> 01:32:05,306
I mean, presumably you know something
about the prices, but

1592
01:32:05,306 --> 01:32:07,500
they may not be what you think they are.

1593
01:32:07,500 --> 01:32:11,219
And we're going to model those prices as a
random vector.

1594
01:32:12,240 --> 01:32:18,562
And we'll imagine that C as mean value C
Bar.

1595
01:32:18,562 --> 01:32:20,750
Right, so that's the mean price.

1596
01:32:20,750 --> 01:32:22,664
And then it has variance so

1597
01:32:22,664 --> 01:32:28,149
expected C minus C Bar, C minus C bar
transpose is sigma.

1598
01:32:28,149 --> 01:32:30,219
Is covariant sigma.

1599
01:32:30,219 --> 01:32:38,685
So So c bar and sigma describe a some of
the statistics of the cost.

1600
01:32:38,685 --> 01:32:39,746
Right?

1601
01:32:39,746 --> 01:32:40,600
Okay.

1602
01:32:40,600 --> 01:32:44,469
Now what we'll do is we'll minimize here c
bar trig/g, that's,

1603
01:32:44,469 --> 01:32:46,513
that's the mean expected cost and

1604
01:32:46,513 --> 01:32:52,991
that's plus gamma times, that's the
variance, that's what this does.

1605
01:32:52,991 --> 01:32:56,643
Gamma is a positive constant here, it's
positive and

1606
01:32:56,643 --> 01:33:01,789
it's called the risk aversion parameter
because the large you make gamma,

1607
01:33:01,789 --> 01:33:05,939
it says, the more you care in this case by
charging yourself,

1608
01:33:05,939 --> 01:33:13,410
it irritates you that the variants of the
cost are high.

1609
01:33:13,410 --> 01:33:14,555
So that's what this is.

1610
01:33:14,555 --> 01:33:18,515
So that's the idea and you would solve
this problem for

1611
01:33:18,515 --> 01:33:26,300
various values of gamma and look at it to
see where you would be comfortable.

1612
01:33:26,300 --> 01:33:30,420
Where where where your comfort is in
trading off risk.

1613
01:33:30,420 --> 01:33:36,441
This is generally associated with risk and
this would be something like just cost.

1614
01:33:36,441 --> 01:33:36,982
Okay.

1615
01:33:36,982 --> 01:33:41,632
Okay, now something in between or the next
step up is you say well look at

1616
01:33:41,632 --> 01:33:47,410
the objective can be quadratic why not the
constraints?

1617
01:33:47,410 --> 01:33:48,650
Okay, fine.

1618
01:33:48,650 --> 01:33:50,320
That's called a qcqp.

1619
01:33:50,320 --> 01:33:55,633
Again, this is the historical Evolution so
these days I guess out of historical

1620
01:33:55,633 --> 01:34:00,792
respect people still talk about QCQP's but
never the less we'll see that there's

1621
01:34:00,792 --> 01:34:09,420
something that subsumes this now a days
that's a generalization even more of this.

1622
01:34:09,420 --> 01:34:12,124
So QCQP is a quadratically constrained
quadratic program and

1623
01:34:12,124 --> 01:34:15,192
all of these matricies have to be positive
semi definite because all of

1624
01:34:15,192 --> 01:34:17,883
these functions are convex.

1625
01:34:17,883 --> 01:34:22,670
OK, so that's the, that's a QCQP.

1626
01:34:22,670 --> 01:34:25,283
Notice that this includes QP as a special
case,

1627
01:34:25,283 --> 01:34:28,097
because I just take all of these Pi's to
be 0, OK, and

1628
01:34:28,097 --> 01:34:35,140
by the way that includes LP as a special
case too because I take this P0 to be 0.

1629
01:34:35,140 --> 01:34:37,558
So the three problem classes we've looked
at so

1630
01:34:37,558 --> 01:34:41,500
far which is linear programming, QP, LP,
QP, QCQP.

1631
01:34:41,500 --> 01:34:42,550
They're growing, right?

1632
01:34:42,550 --> 01:34:46,906
We have LP, this is very rough but you
know what I mean.

1633
01:34:46,906 --> 01:34:51,160
That's a subset of QP and that's a subset
of QCQP.

1634
01:34:51,160 --> 01:34:54,470
So that's the, that's the picture so far.

1635
01:34:54,470 --> 01:34:54,980
Okay.

1636
01:34:54,980 --> 01:35:00,692
We're going to look at something even
Bigger.

1637
01:35:00,692 --> 01:35:06,650
It's called second-order cone programming
or S-O-C-P.

1638
01:35:06,650 --> 01:35:07,708
This is the modern one.

1639
01:35:07,708 --> 01:35:11,740
Okay [COUGH] now second-order cone
programming looks like this.

1640
01:35:11,740 --> 01:35:15,450
It says minimize the linear function,
that's kind of like a L-P,

1641
01:35:15,450 --> 01:35:18,520
subject to equality contraints.

1642
01:35:18,520 --> 01:35:21,260
Well, they have to be linear, it's convex.

1643
01:35:21,260 --> 01:35:23,090
And then subject to the following.

1644
01:35:23,090 --> 01:35:26,172
There's a two norm And an affine part.

1645
01:35:26,172 --> 01:35:31,260
And you look at that, and it sure looks
like, it looks like,

1646
01:35:31,260 --> 01:35:36,700
kind of a QCQP or something like that.

1647
01:35:36,700 --> 01:35:38,430
I'll get to that in a minute, but.

1648
01:35:38,430 --> 01:35:39,290
So let's take a look at this.

1649
01:35:39,290 --> 01:35:42,372
Basically, each of these constraints,
that's called,

1650
01:35:42,372 --> 01:35:46,410
this is called a second-order cone
constraint.

1651
01:35:46,410 --> 01:35:48,970
And basically it says the following, it
says Ax,

1652
01:35:48,970 --> 01:35:52,190
Aix plus bi comma ci transpose x plus di.

1653
01:35:52,190 --> 01:35:55,220
That's in the second-order cone, okay?

1654
01:35:55,220 --> 01:35:59,320
So it's the image under an affine mapping,
right.

1655
01:35:59,320 --> 01:36:04,066
It maps A, it maps x into, into this pair.

1656
01:36:04,066 --> 01:36:06,796
And so you know, well, it's affine
mapping.

1657
01:36:06,796 --> 01:36:10,198
And then it says that has to be the second
order cone.

1658
01:36:10,198 --> 01:36:14,228
Or another way to say it is it's the
inverse image under an affine mapping of

1659
01:36:14,228 --> 01:36:16,597
a second order cone.

1660
01:36:16,597 --> 01:36:20,330
So that's what a second order constraint
is.

1661
01:36:20,330 --> 01:36:24,546
If I took for example, I mean I can either
take the dimension to be low, or

1662
01:36:24,546 --> 01:36:29,640
I could take ai to be to make the
dimension ni one.

1663
01:36:29,640 --> 01:36:33,528
I could take ai to be zero or something,
and this, this will recover an lp.

1664
01:36:33,528 --> 01:36:36,890
And in fact I can express any qc qp this
way, and

1665
01:36:36,890 --> 01:36:44,600
any lp this way because I just don't need
these terms and I have an lp.

1666
01:36:44,600 --> 01:36:45,480
Right?
So that's it.

1667
01:36:45,480 --> 01:36:50,400
And this is, so this is more general than
QCQP and LP.

1668
01:36:50,400 --> 01:36:53,540
Now I want to mention something here which
is interesting.

1669
01:36:53,540 --> 01:36:55,380
Now for us, we say that's a convex
problem.

1670
01:36:55,380 --> 01:36:57,060
And why do we know that?

1671
01:36:57,060 --> 01:37:02,620
Well, we look over here at the constraints
and the objective is linear problem.

1672
01:37:02,620 --> 01:37:07,060
And we look at the constraints here and we
say, well this is convex.

1673
01:37:07,060 --> 01:37:09,520
And then the right hand side is affine.

1674
01:37:09,520 --> 01:37:12,258
So I could just as well subtract it and
say nor

1675
01:37:12,258 --> 01:37:18,490
may I X plus BI minus CI transpose X minus
DI less than or equal to zero.

1676
01:37:18,490 --> 01:37:21,420
But that function is convex, cause its a
norm.

1677
01:37:21,420 --> 01:37:25,112
Norm of affine is convex so that's convex.

1678
01:37:25,112 --> 01:37:27,440
Now the.

1679
01:37:27,440 --> 01:37:32,990
If you are in the pre-modern era of
optimization, here's what would happen.

1680
01:37:34,279 --> 01:37:39,277
People have encountered two norms for
hundreds of years.

1681
01:37:39,277 --> 01:37:44,630
Gauss did, I mean Gauss wrote a book about
two door minimization, right.

1682
01:37:44,630 --> 01:37:46,520
That lead the least squares.

1683
01:37:46,520 --> 01:37:47,544
And that's you hint.

1684
01:37:47,544 --> 01:37:52,692
In the classical view when you see a to
norm there's something that you want to do

1685
01:37:52,692 --> 01:37:55,380
very badly to it.

1686
01:37:57,040 --> 01:38:00,160
You want to square it and the reason is
this.

1687
01:38:00,160 --> 01:38:04,160
A two norm is not differentiable when the
argument is zero.

1688
01:38:04,160 --> 01:38:06,690
I mean after all a two norm Let's do one
dimension.

1689
01:38:06,690 --> 01:38:08,718
It's an absolute value, right?

1690
01:38:08,718 --> 01:38:11,890
So this doesn't look good.

1691
01:38:11,890 --> 01:38:14,915
And if your whole world view centers
around differentiability of

1692
01:38:14,915 --> 01:38:17,540
things like that, then this is bad.

1693
01:38:17,540 --> 01:38:18,515
Not good.

1694
01:38:18,515 --> 01:38:22,190
Okay, but if you square this.

1695
01:38:24,200 --> 01:38:29,320
[SOUND] The square of a norm expression,
like Aix plus bi, 2 norm squared.

1696
01:38:29,320 --> 01:38:33,510
That is a quadratic, that's a convex
quadratic function.

1697
01:38:34,950 --> 01:38:38,270
That is fantastic, that's, it's convex,
number one.

1698
01:38:38,270 --> 01:38:39,037
And number two,

1699
01:38:39,037 --> 01:38:43,460
this is even better, it's smooth; there's
no There's no point any more.

1700
01:38:43,460 --> 01:38:46,428
I mean, if you square the absolute value,
you get the square.

1701
01:38:46,428 --> 01:38:47,190
Right?

1702
01:38:47,190 --> 01:38:48,448
It's nice and smooth.

1703
01:38:48,448 --> 01:38:49,336
Okay?

1704
01:38:49,336 --> 01:38:53,565
You can take gradients, derivatives,
whatever you like.

1705
01:38:53,565 --> 01:38:54,910
Okay.

1706
01:38:54,910 --> 01:38:55,600
So you look at this thing and

1707
01:38:55,600 --> 01:38:58,110
you say, well, you know what I'm going to
do, I'm going to square it.

1708
01:38:58,110 --> 01:39:00,050
Because it's irritating me or something.

1709
01:39:00,050 --> 01:39:02,780
So you'll square it and you'll get this.

1710
01:39:02,780 --> 01:39:05,060
See I transposed X plus D I.

1711
01:39:05,060 --> 01:39:07,895
Now this is not quite, oops I got to
square that.

1712
01:39:07,895 --> 01:39:12,080
Now this is not the same as that because
we still have to

1713
01:39:12,080 --> 01:39:19,740
add the string C transposed X plus D I Is
bigger than or equal to 0.

1714
01:39:19,740 --> 01:39:22,771
These two together are exactly the same as
that constraint there.

1715
01:39:22,771 --> 01:39:25,352
Okay?
And it's looking really good because I

1716
01:39:25,352 --> 01:39:30,187
would subtract this and write that as less
than or equal to 0.

1717
01:39:30,187 --> 01:39:35,909
And I, I'm in a great position here
because now I have a, that's quadratic.

1718
01:39:35,909 --> 01:39:37,150
Quadratic.

1719
01:39:37,150 --> 01:39:39,690
Less than or equal to 0.

1720
01:39:39,690 --> 01:39:45,030
Linear inequalities I got a QP, QCQP I
should say.

1721
01:39:45,030 --> 01:39:51,424
Okay, so that, this is what you would want
to do, now can you do this.

1722
01:39:51,424 --> 01:39:57,524
Well it all looks good and there's only
one minor problem with that and

1723
01:39:57,524 --> 01:40:03,024
that is this the Quadratic part of this
matrix is exactly this one,

1724
01:40:03,024 --> 01:40:10,992
it's Ai transpose Ai minus, ci, ci
transpose.

1725
01:40:10,992 --> 01:40:11,770
[COUGH], sorry, that's right.

1726
01:40:11,770 --> 01:40:12,620
Okay?
So that's what it is.

1727
01:40:16,265 --> 01:40:17,235
Alright, now.

1728
01:40:17,235 --> 01:40:20,640
That's positive, semi-definite, so is
that.

1729
01:40:20,640 --> 01:40:22,620
But the difference is not necessarily.

1730
01:40:22,620 --> 01:40:26,832
Oh, but if the difference is positive,
semi-definite, great,

1731
01:40:26,832 --> 01:40:31,304
you have reduced your general SOCP to a
QCQP.

1732
01:40:31,304 --> 01:40:36,670
But [COUGH] if this is not positive
semi-definite, You don't have.

1733
01:40:36,670 --> 01:40:39,510
You have a QCQP, but it's one with
indefinite matrices.

1734
01:40:39,510 --> 01:40:41,890
Right?
So, and that sort of makes it hard.

1735
01:40:41,890 --> 01:40:43,730
Now of course it's easy, but you don't
know that.

1736
01:40:43,730 --> 01:40:47,312
So, all right.
So, let me summarize I should say that in

1737
01:40:47,312 --> 01:40:52,706
the older more historical, conventional
view This, a norm, a two norm,

1738
01:40:52,706 --> 01:41:00,920
without a square on top irritates you
because it's not differentiable.

1739
01:41:00,920 --> 01:41:02,750
And you'd have an urge to square it.

1740
01:41:02,750 --> 01:41:04,559
If you square it, you would get a,

1741
01:41:04,559 --> 01:41:10,170
a problem that is quadratic, that's grated
smooth but it's not convex.

1742
01:41:10,170 --> 01:41:13,711
So, ok, alright so that's a, this is SOCP.

1743
01:41:16,370 --> 01:41:18,190
So let's look in the example of SOCP.

1744
01:41:18,190 --> 01:41:21,767
Oh and I should say that if you were
tracing the history,

1745
01:41:21,767 --> 01:41:26,372
quadratic programming we were at about
1952, '53.

1746
01:41:26,372 --> 01:41:29,130
QCQP not long thereafter.

1747
01:41:29,130 --> 01:41:33,190
We are now, well it depends, I mean we're
in the nineties let's say.

1748
01:41:33,190 --> 01:41:36,860
Late eighties not it would be the very
beginnings, you're in the nineties maybe.

1749
01:41:36,860 --> 01:41:37,740
Something like that.

1750
01:41:37,740 --> 01:41:39,980
So you're in the modern era when you talk
about SSCP.

1751
01:41:39,980 --> 01:41:42,840
So, let's look at an example.

1752
01:41:42,840 --> 01:41:45,920
Let's take a linear programming problem,
here it is.

1753
01:41:45,920 --> 01:41:46,845
Minimize this.

1754
01:41:46,845 --> 01:41:56,210
And [COUGH] let's get, let's suppose that
there's uncertainty in c a i and b.

1755
01:41:56,210 --> 01:41:57,260
That's the problem data.

1756
01:41:57,260 --> 01:41:58,052
Now, you know,

1757
01:41:58,052 --> 01:42:02,949
of course, in any real application there
will be uncertainty in these.

1758
01:42:02,949 --> 01:42:03,940
Eh, that's not true.

1759
01:42:03,940 --> 01:42:06,480
There are some example where there would
not be.

1760
01:42:06,480 --> 01:42:07,040
For example.

1761
01:42:07,040 --> 01:42:11,276
suppose That you are trying to verify some
mathematical conjecture, right?

1762
01:42:11,276 --> 01:42:15,360
And then, then in fact the data are exact.

1763
01:42:15,360 --> 01:42:19,520
But other than some, except for that one
case, right?

1764
01:42:19,520 --> 01:42:23,936
In any practical application, all of these
things derived from Well your problem,

1765
01:42:23,936 --> 01:42:27,230
they derived from your problem right?

1766
01:42:27,230 --> 01:42:32,656
So and there I'l just have a little side
discussion about problem data.

1767
01:42:32,656 --> 01:42:38,500
0's and the coefficients they are probably
really 0 and they might not be right?

1768
01:42:38,500 --> 01:42:40,890
That might just be your way of saying
small.

1769
01:42:40,890 --> 01:42:43,840
Think numbers like 1/2 minus 1.

1770
01:42:43,840 --> 01:42:48,290
You know, plus one those maybe or exactly
ones minus one.

1771
01:42:48,290 --> 01:42:51,290
Every other number, if you see a .236 or a
1.682 or

1772
01:42:51,290 --> 01:42:56,030
something, all of those numbers have a
providence.

1773
01:42:56,030 --> 01:42:57,810
They trace back to something, right.

1774
01:42:57,810 --> 01:43:01,173
They trace back to some combination of if
it's a physical thing so

1775
01:43:01,173 --> 01:43:05,020
it's Young's modulous times the distance.

1776
01:43:05,020 --> 01:43:07,260
Right, it's some coefficent of thermal
expansion.

1777
01:43:07,260 --> 01:43:10,151
If this is finance, it will trace back to
some parameter and

1778
01:43:10,151 --> 01:43:15,010
a model like the volatility or the mean
return or something like that.

1779
01:43:15,010 --> 01:43:19,870
So, in all cases like that, those numbers
are suspect, right, and

1780
01:43:19,870 --> 01:43:26,660
it should be the case that if you vary
them, a little bit.

1781
01:43:26,660 --> 01:43:28,835
The solution does not change wildly.

1782
01:43:28,835 --> 01:43:29,910
Okay?

1783
01:43:29,910 --> 01:43:33,482
So, if it does change wildly, then, it
tells you that,

1784
01:43:33,482 --> 01:43:38,118
solving this problem is as a practical
matter Useless, right, because I,

1785
01:43:38,118 --> 01:43:42,602
I could hardly tell you oh, I've got a
wonderful way to land an airplane,

1786
01:43:42,602 --> 01:43:49,460
it's absolutely unbelievable, wait til you
see it.

1787
01:43:49,460 --> 01:43:52,488
And they'd say how'd you do that, well, I,
I solved a linear program and.

1788
01:43:52,488 --> 01:43:54,750
Well, that's great.

1789
01:43:54,750 --> 01:43:57,244
And I'd say, there's only one minor
problem with it,

1790
01:43:57,244 --> 01:44:02,360
you need to know the mass of the airplane
to seven significant figures, right.

1791
01:44:02,360 --> 01:44:05,462
So if you, if If there's any error in the,
in the seventh or

1792
01:44:05,462 --> 01:44:11,270
sixth significant figure in the mess then
it won't work at all.

1793
01:44:11,270 --> 01:44:13,160
Well, I mean, that's just stupid.

1794
01:44:13,160 --> 01:44:15,750
It's not, that's just a non solution.

1795
01:44:15,750 --> 01:44:17,410
It has no practical use anyway.

1796
01:44:17,410 --> 01:44:23,055
All right, so all of that was just a long
aside about variations in problem data.

1797
01:44:23,055 --> 01:44:29,908
So, and there's a new trend now where
people are explicit about the data.

1798
01:44:29,908 --> 01:44:30,630
Variations in data.

1799
01:44:30,630 --> 01:44:32,240
And we're going to look at that now.

1800
01:44:32,240 --> 01:44:34,264
So, for simplicity, let's just assume that
the data,

1801
01:44:34,264 --> 01:44:36,780
that the only thing that's going to change
is a.

1802
01:44:36,780 --> 01:44:38,180
So for some reason we know c.

1803
01:44:38,180 --> 01:44:41,870
Actually, we already looked earlier at the
problem of c being unknown.

1804
01:44:41,870 --> 01:44:44,181
We interpreted that as prices, or
something.

1805
01:44:44,181 --> 01:44:47,410
So let's assume it's only a than changes.

1806
01:44:47,410 --> 01:44:48,124
You can interpret a,

1807
01:44:48,124 --> 01:44:51,375
by the way, as something that tells you
how much resources you consume.

1808
01:44:51,375 --> 01:44:53,360
Okay.

1809
01:44:53,360 --> 01:44:58,083
Now the deterministic model says something
like this.

1810
01:44:58,083 --> 01:45:01,349
It says that I have some sets, e i, Let's
say an ellipse or

1811
01:45:01,349 --> 01:45:07,080
something like that and it says that each
AI is in that ellipse.

1812
01:45:07,080 --> 01:45:11,850
And I'm going to insist that constraint
hold for every single possible AI.

1813
01:45:11,850 --> 01:45:12,860
So that's my constraint.

1814
01:45:12,860 --> 01:45:17,180
Some people call that a worst case model,
well cause that's what it says.

1815
01:45:17,180 --> 01:45:20,716
It says I want my resource consumption to
not exceed my resour,

1816
01:45:20,716 --> 01:45:23,940
the resources I have.

1817
01:45:23,940 --> 01:45:27,710
My consumption should not exceed my
resources even in the absolute worst case.

1818
01:45:27,710 --> 01:45:29,890
So that's that.

1819
01:45:29,890 --> 01:45:32,604
Now another model is the stochastic model
and that says that these AI's

1820
01:45:32,604 --> 01:45:36,760
are random variables and the constraints
have to hold with some probability.

1821
01:45:36,760 --> 01:45:40,450
For example I don't know 90%, 99.

1822
01:45:40,450 --> 01:45:45,390
Typical ones would be in fact things like
these are the ones of interest right?

1823
01:45:45,390 --> 01:45:48,345
There's not that many of interest frankly
Right?

1824
01:45:48,345 --> 01:45:51,380
[SOUND] And there's maybe one more,
something like that, right?

1825
01:45:51,380 --> 01:45:52,402
These are the three of interest.

1826
01:45:52,402 --> 01:45:57,560
Now, you might ask, why do I say these are
the only three numbers of interest?

1827
01:45:57,560 --> 01:45:58,854
And, it's very simple.

1828
01:45:58,854 --> 01:46:01,940
You don't, you don't care about like s-,
0.7, right?

1829
01:46:01,940 --> 01:46:04,930
That says, yes, I'd like those constraints
to hold 70% of the time.

1830
01:46:04,930 --> 01:46:07,630
That, that does, that doesn't make any
sense, right?

1831
01:46:07,630 --> 01:46:10,443
Because, well, it doesn't make, it
doesn't, you want it to fail?

1832
01:46:10,443 --> 01:46:12,140
You want it to be violated 30% of the
time?

1833
01:46:12,140 --> 01:46:12,715
I don't think so.

1834
01:46:12,715 --> 01:46:14,520
Okay.

1835
01:46:14,520 --> 01:46:17,814
Nine five its just kind of your way of
saying I wanted to usually be

1836
01:46:17,814 --> 01:46:19,760
satisfied often.

1837
01:46:19,760 --> 01:46:22,930
I want it to be rare that its violated.

1838
01:46:22,930 --> 01:46:25,075
You know like once in twenty times.

1839
01:46:25,075 --> 01:46:26,340
Okay.

1840
01:46:26,340 --> 01:46:29,640
This says no I want it actually rarer than
that, one in a hundred times and

1841
01:46:29,640 --> 01:46:35,000
this is basically your way of saying I
want it to be quite rare.

1842
01:46:35,000 --> 01:46:38,009
I'll accept a violation but it should be
like one in a thousand times but

1843
01:46:38,009 --> 01:46:40,760
already this doesn't mean a whole lot.

1844
01:46:40,760 --> 01:46:43,840
[COUGH] Because when you put numbers like
that on here it sort of

1845
01:46:43,840 --> 01:46:46,147
has a different meaning.

1846
01:46:46,147 --> 01:46:49,451
Because this says you better be very
certain of the distribution of

1847
01:46:49,451 --> 01:46:50,277
these things and

1848
01:46:50,277 --> 01:46:55,680
when these are just in practice, in order
to assert that a probability is.

1849
01:46:55,680 --> 01:46:56,610
0.001.

1850
01:46:56,610 --> 01:47:02,655
If it's 0.0% you better be really sure of
details of your distribution.

1851
01:47:02,655 --> 01:47:06,429
And I can tell you that in practice the
one thing that people do

1852
01:47:06,429 --> 01:47:10,560
not know about distributions is the tail.

1853
01:47:10,560 --> 01:47:11,100
Right?

1854
01:47:11,100 --> 01:47:11,739
Period.

1855
01:47:11,739 --> 01:47:14,160
So, I mean, there's no way somebody can
say oh, yeah, yeah.

1856
01:47:14,160 --> 01:47:16,785
So that's why you don't talk about
something like this.

1857
01:47:16,785 --> 01:47:19,882
Now they do, okay?

1858
01:47:19,882 --> 01:47:22,357
But when they talk about that, you have to
understand,

1859
01:47:22,357 --> 01:47:27,090
they don't really mean the probability
that you violate is less than .01%.

1860
01:47:27,090 --> 01:47:30,150
They don't believe that, I mean, let's
hope they don't believe that.

1861
01:47:30,150 --> 01:47:32,178
What they really mean is this is a
surrogate for

1862
01:47:32,178 --> 01:47:35,812
saying, I really want that to hold, like,
very, very often.

1863
01:47:35,812 --> 01:47:37,765
That's what they mean to say.

1864
01:47:37,765 --> 01:47:42,292
Okay I really care about the exact value
of that number.

1865
01:47:42,292 --> 01:47:45,360
Okay, so that's the stochastic model.

1866
01:47:47,200 --> 01:47:50,760
Okay, let's look at the deterministic
approach let's see how that works.

1867
01:47:50,760 --> 01:47:52,630
Let's say that the ellipsoid.

1868
01:47:52,630 --> 01:47:57,090
Okay these are ellipsoid that contain that
describe possible values of the AI.

1869
01:47:57,090 --> 01:47:59,260
Oh, and you ,might ask how do you get
these.

1870
01:47:59,260 --> 01:48:02,270
Well these are problems we'll even look at
in this course.

1871
01:48:02,270 --> 01:48:03,840
How do you get this ellipsoid?

1872
01:48:03,840 --> 01:48:06,120
Well, the answer is you'd look at a 1.

1873
01:48:06,120 --> 01:48:07,271
Right?
That's a vector that

1874
01:48:07,271 --> 01:48:11,580
characterizes the resource consumption of,
you know, for the first resource.

1875
01:48:11,580 --> 01:48:13,880
And what you do is you go get a model of
this thing from Monday,

1876
01:48:13,880 --> 01:48:17,300
Tuesday, Wednesday, Thursday, and you get
different AI's.

1877
01:48:17,300 --> 01:48:18,540
And you get a year's worth.

1878
01:48:18,540 --> 01:48:20,679
You have 365 vectors AI.

1879
01:48:22,000 --> 01:48:25,110
And if they're all over the place then
it's time to give up and go home.

1880
01:48:25,110 --> 01:48:27,372
But if they're kind of reasonably,

1881
01:48:27,372 --> 01:48:32,420
tightly concentrated you might fit an
ellipsoid over that.

1882
01:48:32,420 --> 01:48:34,600
We'll see exactly how to do that later in
the course.

1883
01:48:34,600 --> 01:48:39,242
You'll fit an ellipsoid over it and that
would be your ellipsoid.

1884
01:48:39,242 --> 01:48:43,530
So so you have an ellipsoid, it's
characterized by a center and the matrix

1885
01:48:43,530 --> 01:48:50,886
PI which is positive well here we haven't
yet assumed it's positive semi definite.

1886
01:48:50,886 --> 01:48:56,045
is, it's, we'll say it's, well actually it
doesn't have to be non-singular.

1887
01:48:56,045 --> 01:48:59,939
that, it's, it's an ellipsoid, this is a
generalized ellipsoid, P has less than

1888
01:48:59,939 --> 01:49:05,875
full rank, it means that there is some
dimensions in which AI is known exactly.

1889
01:49:05,875 --> 01:49:09,575
Okay, the robust lp says you, this
constraint has to hold for

1890
01:49:09,575 --> 01:49:13,200
all ai in an ellipsoid.

1891
01:49:13,200 --> 01:49:15,360
But wait a minute, what's this?

1892
01:49:15,360 --> 01:49:20,511
That says that ai bar plus pi u transpose
x,that's the maximum

1893
01:49:20,511 --> 01:49:25,050
value of this thing here.

1894
01:49:25,050 --> 01:49:26,115
Has to be less than b.

1895
01:49:26,115 --> 01:49:28,930
That has to be less than bi.

1896
01:49:28,930 --> 01:49:34,310
And that's gotta hold for all u, but we
can just multiply this out.

1897
01:49:34,310 --> 01:49:39,630
Right, that's ai bar transpose x plus and
then that's the norm of PI transpose x.

1898
01:49:39,630 --> 01:49:44,450
And that's from the converse
Cauchy-Schwarz inequality.

1899
01:49:44,450 --> 01:49:48,462
So basically it says this constraint
becomes that., We now sit back and

1900
01:49:48,462 --> 01:49:50,580
take a look at it.

1901
01:49:50,580 --> 01:49:51,598
At what we have.

1902
01:49:51,598 --> 01:49:59,186
Linear objective, that constraint is
linear plus norm of aphine/g.

1903
01:49:59,186 --> 01:50:01,870
2 norm of Afine, less than constant.

1904
01:50:01,870 --> 01:50:03,620
That's an SOCP.

1905
01:50:03,620 --> 01:50:05,000
Right?
And that's it.

1906
01:50:05,000 --> 01:50:06,480
And, by the way, the meaning of this.

1907
01:50:06,480 --> 01:50:09,273
You know, this is something that not, you
know, only some people know

1908
01:50:09,273 --> 01:50:13,430
about SOCPs now, but 25 years ago, you
know, 15 people knew about them.

1909
01:50:13,430 --> 01:50:15,645
Okay?
Or maybe 20.

1910
01:50:15,645 --> 01:50:17,545
So, it's an extraordinary thing, cause
they,

1911
01:50:17,545 --> 01:50:21,620
there's a very practical, the practical
conclusion is, we can solve this.

1912
01:50:21,620 --> 01:50:24,690
With extreme efficiency and reliability.

1913
01:50:24,690 --> 01:50:28,290
In effect, this is already happening, most
fields, many fields that use

1914
01:50:28,290 --> 01:50:33,849
linear programs are switching to SOCPs
just to handle the robust case, OK?

1915
01:50:33,849 --> 01:50:36,390
And let me say a little bit more about it,

1916
01:50:36,390 --> 01:50:39,239
it's actually super cool If I get rid of
this,

1917
01:50:39,239 --> 01:50:47,442
this says simply make the inequality hold
when I put in the center of the ellipsoid.

1918
01:50:47,442 --> 01:50:55,750
But that's not right because a is going to
vary, and I want some margin there, right?

1919
01:50:55,750 --> 01:51:00,089
So this is to be interpreted as the
margin.

1920
01:51:01,700 --> 01:51:04,650
What it is, is it's a beautiful thing that
tells you that depending on x,

1921
01:51:04,650 --> 01:51:07,380
it tells you how much margin to leave.

1922
01:51:07,380 --> 01:51:12,670
And the answer simply is p, transpose x
norm 2 right?

1923
01:51:12,670 --> 01:51:15,235
And as an example, let's go to this thing.

1924
01:51:15,235 --> 01:51:19,650
Suppose x is zero, and I ask you.

1925
01:51:21,630 --> 01:51:24,070
Do you have to worry about variations in a
i?

1926
01:51:24,070 --> 01:51:28,855
And the answer is no and I'd say really
even if a i changes hugely and

1927
01:51:28,855 --> 01:51:37,170
the answer is no not at all because a
transpose times zero is zero.

1928
01:51:37,170 --> 01:51:38,535
So if x is zero you,

1929
01:51:38,535 --> 01:51:44,730
you're, you don't have to worry about
variations in a, right?

1930
01:51:44,730 --> 01:51:46,281
Where as if x is big you do, because well,

1931
01:51:46,281 --> 01:51:50,670
roughly they're getting multiplied by, you
get, they get multiplied together.

1932
01:51:50,670 --> 01:51:53,442
This thing says that the margin has to
scale with x and

1933
01:51:53,442 --> 01:51:56,160
it even scales with the shape.

1934
01:51:56,160 --> 01:51:58,860
If you, if x moves in the ellipsoid is
very big Then you have to

1935
01:51:58,860 --> 01:52:02,770
have more margin than if you moved in
another direction.

1936
01:52:02,770 --> 01:52:07,570
Okay that's it says summary is this,

1937
01:52:07,570 --> 01:52:16,240
you can solve deterministic robust LP via
SOCP.

1938
01:52:16,240 --> 01:52:18,465
Okay let's look at the stochastic
approach.

1939
01:52:18,465 --> 01:52:21,729
Well the stochastic approach Is this ai is
Gaussian with a mean ai ai bar and

1940
01:52:21,729 --> 01:52:24,620
a covariance sigma i, that's Gaussian.

1941
01:52:24,620 --> 01:52:28,070
Then that's a Gaussian scaler random
variable, right.

1942
01:52:28,070 --> 01:52:34,244
And that says that the probability that
the constrained holes is simply

1943
01:52:34,244 --> 01:52:42,300
the cumulative distribution function of
the normalized version of it.

1944
01:52:42,300 --> 01:52:45,836
So that's the margin Divided by, this is
something that has

1945
01:52:45,836 --> 01:52:51,826
that's a variable that has you know, zero,
one it's N zero one here.

1946
01:52:51,826 --> 01:52:53,916
Oh, sorry, yeah it is.

1947
01:52:53,916 --> 01:52:57,535
That's an N zero one variable.

1948
01:52:57,535 --> 01:53:01,760
And sorry if I put an AI there it's and N
zero one variable.

1949
01:53:01,760 --> 01:53:05,190
And then this simply gives you the
probability right?

1950
01:53:05,190 --> 01:53:09,050
Okay, so the robust LP, which looks like
this.

1951
01:53:09,050 --> 01:53:11,900
Becomes the following, oh, and we have to
be very careful.

1952
01:53:11,900 --> 01:53:16,454
It's this, to say that this is bigger than
that you need this probability here, to be

1953
01:53:16,454 --> 01:53:23,520
bigger than that if this is this thing
here is an increasing function of course.

1954
01:53:24,720 --> 01:53:27,810
With X, and it says that you have to have
this here.

1955
01:53:27,810 --> 01:53:29,560
Now the problem is, if this is,

1956
01:53:29,560 --> 01:53:35,326
if this thing is negative then this has
the wrong sign, right?

1957
01:53:35,326 --> 01:53:42,057
Otherwise, if this is positive, that's the
second order cone constraint.

1958
01:53:42,057 --> 01:53:48,530
If it's positive, and that's exactly For
eta bigger than one half, right?

1959
01:53:48,530 --> 01:53:54,840
So it's quite beautiful what this says, so
the interpretation is this.

1960
01:53:54,840 --> 01:53:59,240
If you say solve me the stochastic linear
program, with gau,

1961
01:53:59,240 --> 01:54:04,290
let's say Gaussian, Gaussian AI.

1962
01:54:04,290 --> 01:54:07,070
And with confidence level eta.

1963
01:54:07,070 --> 01:54:10,206
That means I want the constrains to hold
with probability eta.

1964
01:54:10,206 --> 01:54:13,060
And we already discussed what etas you're
interested in.

1965
01:54:13,060 --> 01:54:16,870
You're interested in 0,9, 0.95, 0.999,
something like that.

1966
01:54:16,870 --> 01:54:18,212
These are the ones you're interested in.

1967
01:54:18,212 --> 01:54:19,120
Okay.

1968
01:54:19,120 --> 01:54:20,700
For those, you get an SOCP.

1969
01:54:20,700 --> 01:54:21,225
You solve it.

1970
01:54:21,225 --> 01:54:24,160
But what's super interesting about this is
the following.

1971
01:54:25,930 --> 01:54:28,980
Is, mathematically it says that you get a
context problem provided eta is

1972
01:54:28,980 --> 01:54:31,520
bigger than half.

1973
01:54:31,520 --> 01:54:34,000
Right, so you get a very strange things.

1974
01:54:34,000 --> 01:54:36,190
Let's right down some values of eta here.

1975
01:54:36,190 --> 01:54:43,260
Let's have 0 point 1 and 0 point 9.

1976
01:54:43,260 --> 01:54:44,506
Right?
So this, this asymmetric interest in

1977
01:54:44,506 --> 01:54:45,960
whether we can solve this problem.

1978
01:54:47,170 --> 01:54:49,300
That's interesting because that's robust
optimiation.

1979
01:54:49,300 --> 01:54:51,990
That says I want the constraints to kind
of hold 90% of the time.

1980
01:54:51,990 --> 01:54:53,930
They can violate 10.

1981
01:54:53,930 --> 01:54:54,720
I don't want this.

1982
01:54:54,720 --> 01:54:59,320
I mean unless I'm in, unless I'm
absolutely desperate.

1983
01:54:59,320 --> 01:55:05,610
This says please find an x for which each
consraint holds one in 10 times.

1984
01:55:05,610 --> 01:55:06,690
So, you don't do that.

1985
01:55:06,690 --> 01:55:09,394
I mean, well, it all comes down to risk
aversion, right?

1986
01:55:09,394 --> 01:55:12,720
if, if you adverse to risk, this is quite
bad, right?

1987
01:55:12,720 --> 01:55:14,760
If your sucess rate is 10%.

1988
01:55:14,760 --> 01:55:17,440
Now, by the way, if you're, if you're in
some, eh,

1989
01:55:17,440 --> 01:55:22,070
this is some active, huge desperation, you
might take 10%.

1990
01:55:22,070 --> 01:55:25,045
But, generally we're not interested in it.

1991
01:55:25,045 --> 01:55:28,220
And that's super good, because guess what.

1992
01:55:28,220 --> 01:55:29,600
You can't solve that problem anyway.

1993
01:55:29,600 --> 01:55:34,620
You can solve this one because its an s of
c p.

1994
01:55:34,620 --> 01:55:37,720
These are actually quite difficult
problems and you can't solve em anyway.

1995
01:55:37,720 --> 01:55:41,070
So you get this weird asymmetry.

1996
01:55:41,070 --> 01:55:42,030
There's two problems.

1997
01:55:42,030 --> 01:55:45,995
We as a practical matter these are the
ones that we really want to solve and

1998
01:55:45,995 --> 01:55:49,375
we don't really care about these And then
as fate would have it,

1999
01:55:49,375 --> 01:55:57,280
it turns out the competition complexity of
the two problems is hugely different.

2000
01:55:57,280 --> 01:56:01,940
And it turns out, the one we want to solve
is exactly the one we can solve.

2001
01:56:03,040 --> 01:56:09,355
The one that we don't really want to solve
is the one we can't solve anyway.

2002
01:56:09,355 --> 01:56:11,519
So I don't know.

2003
01:56:11,519 --> 01:56:12,560
It's kind of cool.

2004
01:56:12,560 --> 01:56:15,200
I mean, you might imagine a world where we
would have 2

2005
01:56:15,200 --> 01:56:18,560
versions of various problems and there be
the ones we want to solve,

2006
01:56:18,560 --> 01:56:24,720
the ones we don't want to solve, the ones
we can solve, the ones not solved.

2007
01:56:24,720 --> 01:56:28,670
And yo might imagine they might split as
0.25.25.25.25, right.

2008
01:56:28,670 --> 01:56:30,320
So, in other words, Whether or

2009
01:56:30,320 --> 01:56:35,620
not we can solve a problem is independent
of whether we want to solve it.

2010
01:56:35,620 --> 01:56:39,250
But and this is just as a weird, I mean
don;t take any of these too seriously.

2011
01:56:39,250 --> 01:56:42,420
But as a weird observation, the following
holds.

2012
01:56:43,980 --> 01:56:47,824
There's strong correlation between the
problems that we want to solve and

2013
01:56:47,824 --> 01:56:49,725
the one we can't.

2014
01:56:49,725 --> 01:56:54,229
So, it's bizarre, but it's to be true, and
this is an example of it.

2015
01:56:54,229 --> 01:57:00,880
The next application we're going to talk
about is geometric programming.

2016
01:57:00,880 --> 01:57:04,078
And this is fun because it's in a
different group,

2017
01:57:04,078 --> 01:57:08,590
a different typeof convex optimization
problem.

2018
01:57:08,590 --> 01:57:12,880
It's one Then in one form, it's natural
form is actually not a convex problem so

2019
01:57:12,880 --> 01:57:17,104
it's a problem well, we'll see it's not
convex but you change variable and

2020
01:57:17,104 --> 01:57:20,490
it becomes convex.

2021
01:57:20,490 --> 01:57:23,670
So that's what's interesting about the
next class of problems.

2022
01:57:23,670 --> 01:57:25,249
So that's geometric programming.

2023
01:57:25,249 --> 01:57:29,803
So first a couple of definitions in
geometric programming you were referred to

2024
01:57:29,803 --> 01:57:35,290
a monomial as a function that looks like
this it is a Product.

2025
01:57:35,290 --> 01:57:38,150
Their variables, the variables are all
positive in geometric programming so

2026
01:57:38,150 --> 01:57:40,490
they're all positive numbers.

2027
01:57:40,490 --> 01:57:45,250
Its a product of these variables, each one
raised to a real power.

2028
01:57:45,250 --> 01:57:47,482
So these coefficients a one, a two, up to
a n,

2029
01:57:47,482 --> 01:57:50,520
they can be negative, they can be
fractional, anything and

2030
01:57:50,520 --> 01:57:55,930
the coefficient has to be positive and
this is called a monomial.

2031
01:57:55,930 --> 01:57:59,820
Now I should say that there is a
definition of monomial.

2032
01:57:59,820 --> 01:58:03,560
Its been used for a hundred or maybe more
than probably more than a hundred years in

2033
01:58:03,560 --> 01:58:08,230
mathematics and this is like it but its
not at all the same thing.

2034
01:58:08,230 --> 01:58:11,590
A monomial in mathematics is a single term
polynomial but

2035
01:58:11,590 --> 01:58:15,370
here these coefficients a one through a n
Have to be integers,

2036
01:58:15,370 --> 01:58:22,480
non negative integers and the coefficient
in front, c, can have any sign.

2037
01:58:22,480 --> 01:58:25,864
So unfortunately, if someone says
monomial, you have to

2038
01:58:25,864 --> 01:58:30,760
determine whether that's in the very
narrow context of geometric programming Or

2039
01:58:30,760 --> 01:58:37,160
whether that is in the broader context of
just mathematics.

2040
01:58:37,160 --> 01:58:38,723
Anyway.
So, we'll call it a monomial.

2041
01:58:38,723 --> 01:58:47,266
Now a, a posynomial is I mean in addition
to being very, very awkward nomenclature.

2042
01:58:47,266 --> 01:58:52,161
And it's supposed to be a combination of
polynomial and positive.

2043
01:58:52,161 --> 01:58:55,820
So anyway, who knows why this term was
coined?

2044
01:58:55,820 --> 01:58:58,188
It was, this was coined in the early 60s.

2045
01:58:58,188 --> 01:59:00,120
And it's simply a sum of monomial.

2046
01:59:00,120 --> 01:59:02,515
So it has a form that looks like that.

2047
01:59:02,515 --> 01:59:06,668
and, and it's not quite the same as a
positive polynomial.

2048
01:59:06,668 --> 01:59:13,400
however, if you have a polynomial with
non-negative coefficients.

2049
01:59:13,400 --> 01:59:15,406
That is a posynomial.

2050
01:59:15,406 --> 01:59:19,550
But posynomials is much broader because it
has, these coeffecients can be negative,

2051
01:59:19,550 --> 01:59:23,470
the, sorry the exponents, and, they can
also be fractional, which is not true for

2052
01:59:23,470 --> 01:59:26,040
a polynomial.

2053
01:59:26,040 --> 01:59:28,220
Okay.
And finally we get to a geometric program,

2054
01:59:28,220 --> 01:59:30,335
that is an optimization problem that looks
like this and

2055
01:59:30,335 --> 01:59:34,660
at first it's, there's going to be
something a little bit strange about it.

2056
01:59:36,450 --> 01:59:39,988
Its minimize a posynomial because all the
f's are going to be posynomial,

2057
01:59:39,988 --> 01:59:44,640
subject to posynomial inequalities and the
right hand side is one.

2058
01:59:45,980 --> 01:59:49,571
Well it has to be one because a monomial
and a posynomial the value for

2059
01:59:49,571 --> 01:59:53,750
any partiuclar x is actually going to be
positive.

2060
01:59:53,750 --> 02:00:00,810
So the value's positive so They, you could
never have x less than or equal to zero.

2061
02:00:00,810 --> 02:00:03,884
I mean if you did, the problem would be
easy to solve, there's no,

2062
02:00:03,884 --> 02:00:05,866
it's infeasible.

2063
02:00:05,866 --> 02:00:08,532
So it's less than or equal to one and then
a bunch, and

2064
02:00:08,532 --> 02:00:14,360
then the equality constraints have the
form of a mononomial equal to one, right?

2065
02:00:14,360 --> 02:00:21,060
So this is very, very different from what
you would C in a convex problem.

2066
02:00:21,060 --> 02:00:24,360
In a convex problem of course all equality
strains have to be affine.

2067
02:00:24,360 --> 02:00:29,210
Here's one where these are decidedly not
affine.

2068
02:00:29,210 --> 02:00:32,982
Oh, one other connection to things people
talk about in

2069
02:00:32,982 --> 02:00:38,180
areas like mechanics people talk about a
scaling law.

2070
02:00:38,180 --> 02:00:41,050
That's another name by the way for
something like a scaling law.

2071
02:00:41,050 --> 02:00:45,810
it says something like F scales as x1 to
the 1, x2 to the minus 2.3 or

2072
02:00:45,810 --> 02:00:50,760
something, and so that's a scaling law.

2073
02:00:50,760 --> 02:00:53,366
So some people would even call a monomial
a scaling law.

2074
02:00:53,366 --> 02:00:56,098
Okay, so that's a geometric program.

2075
02:00:56,098 --> 02:01:00,130
And it is obviously not a convex problem.

2076
02:01:00,130 --> 02:01:03,238
I mean for example, square root of x.

2077
02:01:03,238 --> 02:01:05,630
Is a mononomial, which is of course
therefore a posynomial, so

2078
02:01:05,630 --> 02:01:07,670
I can minimize square root of x.

2079
02:01:07,670 --> 02:01:08,677
But the square root of,

2080
02:01:08,677 --> 02:01:13,061
the square root of a variable x it's a
concave function, it's not convex.

2081
02:01:13,061 --> 02:01:17,520
And of course you could add things like
this, x1 x2 equals 1.

2082
02:01:17,520 --> 02:01:22,728
The product, that's obviously not convex
so, but this is a gp.

2083
02:01:22,728 --> 02:01:24,012
Okay.

2084
02:01:24,012 --> 02:01:25,836
Now, the interesting thing about GPs,

2085
02:01:25,836 --> 02:01:30,570
which are not convex, is that they can be
transformed to be convex problems.

2086
02:01:30,570 --> 02:01:33,606
By actually, you take two changes of
variables, and

2087
02:01:33,606 --> 02:01:36,300
they're both very interesting.

2088
02:01:36,300 --> 02:01:37,560
And I'll, I'll say what they are.

2089
02:01:37,560 --> 02:01:38,515
The first is this.

2090
02:01:38,515 --> 02:01:41,664
All our variables are positive, so As
actually happens,

2091
02:01:41,664 --> 02:01:46,820
I mean a lot of people have just figure
out for other reasons.

2092
02:01:46,820 --> 02:01:50,140
when you have a problem setting where all
variables are possible.

2093
02:01:50,140 --> 02:01:54,460
But it's actually often a good idea to
work with the logs of the variables.

2094
02:01:54,460 --> 02:01:55,640
Fine.

2095
02:01:55,640 --> 02:01:56,660
And in fact, that's correct.

2096
02:01:56,660 --> 02:01:59,283
If someone is talk, telling you about a
scaling log,

2097
02:01:59,283 --> 02:02:02,635
they'll plot something on a log log plot.

2098
02:02:02,635 --> 02:02:07,190
The fact that the second log, that would
be the log on the horizontal axis.

2099
02:02:07,190 --> 02:02:08,000
That is used.

2100
02:02:08,000 --> 02:02:08,930
It's a logarithmic scale.

2101
02:02:08,930 --> 02:02:11,080
that says that you should really work at
the log of the variable.

2102
02:02:11,080 --> 02:02:14,240
So, well we'll take yi's to be the log of
the variables.

2103
02:02:14,240 --> 02:02:16,060
And that means they're unconstrained.

2104
02:02:16,060 --> 02:02:17,846
They're not constrained to be positive.Oh
I should say,

2105
02:02:17,846 --> 02:02:19,620
that there is an implicit constraint.

2106
02:02:19,620 --> 02:02:27,290
That a monomial and posynomial domain is
positive, right?

2107
02:02:27,290 --> 02:02:29,145
And it actually has to be strictly
positive.

2108
02:02:29,145 --> 02:02:33,040
If any of these alphas are negative, of
course.

2109
02:02:33,040 --> 02:02:33,772
Okay.

2110
02:02:33,772 --> 02:02:38,084
Alright, now if you take a monomial and
you take [COUGH] and

2111
02:02:38,084 --> 02:02:43,188
you write each xi as e to the yi, and you
take a product of e to the yi as if I

2112
02:02:43,188 --> 02:02:48,292
take something like e to the y1 to the a1,
and I take this product times e

2113
02:02:48,292 --> 02:02:57,280
to the y n to the an, and I put a c in
front of it.

2114
02:02:57,280 --> 02:02:59,820
That's the minomial expressed in the y
variables.

2115
02:02:59,820 --> 02:03:01,660
But you know what that is, it has the
form.

2116
02:03:01,660 --> 02:03:06,368
I'm going to write it this way; e to the,
this is exactly,

2117
02:03:06,368 --> 02:03:15,150
e to the a transpose y plus b, where b is
log of c, the constant.

2118
02:03:15,150 --> 02:03:18,835
And that's of course where we need, this
is where we need c to be positive.

2119
02:03:18,835 --> 02:03:19,870
Right.

2120
02:03:19,870 --> 02:03:23,020
And so that says that a monomial in the
variables y,

2121
02:03:23,020 --> 02:03:29,662
these logorithmic variables, is actualy an
exponential of an affine function.

2122
02:03:29,662 --> 02:03:36,152
Okay, so if you take the log of a monomial
you get an affine function.

2123
02:03:36,152 --> 02:03:39,756
When it's expressed, when it's expressed
in terms of the logs of

2124
02:03:39,756 --> 02:03:44,584
the original variablces so you would say
something like this monomial transforms do

2125
02:03:44,584 --> 02:03:50,150
an affine function with two logrythmic
transformations.

2126
02:03:50,150 --> 02:03:52,150
The first one you work not with the
variables but

2127
02:03:52,150 --> 02:03:55,810
with the log of the variables that is sort
of before.

2128
02:03:55,810 --> 02:03:57,010
Cause you transform the variables.

2129
02:03:57,010 --> 02:04:00,350
You then also transform the monomial
itself.

2130
02:04:00,350 --> 02:04:02,540
The monomial itself transforms.

2131
02:04:02,540 --> 02:04:06,726
You take the log of it, and that
transforms this into, so

2132
02:04:06,726 --> 02:04:13,660
you do a posterior, and a prior
logarithmic transformation.

2133
02:04:13,660 --> 02:04:14,996
And you end up with something that's
affine.

2134
02:04:14,996 --> 02:04:18,480
A posynomial, that's something that looks
like this.

2135
02:04:18,480 --> 02:04:20,101
That, well it's the same thing.

2136
02:04:20,101 --> 02:04:23,840
Each each of the monomials looks like
that.

2137
02:04:23,840 --> 02:04:25,970
It's an exponential of an affine function.

2138
02:04:25,970 --> 02:04:26,520
You sum them.

2139
02:04:26,520 --> 02:04:28,890
That is afterall what a posynomial is.

2140
02:04:28,890 --> 02:04:32,300
And you take a log and you see something
super cool.

2141
02:04:32,300 --> 02:04:36,724
that the log of a posynomial expressed in
logarithmic variables.

2142
02:04:36,724 --> 02:04:42,410
Is the log sum x of an affine function.

2143
02:04:42,410 --> 02:04:43,760
That's it.

2144
02:04:43,760 --> 02:04:46,375
So actually its really cool.

2145
02:04:46,375 --> 02:04:49,714
Binomials have been transformed by a duo
logarithmic transformation into

2146
02:04:49,714 --> 02:04:53,371
affine functions and posynomials have been
transformed into convex functions by

2147
02:04:53,371 --> 02:04:56,140
duo logarithmic transformation.

2148
02:04:56,140 --> 02:05:00,506
By duo I mean that you take the log of the
vaiables and work with those and

2149
02:05:00,506 --> 02:05:07,003
also you take the log of the So that gp
converts to this problem.

2150
02:05:07,003 --> 02:05:10,423
It's minimize log sum exp of affine,

2151
02:05:10,423 --> 02:05:17,728
subject to log sum exp of affine less than
0, and affine.

2152
02:05:17,728 --> 02:05:22,900
And Sure enough, it is a convex problem,
right?

2153
02:05:22,900 --> 02:05:24,748
And so the meaning is this,

2154
02:05:24,748 --> 02:05:30,530
the practical meaning is that if you see a
GP we can solve it.

2155
02:05:30,530 --> 02:05:33,290
We can solve it globally, we can do every,
no, we can do anything you want,

2156
02:05:33,290 --> 02:05:37,330
We can do it, we have strong guarantees,
we can find a global solution.

2157
02:05:37,330 --> 02:05:38,270
All sorts of things like that.

2158
02:05:38,270 --> 02:05:39,080
It's basically.

2159
02:05:40,270 --> 02:05:43,260
And sometimes people say GP is convex.

2160
02:05:43,260 --> 02:05:47,190
Technically, that's false; this is not a
convex problem.

2161
02:05:47,190 --> 02:05:48,846
And if I were to write down an instance of
it,

2162
02:05:48,846 --> 02:05:51,980
this, generally speaking, is not a convex
problem, right?

2163
02:05:51,980 --> 02:05:55,651
You can do things like minimize the square
root of a variable.

2164
02:05:55,651 --> 02:06:00,290
You can handle Equality constraints, lets
say that x one times x two equals one.

2165
02:06:00,290 --> 02:06:02,194
These are not convex constraints and yet

2166
02:06:02,194 --> 02:06:06,514
we can solve this by change of variables,
transformation of variables.

2167
02:06:06,514 --> 02:06:10,048
By the way you don't, when you actually
solve it the data is the same so

2168
02:06:10,048 --> 02:06:12,116
not much changes.

2169
02:06:12,116 --> 02:06:16,591
So in other words in the GP, so the data
are the same.

2170
02:06:16,591 --> 02:06:19,200
In to describe a GP.

2171
02:06:19,200 --> 02:06:23,043
What I have to do is for each monomial
term in the object, in the objective and

2172
02:06:23,043 --> 02:06:27,069
the constraint functions, and for each
monomial in the equality constraints,

2173
02:06:27,069 --> 02:06:31,934
I have to give you the coefficient and
exponents.

2174
02:06:31,934 --> 02:06:34,810
But that's t he same here.

2175
02:06:34,810 --> 02:06:37,160
Right?
And they simply are the coefficients here.

2176
02:06:37,160 --> 02:06:39,782
So, so it's absolutely no different.

2177
02:06:39,782 --> 02:06:43,743
OK.
Now you know what a GP is.

2178
02:06:43,743 --> 02:06:46,863
And what's interesting now is, it turns
out, this is something that, you know,

2179
02:06:46,863 --> 02:06:50,333
it goes back to the 60s, a few people know
about it.

2180
02:06:50,333 --> 02:06:53,383
actually, remarkably, it was not known
widely that this was

2181
02:06:53,383 --> 02:06:57,650
a complex optimization problem actually
even into the 80s.

2182
02:06:57,650 --> 02:07:00,840
So there'd be people who'd write articles
saying something like,

2183
02:07:00,840 --> 02:07:04,726
they'd invented a new method for GP and
they could solve a problem Well, you know,

2184
02:07:04,726 --> 02:07:10,990
with up to fifty variables in mere
minutes, or something like that.

2185
02:07:10,990 --> 02:07:14,106
So it was only, yes, it was indeed in
Moscow that it

2186
02:07:14,106 --> 02:07:21,030
was observed that this transformation
makes this a part of convex optimization.

2187
02:07:21,030 --> 02:07:26,990
So any method for convex optimization can
be applied to GP.

2188
02:07:26,990 --> 02:07:31,440
That tells you, you can solve GPs with
tens of thousands or many more variables.

2189
02:07:31,440 --> 02:07:35,035
Using just completely basic methods.

2190
02:07:35,035 --> 02:07:39,591
Oh I should also mention, there's actually
a wonderful the original book on GP

2191
02:07:39,591 --> 02:07:42,338
which in fact popularized not only the
term GP but

2192
02:07:42,338 --> 02:07:48,120
also this bad nomenclature, monomial and
posynomial.

2193
02:07:48,120 --> 02:07:49,140
The book is absolutely wonderful.

2194
02:07:49,140 --> 02:07:50,676
It goes through and it actually talks,

2195
02:07:50,676 --> 02:07:53,268
it describes a whole bunch of GP's
applications to like you know,

2196
02:07:53,268 --> 02:07:56,860
power transformer design and all sorts of
other stuff.

2197
02:07:57,990 --> 02:08:01,230
And in fact the book focuses on problems
you can solve exactly.

2198
02:08:01,230 --> 02:08:02,430
Right, so they reduce it to this, and

2199
02:08:02,430 --> 02:08:05,850
they have maybe two constraints, three
constraints, and something like that.

2200
02:08:05,850 --> 02:08:07,400
And they, they solve these things exactly.

2201
02:08:07,400 --> 02:08:10,320
And the very last paragraph in the book.

2202
02:08:10,320 --> 02:08:11,250
Just truly wonderful.

2203
02:08:11,250 --> 02:08:14,514
The very last chapter says that, it says
that it says that,

2204
02:08:14,514 --> 02:08:18,034
that solving gps in, in cases when you
can't do it by hand, and I,

2205
02:08:18,034 --> 02:08:22,800
I mean literally by hand, you know,
calculus.

2206
02:08:22,800 --> 02:08:23,820
You get out your old pen and paper and

2207
02:08:23,820 --> 02:08:26,165
start writing derivatives down and things
like that.

2208
02:08:26,165 --> 02:08:30,925
It says that it's entirely possible that
by programming computers correctly

2209
02:08:30,925 --> 02:08:34,800
A computer could automatically solve a GP.

2210
02:08:34,800 --> 02:08:36,814
So, I mean, anyway, I thought that was
kind of cool.

2211
02:08:36,814 --> 02:08:42,270
And it turns out, that was from, that's a
book from 1961 or something like that.

2212
02:08:42,270 --> 02:08:45,880
The answer is, you fast forward whatever
it is, 30, 40 years.

2213
02:08:45,880 --> 02:08:49,490
The answer is, you bet, and that's exactly
what's happened.

2214
02:08:49,490 --> 02:08:50,024
Okay.
So

2215
02:08:50,024 --> 02:08:52,584
what we're going to do now is actually
just look at,

2216
02:08:52,584 --> 02:08:56,230
we're just going to look at one example of
a GP.

2217
02:08:56,230 --> 02:08:58,784
It is a non-trivial one.

2218
02:08:58,784 --> 02:09:02,690
And it's, you know, taken from a book from
mechanicial, mechanial design.

2219
02:09:02,690 --> 02:09:05,853
And it's designed to [UNKNOWN] a lever
beam.

2220
02:09:05,853 --> 02:09:06,775
So here it is.

2221
02:09:06,775 --> 02:09:09,620
We're going to design a beam that looks
like this.

2222
02:09:09,620 --> 02:09:13,340
Its going to have segments here and each
of these beams, they're going to

2223
02:09:13,340 --> 02:09:19,180
be connected and then I'm going to simply
put a force at the tip of this beam.

2224
02:09:19,180 --> 02:09:20,510
I should say what our variables are.

2225
02:09:20,510 --> 02:09:22,920
Our variables are these beams.

2226
02:09:22,920 --> 02:09:26,750
We can do the height so you can see the
height here That's HI.

2227
02:09:26,750 --> 02:09:29,740
What you can't see is the width, because
the width would come out of the page here.

2228
02:09:29,740 --> 02:09:32,934
So that's the, the width of the, of it.

2229
02:09:32,934 --> 02:09:35,043
And what is completely clear is sort of
that,

2230
02:09:35,043 --> 02:09:37,742
the stronger, this cantilevered beam.

2231
02:09:37,742 --> 02:09:39,204
It's, it's bigger.

2232
02:09:39,204 --> 02:09:44,480
Then it's, I mean it's, even if you have
deeper segments and wider segments.

2233
02:09:44,480 --> 02:09:48,197
It stronger, it's stiffer, and its stiffer
means that if apply this force at

2234
02:09:48,197 --> 02:09:52,340
the tip it says that the beam will deflect
less, right?

2235
02:09:52,340 --> 02:09:55,805
So roughly speaking, what happens is, I
can put a lot of deal in my being,and I

2236
02:09:55,805 --> 02:09:58,280
can put a big force it will deflect only a
little bit, or

2237
02:09:58,280 --> 02:10:01,140
I can make these things pretty wimpy and
you know flat, and, and

2238
02:10:01,140 --> 02:10:07,910
very weight very lightweight but the point
then is it'll be quite flexible.

2239
02:10:07,910 --> 02:10:09,765
You put of force and it will bend quite a
bit.

2240
02:10:09,765 --> 02:10:13,620
Right and you probably also have some
basic intuition about it.

2241
02:10:13,620 --> 02:10:16,536
For example, if you thought about these
things mechanically and

2242
02:10:16,536 --> 02:10:20,750
if you fiddle with things build things
with wood or anything else.

2243
02:10:20,750 --> 02:10:23,886
You probably have some intuition telling
you that height gives you

2244
02:10:23,886 --> 02:10:26,210
more stiffness than width.

2245
02:10:26,210 --> 02:10:26,972
Right?
You probably,

2246
02:10:26,972 --> 02:10:29,096
you may know that if you're trained in
mechanical engineering, you for

2247
02:10:29,096 --> 02:10:31,560
sure know that, or civil engineering, you
know that.

2248
02:10:31,560 --> 02:10:34,244
But even if you don't, you should have
that intuition, right, that, well,

2249
02:10:34,244 --> 02:10:35,760
think of it this way.

2250
02:10:35,760 --> 02:10:39,237
If I take a 2 by 12, it's a whole lot
stronger if I push, if I set it end up,

2251
02:10:39,237 --> 02:10:42,409
like this, push on this end, then if I
turn it flat like that, and

2252
02:10:42,409 --> 02:10:45,790
push on that end.

2253
02:10:45,790 --> 02:10:46,610
It's a lot stronger.

2254
02:10:46,610 --> 02:10:47,815
So, anyway.

2255
02:10:47,815 --> 02:10:49,882
So the variables are we're going to
calculation,

2256
02:10:49,882 --> 02:10:53,585
we're going to optimize the
cross-sectional area of each segment.

2257
02:10:53,585 --> 02:10:55,890
So it's actually kind of an in interesting
beam, right.

2258
02:10:55,890 --> 02:10:56,970
It can actually change shape.

2259
02:10:56,970 --> 02:10:59,910
It can be deeper and it can taper to
something thinner.

2260
02:10:59,910 --> 02:11:02,210
I mean who knows what it is right.

2261
02:11:02,210 --> 02:11:02,910
And here's what we want.

2262
02:11:04,251 --> 02:11:06,750
We're going to minimize the total weight
of this thing.

2263
02:11:06,750 --> 02:11:10,764
That's the total amount of steel I mean if
it's made out of steel.

2264
02:11:10,764 --> 02:11:16,650
And that weight is usually a surrogate in
a design like this for cost.

2265
02:11:16,650 --> 02:11:17,390
Something like that.

2266
02:11:17,390 --> 02:11:19,790
So, it's the tot, we'll minimize total
weight.

2267
02:11:19,790 --> 02:11:22,550
We'll have upper and lower bounds on the
width and height.

2268
02:11:22,550 --> 02:11:25,480
You'll have a maximum and a lower and a,
and a minimum for each one.

2269
02:11:25,480 --> 02:11:27,971
And we can do upper and lower bound on the
aspect ratio, so

2270
02:11:27,971 --> 02:11:32,820
you can't make something that has an
aspect, you know, that looks like this.

2271
02:11:32,820 --> 02:11:34,270
Right?
Where it's super thin and too high and

2272
02:11:34,270 --> 02:11:36,510
you can't make something that looks like
that.

2273
02:11:36,510 --> 02:11:38,103
You probably wouldn't want to make
something that looks like that, but

2274
02:11:38,103 --> 02:11:39,960
you can't do it anyway.

2275
02:11:39,960 --> 02:11:43,538
So we'll have as, we'll have upper and
lower bounds on the as, aspect ratios.

2276
02:11:43,538 --> 02:11:47,520
What we'll do is we'll have an upper bound
on the stress in each segment.

2277
02:11:47,520 --> 02:11:51,302
So in each segment here when you load it
there's actually a stress here and

2278
02:11:51,302 --> 02:11:54,836
I I'm not going to go into what that is or
I will tell you exactly how its

2279
02:11:54,836 --> 02:12:02,130
calculated and I guess if your background
is in ME you would know these formulas.

2280
02:12:02,130 --> 02:12:05,826
We're going to have an upper bound on the
stress cause you know one one of the very

2281
02:12:05,826 --> 02:12:09,634
simple models of Mechanical failure is
that you have a maximum allowed stress and

2282
02:12:09,634 --> 02:12:13,386
if you exceed that you start getting
platsic flow or something like that, but

2283
02:12:13,386 --> 02:12:16,746
it doesn't matter for this problem we have
a maximum amount of stress and

2284
02:12:16,746 --> 02:12:24,011
we have another bound on verticle
deflection on the end of the beam.

2285
02:12:24,011 --> 02:12:27,586
That's here and that's going to be
soemthing like a surrogate That is

2286
02:12:27,586 --> 02:12:31,445
a surrogate for how stiff the structure
is.

2287
02:12:31,445 --> 02:12:35,000
if, if it deflects a lot, that's bad; it's
not stiff.

2288
02:12:35,000 --> 02:12:39,194
And if it deflects a little bit, that's
good; it's a stiff structure, okay.

2289
02:12:39,194 --> 02:12:43,548
And the variables are the widths and
heights, just to, to remind you.

2290
02:12:43,548 --> 02:12:44,476
Okay?

2291
02:12:44,476 --> 02:12:48,949
So alright, now the objective looks like
this, it's it's the sum of W I H I,

2292
02:12:48,949 --> 02:12:53,138
all the way up to H N W N, that's cross
sectional areas, and if the length,

2293
02:12:53,138 --> 02:13:01,030
all these things have the same length, so
you could multiply these by L.

2294
02:13:01,030 --> 02:13:03,730
And I guess to really get a weight you
then multiply by density of steel or

2295
02:13:03,730 --> 02:13:05,950
the, whatever the material is.

2296
02:13:05,950 --> 02:13:08,720
I mean, it, that's just a positive
constant, so we're not going to show it.

2297
02:13:08,720 --> 02:13:11,073
But look at this function.

2298
02:13:11,073 --> 02:13:12,110
It's a sum.

2299
02:13:12,110 --> 02:13:14,830
Well, it's actually to help you transpose
h.

2300
02:13:14,830 --> 02:13:18,560
That for sure is not convex, in w and h.

2301
02:13:18,560 --> 02:13:20,630
There's absolutely no doubt about it.

2302
02:13:20,630 --> 02:13:22,267
I'll tell you what this thing is though.

2303
02:13:22,267 --> 02:13:27,050
It's quadratic, so that is a quadratic
function of W and H.

2304
02:13:27,050 --> 02:13:31,722
But it is definitely not, I shouldn't have
used the word definitely, it is

2305
02:13:31,722 --> 02:13:38,747
definitely not convex, because the matrix
is not positive semi [UNKNOWN], right?

2306
02:13:38,747 --> 02:13:42,820
This is an It's a, it's a term, looks like
that.

2307
02:13:42,820 --> 02:13:46,256
There's sort of an i and an i and a 0 and
a 0, and this is your wh.

2308
02:13:46,256 --> 02:13:47,926
Right?

2309
02:13:47,926 --> 02:13:49,596
Right?

2310
02:13:49,596 --> 02:13:56,060
And so, this is, indeed looks like that
this quadratic form is this.

2311
02:13:56,060 --> 02:13:58,580
But of course this thing has split Eigen
values and

2312
02:13:58,580 --> 02:14:01,760
it's not, it's neither convex nor concave.

2313
02:14:01,760 --> 02:14:03,237
Right?
So the point here is just to show,

2314
02:14:03,237 --> 02:14:04,830
this is not a convex function.

2315
02:14:05,880 --> 02:14:09,400
Now, what is interesting is this a convex
function if

2316
02:14:09,400 --> 02:14:14,080
you work with the variables log w i and
log h i.

2317
02:14:14,080 --> 02:14:19,180
So if you work with the logs of the widths
and the heights, it's convex function.

2318
02:14:19,180 --> 02:14:19,748
Okay.

2319
02:14:19,748 --> 02:14:24,678
Now the aspect ratio and the, and the
inverse aspect ratio.

2320
02:14:24,678 --> 02:14:28,826
These are monomials, because this is
really h i to the 1 Wi to the minus 1 and

2321
02:14:28,826 --> 02:14:35,980
if you like you can put in all the other
h's and w's but to the zeroth power.

2322
02:14:35,980 --> 02:14:41,350
Okay, so that's the monomial, these are,
these are monomials, these things, okay?

2323
02:14:41,350 --> 02:14:47,110
So those are monomials, therefore by the
way, they're also hosinomials, right?

2324
02:14:47,110 --> 02:14:50,709
So for example if I tell you that the
aspect ratio has to be limited to 3 to 1,

2325
02:14:50,709 --> 02:14:55,212
no more than 3 to 1, I can write hi over
wi less than 3.

2326
02:14:56,230 --> 02:14:59,360
That is the same as one-third hi of wi
less than one.

2327
02:14:59,360 --> 02:15:03,398
That's a monomial constraint.

2328
02:15:03,398 --> 02:15:06,340
Now, the maximum stress on a segment is
given this way.

2329
02:15:06,340 --> 02:15:09,310
It's 6 times i, i is the segment number.

2330
02:15:09,310 --> 02:15:11,559
And I'm missing some constants in here,
right?

2331
02:15:11,559 --> 02:15:15,147
Some, you know, things like Young's
modulus and various other things.

2332
02:15:15,147 --> 02:15:16,440
There's things I'm just missing.

2333
02:15:16,440 --> 02:15:17,220
I'm not showing here.

2334
02:15:17,220 --> 02:15:18,570
And that doesn't matter.

2335
02:15:18,570 --> 02:15:20,950
i is the length the, is the.

2336
02:15:20,950 --> 02:15:21,620
Section number.

2337
02:15:21,620 --> 02:15:25,615
It basically tells you how far out the
beam you are, the [UNKNOWN] beam.

2338
02:15:25,615 --> 02:15:29,989
And it's divided by wi over this is
positive constant times wi

2339
02:15:29,989 --> 02:15:32,420
over hi squared.

2340
02:15:32,420 --> 02:15:33,820
That's a monomial, right.

2341
02:15:33,820 --> 02:15:37,478
So if I wanted to limit the maxium stress
that is absolutely a monomial,

2342
02:15:37,478 --> 02:15:40,725
that that is a monomial function.

2343
02:15:40,725 --> 02:15:45,345
Now the vertical deflection is to
calculate, you actually have to

2344
02:15:45,345 --> 02:15:52,400
calculate the vertical inflection and the
slope at each of the segments.

2345
02:15:52,400 --> 02:15:57,296
And these are done recursively, and it's
by a set of equations that works this way,

2346
02:15:57,296 --> 02:16:01,400
and they work backward from the tip, and
it says something like this,

2347
02:16:01,400 --> 02:16:08,050
it says VI Is equal to 12 times i minus 1
times this thing.

2348
02:16:08,050 --> 02:16:11,350
And I, I, I certainly won't go into any of
this, or where this comes from.

2349
02:16:11,350 --> 02:16:12,700
That's, that's that.

2350
02:16:12,700 --> 02:16:17,441
And then, y i is then given by this
formula, here.

2351
02:16:17,441 --> 02:16:22,955
And you start with vn plus 1 is yn plus 1
is 0.

2352
02:16:22,955 --> 02:16:25,310
Right.

2353
02:16:25,310 --> 02:16:27,855
And here E is Young's modulus.

2354
02:16:27,855 --> 02:16:31,375
And what, what we're going to do, the way
I'm going to argue that vi and yi

2355
02:16:31,375 --> 02:16:35,663
are posynomial functions and I'm going to
use And a very important property and so,

2356
02:16:35,663 --> 02:16:41,770
these are obvious things, but let me just
mention them.

2357
02:16:41,770 --> 02:16:44,670
The product of two monomials is a
monomial.

2358
02:16:44,670 --> 02:16:45,540
That's the first thing.

2359
02:16:45,540 --> 02:16:46,820
That's, that should be clear.

2360
02:16:46,820 --> 02:16:49,660
In fact, le, let's just go back because
it's just a set of simple rules.

2361
02:16:49,660 --> 02:16:52,960
If you take a product of two monomials,
you get a monomials.

2362
02:16:52,960 --> 02:16:55,116
You take the product of the coefficients
in front and

2363
02:16:55,116 --> 02:16:58,760
you add the, the associative coefficient
exponents.

2364
02:16:58,760 --> 02:17:03,580
Okay?
Posynomials are, are closed under sums.

2365
02:17:03,580 --> 02:17:05,656
That's clear.

2366
02:17:05,656 --> 02:17:07,870
Positive scaling.

2367
02:17:07,870 --> 02:17:08,810
That's also clear.

2368
02:17:08,810 --> 02:17:10,529
That's also cle, clear for a pot,
monomial.

2369
02:17:10,529 --> 02:17:16,346
And also things like for example, you can
take the square of a posynomial.

2370
02:17:16,346 --> 02:17:17,540
That's posynomial.

2371
02:17:17,540 --> 02:17:21,158
See you have all sort of obvious Rules
about how you can add hm,

2372
02:17:21,158 --> 02:17:23,360
things like that.

2373
02:17:23,360 --> 02:17:25,820
For example, here's another one for
monomials.

2374
02:17:25,820 --> 02:17:28,790
Ready?
The ratio of two monomials is a monomial.

2375
02:17:28,790 --> 02:17:29,660
Well, that's kind of obvious.

2376
02:17:29,660 --> 02:17:31,660
Because you just simply divide one of
these by the other, and

2377
02:17:31,660 --> 02:17:33,023
you can work it out.

2378
02:17:33,023 --> 02:17:34,537
Okay.
So, so there's a bunch of,

2379
02:17:34,537 --> 02:17:39,170
you know, rules that tell you about which
things are closed under which operations.

2380
02:17:39,170 --> 02:17:39,950
Okay.

2381
02:17:41,380 --> 02:17:42,800
Now let's look at these equations.

2382
02:17:42,800 --> 02:17:45,060
These things start at zero.

2383
02:17:45,060 --> 02:17:47,394
I mean in some sense that's a null monome.

2384
02:17:47,394 --> 02:17:51,426
It's not really because for a monomial the
coefficient's supposed to be positive, but

2385
02:17:51,426 --> 02:17:52,970
in any case.

2386
02:17:52,970 --> 02:17:57,190
Let's look, let's look at the first one
which is v n and y n.

2387
02:17:57,190 --> 02:17:59,530
So these just go away because they're all
zero.

2388
02:17:59,530 --> 02:18:01,399
And we look at that and that's a monomial.

2389
02:18:03,120 --> 02:18:05,864
On the next step, if you look at v sub n
minus 1, y sub n minus 1,

2390
02:18:05,864 --> 02:18:10,570
what you get is you get something that
looks like that.

2391
02:18:10,570 --> 02:18:13,710
And you're using the fact that that is a,
that these are monomials here.

2392
02:18:13,710 --> 02:18:20,144
That these are monomials, it's a monomial
plus monomial, that makes it a posynomial.

2393
02:18:20,144 --> 02:18:24,176
So By induction all of the Is and YIs are
posinomyials, okay so that's what it

2394
02:18:24,176 --> 02:18:29,742
means and that's very interesting because
we're interested in YN.

2395
02:18:29,742 --> 02:18:34,007
That's the deflection at the end, so Y0.

2396
02:18:34,007 --> 02:18:36,667
Okay, so, we right it this way,

2397
02:18:36,667 --> 02:18:43,350
we're going to right Y1 sorry, we're
going to right it this way.

2398
02:18:43,350 --> 02:18:47,750
We're going to minimize this that's a
posinomylia Subject to,

2399
02:18:47,750 --> 02:18:52,430
this is the way to say w is less than w
max.

2400
02:18:52,430 --> 02:18:53,890
That's a maximum width,

2401
02:18:53,890 --> 02:19:00,120
that's a minimum width, that's a maximum
height, that's a minimum height.

2402
02:19:00,120 --> 02:19:03,760
You need a segment, this would be the
aspect ratio maximum, and

2403
02:19:03,760 --> 02:19:06,398
the aspect ratio minimum.

2404
02:19:06,398 --> 02:19:13,173
And then, here I would have this is the
stress limit, that's also very simple.

2405
02:19:13,173 --> 02:19:18,123
So far everything has been simple but here
this one, we use the fact that y1 is

2406
02:19:18,123 --> 02:19:25,752
a posynomial function of the w's and the
h's, and it's given by that recursion.

2407
02:19:25,752 --> 02:19:26,280
Right?

2408
02:19:26,280 --> 02:19:30,596
So, By the way, the same as in LP people
will write down an LP,

2409
02:19:30,596 --> 02:19:36,313
not in the standard form because it's
kind of weird.

2410
02:19:36,313 --> 02:19:38,914
They actually wind it, they write down an
LP in general as,

2411
02:19:38,914 --> 02:19:43,710
I mean where in the convenient ways So
people don't really write these things.

2412
02:19:43,710 --> 02:19:44,880
You would just write that.

2413
02:19:44,880 --> 02:19:46,710
And you would say that, that's a GP.

2414
02:19:46,710 --> 02:19:48,120
No problem.
Cause everyone in

2415
02:19:48,120 --> 02:19:51,470
their head would know how to convert this
to that.

2416
02:19:51,470 --> 02:19:53,900
And if you have a, if you have a, a
modelling system.

2417
02:19:53,900 --> 02:19:54,900
Like cvx.

2418
02:19:54,900 --> 02:19:57,890
You just write things like this and that's
automatic to transform to that.

2419
02:19:57,890 --> 02:19:59,605
So you would just write stuff like that
and

2420
02:19:59,605 --> 02:20:02,888
you would write things like that, a ratio
and they would say that's a monomial and

2421
02:20:02,888 --> 02:20:08,085
you can have monomial less than a constant
and monomial bigger than a constant.

2422
02:20:08,085 --> 02:20:13,350
So something, you don't write it, you
would rarely write it this way unless you

2423
02:20:13,350 --> 02:20:21,350
would raw call A GP solver where you had
to produce the data in the canonical form.

2424
02:20:21,350 --> 02:20:25,040
These days with things like CVX there's no
reason to do that.

2425
02:20:25,040 --> 02:20:27,382
This is a waste of your time, so.

2426
02:20:27,382 --> 02:20:32,182
The next topic is generalized inequality
constraints, and

2427
02:20:32,182 --> 02:20:37,460
let me explain a little bit about what it.

2428
02:20:37,460 --> 02:20:38,980
What it is before we start.

2429
02:20:38,980 --> 02:20:43,372
What we're going to do, is we're going to
look at these constraints here, and

2430
02:20:43,372 --> 02:20:48,300
we're going to generalize these functions
to be vectors.

2431
02:20:48,300 --> 02:20:52,350
Okay, so that means up to now they've been
scales right, so f,

2432
02:20:52,350 --> 02:20:57,320
if you evaluate F three of X, that's a
number.

2433
02:20:57,320 --> 02:21:02,460
And the requirement, this is less than or
equal to zero.

2434
02:21:02,460 --> 02:21:05,980
So if F three of X is, you know, minus
0.01, that's fine.

2435
02:21:05,980 --> 02:21:09,210
If F three of X is plus 0.01, that's
infinitely bad.

2436
02:21:09,210 --> 02:21:10,442
What we're going to do now,

2437
02:21:10,442 --> 02:21:14,190
is we're actually going to allow these
things to be vectors.

2438
02:21:14,190 --> 02:21:16,637
And we're going to see, what does this
mean.

2439
02:21:16,637 --> 02:21:19,005
You know, we'll figure it out.

2440
02:21:19,005 --> 02:21:22,140
Now, though we do have inequalities.

2441
02:21:22,140 --> 02:21:24,220
These are inequality with respect the the
cone.

2442
02:21:24,220 --> 02:21:26,860
And so we'll have an inequality with
respect to a cone.

2443
02:21:26,860 --> 02:21:30,110
And a requirement here to be a convex
problem is you have equality constraints

2444
02:21:30,110 --> 02:21:32,832
as the only equa, have to be linear.

2445
02:21:32,832 --> 02:21:38,870
And the inequalities, here you have fi is
convex, is ki convex.

2446
02:21:38,870 --> 02:21:40,150
Right?
so that means that

2447
02:21:40,150 --> 02:21:45,760
Jensen's inequality holds but with respect
to the inequality induced by k i.

2448
02:21:45,760 --> 02:21:49,552
OK and there's several there's several
forms for these.

2449
02:21:49,552 --> 02:21:51,400
Usually they're quite simple but

2450
02:21:51,400 --> 02:21:56,504
of one that's very common now is something
called a conic form problem.

2451
02:21:56,504 --> 02:21:59,936
Some people would even call this the
modern cononical form for

2452
02:21:59,936 --> 02:22:02,666
a convex optimization problem.

2453
02:22:02,666 --> 02:22:07,970
Its this You minimize a linear function,
subject to linear equality constraints

2454
02:22:07,970 --> 02:22:13,118
and, an affine function is negative, is,
less or equal to 0 in respect to a cone k,

2455
02:22:13,118 --> 02:22:19,850
and the idea here is, if you take K to BR
plus to the M.

2456
02:22:19,850 --> 02:22:23,380
This describes a completely general linear
program.

2457
02:22:23,380 --> 02:22:25,471
But the idea is now you swap in a
different cone and

2458
02:22:25,471 --> 02:22:28,028
you get a different problem family.

2459
02:22:28,028 --> 02:22:30,470
We'll some very interesting ones in a
minute.

2460
02:22:30,470 --> 02:22:31,800
A lot of these things have names.

2461
02:22:31,800 --> 02:22:33,196
We will see some of them.

2462
02:22:33,196 --> 02:22:37,820
And these are mostly things that have come
up in the last 15 years.

2463
02:22:37,820 --> 02:22:39,090
Something like that.

2464
02:22:40,950 --> 02:22:47,470
The most famous by far is a so called
semi-definite programmer FDP.

2465
02:22:47,470 --> 02:22:48,910
So this is the following problem.

2466
02:22:48,910 --> 02:22:53,860
It looks deceptively simple it says this
minimize a linear function subject to

2467
02:22:53,860 --> 02:23:00,590
linear quality constraints and inequality
that involves just Matrices.

2468
02:23:00,590 --> 02:23:01,310
A single one.

2469
02:23:01,310 --> 02:23:02,180
That's it.

2470
02:23:02,180 --> 02:23:05,706
So it just says take an affine function of
matrices,

2471
02:23:05,706 --> 02:23:09,972
that's x1 F1 plus x2 F2 plus xn Fn plus G.

2472
02:23:09,972 --> 02:23:11,940
That's a symmetric matrix.

2473
02:23:11,940 --> 02:23:14,245
And you insist that that be negative
semidefinite.

2474
02:23:14,245 --> 02:23:15,010
There.

2475
02:23:15,010 --> 02:23:19,298
Oh, by the way, a constraint of this form
is called a linear matrix inequality and

2476
02:23:19,298 --> 02:23:23,842
the idea is if I were to make this, this
inequality here an ordinary inequality and

2477
02:23:23,842 --> 02:23:30,790
make everything a scaler this would be a
single linear inequality.

2478
02:23:30,790 --> 02:23:33,978
But now I simply capatilze the epson gs.

2479
02:23:33,978 --> 02:23:37,461
So the left-hand side is now a symmetric
matrix, and

2480
02:23:37,461 --> 02:23:42,645
I take the inequality on R and I make an
inequality on symmetric matrices, and

2481
02:23:42,645 --> 02:23:48,390
I get the so-called linear matrix
inequality.

2482
02:23:48,390 --> 02:23:52,166
So, minimize the linear function subject
to quality constraints, and

2483
02:23:52,166 --> 02:23:55,626
a single LMI, that's what these are
called.

2484
02:23:55,626 --> 02:23:58,380
That's a semidefiniate program.

2485
02:23:58,380 --> 02:24:01,848
And that's an example of a convex
optiumization problem with

2486
02:24:01,848 --> 02:24:04,672
a vector inequality constraint.

2487
02:24:04,672 --> 02:24:05,188
M'kay?

2488
02:24:05,188 --> 02:24:10,474
So, now there's a couple things we should
say because important to know.

2489
02:24:10,474 --> 02:24:13,760
Now it turns out, you look at this and you
say you just want an inequality and

2490
02:24:13,760 --> 02:24:18,385
the answer is something like this; If you
have multiple independant.

2491
02:24:18,385 --> 02:24:19,870
LMI's, I mean they're not independent,

2492
02:24:19,870 --> 02:24:23,408
I mean if you have multiple LMI's like
this: linear matrix inequalities.

2493
02:24:23,408 --> 02:24:26,288
You can always throw them together and
make one big one and

2494
02:24:26,288 --> 02:24:28,590
it's a very simple thing.

2495
02:24:28,590 --> 02:24:32,186
All you do is you put these together on
the diagonal of a bigger matrix,

2496
02:24:32,186 --> 02:24:36,630
like that and the off diagonals are just
zero.

2497
02:24:36,630 --> 02:24:39,366
And you're using the stunning fact that if
you

2498
02:24:39,366 --> 02:24:44,480
have a Block diagonal matrix then it's
positive semidefinite.

2499
02:24:44,480 --> 02:24:47,888
If and only if each of the blocks is
positive semidefinite.

2500
02:24:47,888 --> 02:24:51,853
So the point there is that most people
realize that you can have multiple,

2501
02:24:51,853 --> 02:24:55,960
multiple LMIs and that's the same as
having one.

2502
02:24:55,960 --> 02:24:59,870
So people still just say its an SDP.

2503
02:24:59,870 --> 02:25:00,524
Okay.

2504
02:25:00,524 --> 02:25:06,900
Now it turns out SDP generalizes most of
the classes we've seen so far.

2505
02:25:06,900 --> 02:25:08,210
Not GP.

2506
02:25:08,210 --> 02:25:10,913
But other than that, it generalizes them.

2507
02:25:10,913 --> 02:25:13,910
For example, LP, you can write as an SDP.

2508
02:25:13,910 --> 02:25:15,961
You can write SOCP as an SDP.

2509
02:25:15,961 --> 02:25:19,081
Of course, that's, one's a stronger
statement than the other,

2510
02:25:19,081 --> 02:25:22,810
because you can represent an LP as an STP.

2511
02:25:22,810 --> 02:25:23,720
Sorry, as an SOCP.

2512
02:25:23,720 --> 02:25:26,730
And an SOCP can be represented as an SDP,
right.

2513
02:25:26,730 --> 02:25:31,190
So you can say things like we have the LP
and SOCP embeddings as SDPs right.

2514
02:25:31,190 --> 02:25:36,180
And this has,.

2515
02:25:36,180 --> 02:25:39,807
I mean, it doesn't really, it has some
implications.

2516
02:25:39,807 --> 02:25:43,996
if, if and when some indefinite program
solve, solvers are completely perfected

2517
02:25:43,996 --> 02:25:49,190
this will be beautiful because you'll just
have one solver for everything.

2518
02:25:49,190 --> 02:25:52,140
And if it, you'll just, if it's an LP
you'll form a certain type of STP and

2519
02:25:52,140 --> 02:25:55,090
solve it, but Okay, So here is a linear
program minimizing C transpose X

2520
02:25:55,090 --> 02:25:58,655
subject to X less than or equal to B.

2521
02:25:58,655 --> 02:26:02,820
And here's a semi definate program that's

2522
02:26:02,820 --> 02:26:09,430
equavilent what we do is we use a stunning
fact.

2523
02:26:09,430 --> 02:26:14,650
The diagonal, a diagonal matrix that's
positive semi definate if any only if.

2524
02:26:14,650 --> 02:26:17,600
All of it's entries on the diagonal are
bigger or equal to 0.

2525
02:26:17,600 --> 02:26:19,280
So, this is simple.

2526
02:26:19,280 --> 02:26:23,780
It's kind of silly, you know, so you would
say what's an LP?

2527
02:26:23,780 --> 02:26:25,964
And you could say, well it's an SDP but
with diagonal matricies, but

2528
02:26:25,964 --> 02:26:27,250
I mean, who cares?

2529
02:26:27,250 --> 02:26:30,454
OK.
SOCP is a little bit more interesting, so

2530
02:26:30,454 --> 02:26:33,996
how do you do that, how do you write this
SOCP As an SDP and

2531
02:26:33,996 --> 02:26:38,616
the answer is quite interesting, it goes
like this, this constraint,

2532
02:26:38,616 --> 02:26:47,360
that's a second order cone constraint,
that is a nonlinear constraint on x.

2533
02:26:47,360 --> 02:26:51,070
Well of course it's nonlinear, and it's
not even, it's not affine/g, right?

2534
02:26:51,070 --> 02:26:53,512
This is affine but that, of course, is not
affine.

2535
02:26:53,512 --> 02:26:57,212
And so what we're going to do is we're
going to write a non-linear,

2536
02:26:57,212 --> 02:27:03,070
non-affine function or constraint as a
linear matrix and equality.

2537
02:27:03,070 --> 02:27:06,606
That's quite interesting because a, you're
going to get some, the advantage you're

2538
02:27:06,606 --> 02:27:10,120
going to get something that's linear, or
let's look at it.

2539
02:27:10,120 --> 02:27:11,060
So you write it this way.

2540
02:27:11,060 --> 02:27:16,152
Now that's the identity, that's a scaler
That's a vector, that's a vector and

2541
02:27:16,152 --> 02:27:19,320
that's a scaling.

2542
02:27:19,320 --> 02:27:21,030
And it asserts that, it says that and

2543
02:27:21,030 --> 02:27:24,528
this is going to be by the sure
compliment, alright?

2544
02:27:24,528 --> 02:27:27,936
That's the sure compliment, idea.

2545
02:27:27,936 --> 02:27:30,996
And the sure compliment gives you, well it
tells you

2546
02:27:30,996 --> 02:27:36,360
various things about when a block Matrix
is positive semi definite.

2547
02:27:36,360 --> 02:27:37,340
And so that'll work this way.

2548
02:27:37,340 --> 02:27:41,900
This matrix is positive semi definite,
when, and we can write it either way.

2549
02:27:41,900 --> 02:27:42,810
There's two ways to do it.

2550
02:27:42,810 --> 02:27:46,230
But one is to say something like this.

2551
02:27:46,230 --> 02:27:50,784
You would say that it's, it's, when this
matrix is positive semi-definite, That's

2552
02:27:50,784 --> 02:27:55,272
multiple identity so that simply requires
CI transpose X plus DI bigger than 0 and

2553
02:27:55,272 --> 02:28:02,440
the short compliment of this matrix in
respect to that which is the following.

2554
02:28:02,440 --> 02:28:07,690
There's lots of ways to say it,

2555
02:28:07,690 --> 02:28:12,310
you can also start here but

2556
02:28:12,310 --> 02:28:21,130
you'd end up with something like this CI
transpose

2557
02:28:21,130 --> 02:28:26,800
X plus DI plus then So you have

2558
02:28:26,800 --> 02:28:36,080
to have that.

2559
02:28:36,080 --> 02:28:39,090
And there's a minus sign here I'm sorry
here we go, there we go.

2560
02:28:39,090 --> 02:28:40,610
So that's the shared compliment.

2561
02:28:40,610 --> 02:28:45,660
The shared compliment, well lots of ways
to say it, but it's something like this.

2562
02:28:45,660 --> 02:28:49,820
It's, it's, this, lots of ways, this minus
this times that inverse times that,

2563
02:28:49,820 --> 02:28:53,915
right so you get something that looks like
that.

2564
02:28:53,915 --> 02:28:55,020
Right?

2565
02:28:55,020 --> 02:28:58,730
Now this thing is positive so I can
multiply through by this, and

2566
02:28:58,730 --> 02:29:03,000
I get Norm ai x plus bi squared, here,
it's on the other side, is less than or

2567
02:29:03,000 --> 02:29:07,140
equal to this thing squared.

2568
02:29:07,140 --> 02:29:13,470
And I take the square root and I invoke
this, and I get exactly this, okay?

2569
02:29:13,470 --> 02:29:14,694
So that's the idea, so

2570
02:29:14,694 --> 02:29:20,202
you would say that you can embed A second
order cone program as an SDP.

2571
02:29:20,202 --> 02:29:20,853
Okay.

2572
02:29:20,853 --> 02:29:25,080
Let's look at another problem.

2573
02:29:25,080 --> 02:29:28,300
It's again quite, quite interesting.

2574
02:29:28,300 --> 02:29:32,766
Let's minimize the maximum Eigenvalue of a
symmetric matrix which is

2575
02:29:32,766 --> 02:29:36,330
an afine function of a variable x.

2576
02:29:36,330 --> 02:29:39,314
Eh, so for example I could have a matrix
and I have some entries in it.

2577
02:29:39,314 --> 02:29:42,045
That I'm allowed to choose.

2578
02:29:42,045 --> 02:29:43,620
Some are fixed, some I can choose.

2579
02:29:43,620 --> 02:29:44,555
That they would have this form.

2580
02:29:44,555 --> 02:29:47,400
And the question is, how do you choose
those entries.

2581
02:29:47,400 --> 02:29:49,248
In such a way to, as to minimize, so

2582
02:29:49,248 --> 02:29:53,860
as to minimize the maximum Eigenvalue of
this matrix, right?

2583
02:29:53,860 --> 02:29:55,462
And before we start in on that, I want to.

2584
02:29:55,462 --> 02:29:57,571
Point out and you know this is convex,
right,

2585
02:29:57,571 --> 02:30:00,649
because that's one of the main things we
looked at we looked at

2586
02:30:00,649 --> 02:30:04,126
the maximum eigenvalue being a convex
function of a symmetric matrix and

2587
02:30:04,126 --> 02:30:10,260
a is an affine mapping so by composition
rule, that's a convex function.

2588
02:30:10,260 --> 02:30:12,635
But I want to point out how complicated
this is.

2589
02:30:12,635 --> 02:30:18,850
So If you were to tell somebody how do you
calculate this objective.

2590
02:30:18,850 --> 02:30:21,680
The answer would be well, you form this
matrix a.

2591
02:30:21,680 --> 02:30:22,310
Okay?

2592
02:30:22,310 --> 02:30:26,892
Then you calculate its characteristic
polynomial which is a, it's a,

2593
02:30:26,892 --> 02:30:29,690
by taking a determinant.

2594
02:30:29,690 --> 02:30:32,660
And you get this giant thing with n
factorial terms and

2595
02:30:32,660 --> 02:30:35,432
you collect all the terms and you get like
s to the n,

2596
02:30:35,432 --> 02:30:42,435
plus No trace A of X times F to the N
minus 1, and you'd get these coefficients.

2597
02:30:42,435 --> 02:30:47,470
Then you'd be asked to take, to find all
roots of that.

2598
02:30:47,470 --> 02:30:49,950
There would be N real roots, and you can
find them.

2599
02:30:49,950 --> 02:30:52,940
Now, you may know that there's no formula
for these roots, if N is 5 or bigger, so

2600
02:30:52,940 --> 02:30:56,500
just, it's not, there's not even a formula
for this, right?

2601
02:30:56,500 --> 02:31:00,223
There's a quadratic formula, there's one
for cubics, one for

2602
02:31:00,223 --> 02:31:04,429
quartics, there isn't one for quintics,
okay?

2603
02:31:04,429 --> 02:31:07,138
And then finally, you'd take all these
routes, and you'd take the largest of

2604
02:31:07,138 --> 02:31:11,380
them, and that would be the largest, that
would be the biggest eigenvalue, okay?

2605
02:31:11,380 --> 02:31:14,437
So the point is, this is very complicated.

2606
02:31:14,437 --> 02:31:15,780
In some sense.

2607
02:31:15,780 --> 02:31:18,330
It, well, if you describe it the wrong
way, it's very complicated.

2608
02:31:18,330 --> 02:31:22,810
But it turns out this is nothing but an
SDP.

2609
02:31:22,810 --> 02:31:28,710
It says minimize, a scale or T subject to
A of X is less or equal to T I.

2610
02:31:28,710 --> 02:31:29,792
And that's it.

2611
02:31:29,792 --> 02:31:31,129
Right?

2612
02:31:31,129 --> 02:31:35,015
And that's a matrix in equality and the
reason is this; The maximum eigenvalue of

2613
02:31:35,015 --> 02:31:40,790
a matrix is less than T if it only have A
Is less or equal to T I in a matrix sense.

2614
02:31:40,790 --> 02:31:42,470
The argument, you could make lots of
arguments,

2615
02:31:42,470 --> 02:31:43,772
you can argue with the eigenvalues or

2616
02:31:43,772 --> 02:31:46,305
however you like, but this is just
correct.

2617
02:31:46,305 --> 02:31:54,240
Oh, and I should say, this isn't quite in
LMI form, right?

2618
02:31:54,240 --> 02:31:56,508
Although, people would accept this as an
LMI because the left and

2619
02:31:56,508 --> 02:31:58,860
right hand sides are both affine.

2620
02:31:58,860 --> 02:32:00,700
You would want to, you would subtract it.

2621
02:32:00,700 --> 02:32:03,220
You'd write a of x, say, minus t i.

2622
02:32:03,220 --> 02:32:04,930
And that, that would be it.

2623
02:32:04,930 --> 02:32:06,629
The, there would be full LMI form.

2624
02:32:06,629 --> 02:32:08,076
But that's the same as this.

2625
02:32:08,076 --> 02:32:10,968
So, but the way, what's the upshot of all
this.

2626
02:32:10,968 --> 02:32:14,140
Semi-definite programs are not quite
tractable.

2627
02:32:14,140 --> 02:32:16,004
They're solved all the time.

2628
02:32:16,004 --> 02:32:19,186
I mean it's not as, it's not like linear
program.

2629
02:32:19,186 --> 02:32:20,010
You know.

2630
02:32:20,010 --> 02:32:24,742
So it's not like it's It's used everywhere
and it's super duper reliable.

2631
02:32:24,742 --> 02:32:27,412
It works like quite well.

2632
02:32:27,412 --> 02:32:31,630
And so that's a sense in which you would
do something to an SDP, and

2633
02:32:31,630 --> 02:32:34,670
in it's sort of solved.

2634
02:32:34,670 --> 02:32:37,910
So what that says is you can minimize the
maximum magin value of a matrix,

2635
02:32:37,910 --> 02:32:41,050
of an affine, affine-dependent matrix.

2636
02:32:41,050 --> 02:32:43,840
Okay.
We can do matrix norm minimization.

2637
02:32:43,840 --> 02:32:48,239
Again the trick is through the is through
sure compliments, right.

2638
02:32:48,239 --> 02:32:51,640
So the idea is you minimize the two norm
of a matrix.

2639
02:32:51,640 --> 02:32:59,030
That's a submetric maybe not even square
matrix, a.

2640
02:33:00,410 --> 02:33:05,740
Well, this is the Maximum item in A
transposed to A, and then the square root.

2641
02:33:07,270 --> 02:33:12,195
And here A is a matrix that's affine in
the variable x.

2642
02:33:12,195 --> 02:33:14,233
That's equivalent to an SDP.

2643
02:33:14,233 --> 02:33:17,267
Let's see how: you rewrite it as minimized
t,

2644
02:33:17,267 --> 02:33:22,701
subject to this matrix here being positive
semi-definite.

2645
02:33:23,860 --> 02:33:27,862
And again the trick is your compliments,
this matrix is positive semi-definite if

2646
02:33:27,862 --> 02:33:31,052
and only if -- we'll start here -- ti is
bigger than or equal to zero,

2647
02:33:31,052 --> 02:33:34,880
that requires t to be bigger than or equal
to zero, and ti minus a of x transposed,

2648
02:33:34,880 --> 02:33:41,740
times the inverse of this, times that is
positive semi-definite.

2649
02:33:41,740 --> 02:33:44,565
And that's exactly these inequalities
here.

2650
02:33:44,565 --> 02:33:46,310
RIght?

2651
02:33:46,310 --> 02:33:50,362
And this inequality is also is really
interesting.

2652
02:33:50,362 --> 02:33:55,290
That says this is exactly the same as
saying that lambda max of a transpose a is

2653
02:33:55,290 --> 02:33:59,125
less than or equal to t squared.

2654
02:33:59,125 --> 02:34:01,110
That, that's what this says.

2655
02:34:01,110 --> 02:34:03,320
Well, that is what we did on the previous
page.

2656
02:34:03,320 --> 02:34:04,138
Also, it's clear.

2657
02:34:04,138 --> 02:34:05,182
Okay?

2658
02:34:05,182 --> 02:34:09,913
But this, so therefore if I take the
square root, I get this, and the t,

2659
02:34:09,913 --> 02:34:13,850
the power goes away.

2660
02:34:13,850 --> 02:34:19,870
And that's exactly this, right there, so
that's the, in fact it's the epigraph.

2661
02:34:19,870 --> 02:34:24,334
So a fancy way to save this is that the
matrix two norm The matrix, the matrix

2662
02:34:24,334 --> 02:34:31,710
additional or the maximum singular value
its epigraph has an LMI representation.

2663
02:34:31,710 --> 02:34:32,720
That's how you would say this.

2664
02:34:32,720 --> 02:34:35,670
That's a sophisticated way to say this,
right?

2665
02:34:35,670 --> 02:34:37,470
And it's, it's really cool, so

2666
02:34:37,470 --> 02:34:42,326
it says you can transform a problem
involving a matrix norm.

2667
02:34:42,326 --> 02:34:44,465
To an STP.

2668
02:34:44,465 --> 02:34:45,580
I mean that, that's cool.

2669
02:34:45,580 --> 02:34:50,349
By the way, this is exactly how cvx works.

2670
02:34:50,349 --> 02:34:53,370
So in cvx you can write down the norm of a
matrix, it understands that,

2671
02:34:53,370 --> 02:34:54,940
that's convex.

2672
02:34:54,940 --> 02:34:58,840
If you minimize it, what happens is
exactly the argument here,

2673
02:34:58,840 --> 02:35:04,100
is converted to one of these block 2 by 2
matrices.

2674
02:35:04,100 --> 02:35:06,750
And if you wanted to you could even go in
and look at it.

2675
02:35:06,750 --> 02:35:10,880
You can trap the call before the cone
solver is solved, is, is called but

2676
02:35:10,880 --> 02:35:14,913
you would actually see this matrix there.

2677
02:35:14,913 --> 02:35:15,799
Okay?

2678
02:35:15,799 --> 02:35:16,685
Okay.

2679
02:35:16,685 --> 02:35:18,457
All right.

2680
02:35:18,457 --> 02:35:23,850
Our final generalization.

2681
02:35:23,850 --> 02:35:28,890
Of optimization problem is a bit more
complicated.

2682
02:35:28,890 --> 02:35:30,400
It's vector optimization.

2683
02:35:30,400 --> 02:35:33,792
So what we're going to do now, just to set
the context the last generalization we

2684
02:35:33,792 --> 02:35:38,348
looked at was we said what if these
constraint functions were not.

2685
02:35:38,348 --> 02:35:42,428
Were vectors and so then in turn we had a
standard idea of what it means for

2686
02:35:42,428 --> 02:35:45,590
a vector inequality to hold.

2687
02:35:45,590 --> 02:35:47,900
We'll do something a bit more comlicated
here, and

2688
02:35:47,900 --> 02:35:52,780
you have to be on your super-duper on your
toes with respect to the semantics.

2689
02:35:52,780 --> 02:35:56,312
We're going to minimize a vector function.

2690
02:35:56,312 --> 02:35:56,864
And By the way,

2691
02:35:56,864 --> 02:36:00,470
a lot of people just say well let's
minimize a vector function, and then.

2692
02:36:00,470 --> 02:36:03,095
But the thing is you have to say what that
means.

2693
02:36:03,095 --> 02:36:06,191
So, we'll say what it means in a, in a
bit, but

2694
02:36:06,191 --> 02:36:14,213
it's, it's not completely obvious and it
turns out you can have several meanings.

2695
02:36:14,213 --> 02:36:14,778
Okay.

2696
02:36:14,778 --> 02:36:17,280
So a convex vector optimization problem
looks like this.

2697
02:36:17,280 --> 02:36:20,790
You minimize with respect to a cone.

2698
02:36:20,790 --> 02:36:22,433
An objective that is a vector.

2699
02:36:22,433 --> 02:36:22,996
Right?

2700
02:36:22,996 --> 02:36:26,468
And we'll leave the, the, ineq, the
inequalities as scaler and, and

2701
02:36:26,468 --> 02:36:30,550
the equality constraints there of course
just linear.

2702
02:36:30,550 --> 02:36:31,310
Okay.

2703
02:36:31,310 --> 02:36:33,660
And, but the real question is what does
this mean.

2704
02:36:33,660 --> 02:36:36,894
And what you have to do then is you have
to go back to the original semantics of

2705
02:36:36,894 --> 02:36:39,250
Of an optimization problem.

2706
02:36:39,250 --> 02:36:42,060
So on optimization problem the semantic
goes like this.

2707
02:36:42,060 --> 02:36:45,230
You give me x, and somebody else gives me
another x.

2708
02:36:45,230 --> 02:36:47,230
Okay, x and x tilde.

2709
02:36:47,230 --> 02:36:51,040
The first thing I do with each one is I
evaluate fi of x.

2710
02:36:51,040 --> 02:36:52,998
And I check.
Do I alwaysget a number that's less or

2711
02:36:52,998 --> 02:36:54,100
equal to zero?

2712
02:36:54,100 --> 02:36:57,455
If I don't, I instantly throw that x back
at that person who gave it to me and

2713
02:36:57,455 --> 02:36:59,180
I say.

2714
02:36:59,180 --> 02:37:01,840
Not feasible, it's completely
unacceptable.

2715
02:37:01,840 --> 02:37:02,376
Okay?

2716
02:37:02,376 --> 02:37:02,886
The, I, by the way,

2717
02:37:02,886 --> 02:37:05,668
the same thing would happen if they gave
me an X that was out of the domain.

2718
02:37:05,668 --> 02:37:08,948
That's even worse, I would say, "your
point is so

2719
02:37:08,948 --> 02:37:15,940
bad I can't even evaluate the third
inequality constraint function." Okay?

2720
02:37:15,940 --> 02:37:21,320
And then I would check I would check to
see that hi of x is equal to zero.

2721
02:37:21,320 --> 02:37:22,400
By the way that is a typo.

2722
02:37:22,400 --> 02:37:30,450
So I would check then to see if hi of x
are equal to zero for each one.

2723
02:37:30,450 --> 02:37:32,485
If they are that's fine, if not then I
throw it back.

2724
02:37:32,485 --> 02:37:37,585
If both x and xy~ are feasible, so they
pass these tests.

2725
02:37:37,585 --> 02:37:40,010
Then how do I compare.

2726
02:37:40,010 --> 02:37:41,585
How do I say one is better than the other
and

2727
02:37:41,585 --> 02:37:44,620
the answer's extremelly simple in standard
optimization.

2728
02:37:44,620 --> 02:37:46,650
I evaluate the objective, right?

2729
02:37:46,650 --> 02:37:50,080
If you like to think of an objective as
having units of dollars, go ahead.

2730
02:37:50,080 --> 02:37:51,390
It's a cost.

2731
02:37:51,390 --> 02:37:54,360
Anyway, whichever one is less.

2732
02:37:54,360 --> 02:37:56,663
As a smaller objective is better, it's
cheaper, it does,

2733
02:37:56,663 --> 02:38:00,280
it satisfies all the constraints and it's
cheaper, it's better.

2734
02:38:00,280 --> 02:38:03,136
if by the way, if their different, if x
and x silly are different, and

2735
02:38:03,136 --> 02:38:07,020
have the same objective, I can't say which
one is better.

2736
02:38:07,020 --> 02:38:09,850
I, they simply, as far as this problem is
concerned, they are the same.

2737
02:38:09,850 --> 02:38:12,250
So that's the idea, now the problem here
is this,

2738
02:38:12,250 --> 02:38:16,030
If that's a vector I have to have a way of
saying one is better than another but

2739
02:38:16,030 --> 02:38:19,210
as you know if you have two vectors in a
vector inequality you can

2740
02:38:19,210 --> 02:38:25,990
have the very awkward situation where
there incomparable.

2741
02:38:25,990 --> 02:38:29,720
So that can and does happen and that's the
interesting part.

2742
02:38:29,720 --> 02:38:32,572
Now when that doesn't happen its easy to
say.

2743
02:38:32,572 --> 02:38:35,458
If there, if for example this is a two
vector and

2744
02:38:35,458 --> 02:38:39,540
you're minimizing with respect to r plus
2.

2745
02:38:39,540 --> 02:38:42,576
That simply means that each of the entries
should be smaller than the others and

2746
02:38:42,576 --> 02:38:45,106
if you come back and one person has one
more than the inequality/g,

2747
02:38:45,106 --> 02:38:48,992
one is better than the other, then it is
clearly better.

2748
02:38:48,992 --> 02:38:51,283
But we'll see what the other idea is.

2749
02:38:51,283 --> 02:38:56,418
Okay, so what we'll do is we'll look at
the set of achievable objective values,

2750
02:38:56,418 --> 02:39:00,931
now that's a vector, that's the point.

2751
02:39:00,931 --> 02:39:06,391
So for every feasible point conceptually,
we will simply record the, the objective

2752
02:39:06,391 --> 02:39:13,858
you attain and we'll call that O, for the
set of all objectives and here it is.

2753
02:39:13,858 --> 02:39:17,880
By the way For a scalar optimization
problem this is the simple thing.

2754
02:39:18,910 --> 02:39:19,950
It's a subset of the line.

2755
02:39:19,950 --> 02:39:22,840
There's the line and O might look like
this.

2756
02:39:22,840 --> 02:39:25,079
I mean it could look like that.

2757
02:39:25,079 --> 02:39:27,979
I mean it's absolutely going to be
connected in this case, so

2758
02:39:27,979 --> 02:39:30,020
it will be an interval.

2759
02:39:30,020 --> 02:39:30,580
Okay.

2760
02:39:30,580 --> 02:39:32,390
It'll look like that.

2761
02:39:32,390 --> 02:39:35,903
Then you'll say Okay.

2762
02:39:35,903 --> 02:39:37,630
I for a convex problem.

2763
02:39:37,630 --> 02:39:40,850
Say that's what it is and, and, and, you
know, if there is one.

2764
02:39:40,850 --> 02:39:43,930
If this is achieved, I guess I've drawn it
as achieved.

2765
02:39:43,930 --> 02:39:47,430
Then whichever x corresponds to that
point, that's optimal.

2766
02:39:47,430 --> 02:39:48,950
Okay.
But here it's a set in r, too.

2767
02:39:48,950 --> 02:39:50,690
Like, for example this one, or this one.

2768
02:39:50,690 --> 02:39:51,530
Okay?

2769
02:39:51,530 --> 02:39:53,972
And then we say the following.

2770
02:39:53,972 --> 02:39:58,880
X is optimal if this is the minimum value
of that set.

2771
02:39:58,880 --> 02:40:00,640
Now remember what the minimum value said.

2772
02:40:00,640 --> 02:40:04,735
The minimum value says that this point is
comparable to every other point in

2773
02:40:04,735 --> 02:40:09,020
the set, and is less than or equal to it.

2774
02:40:09,020 --> 02:40:10,070
In the cone sense.

2775
02:40:10,070 --> 02:40:15,343
So, these are, these are two pictures with
respect to r plus 2.

2776
02:40:15,343 --> 02:40:19,333
And it would say that there's a, a, a
point here which is comparable to

2777
02:40:19,333 --> 02:40:23,883
every other point up here, and less than
or equal to it, which means in fact, it,

2778
02:40:23,883 --> 02:40:30,495
it means that all these points are upper,
up and to the right.

2779
02:40:30,495 --> 02:40:31,770
Okay?

2780
02:40:31,770 --> 02:40:33,630
So that means, that says it's optimal.

2781
02:40:33,630 --> 02:40:36,720
And, yeah, by the way [COUGH] it's a very
strong form of optimal.

2782
02:40:36,720 --> 02:40:38,787
It says basically that you can minimize
Both this objective and

2783
02:40:38,787 --> 02:40:40,659
this objective simultaneously and you get
that point and

2784
02:40:40,659 --> 02:40:43,260
by the way if that happens that's
wonderful.

2785
02:40:43,260 --> 02:40:44,008
It usually doesn't.

2786
02:40:44,008 --> 02:40:46,736
The more interesting cases that o might
look like this, something like that.

2787
02:40:46,736 --> 02:40:51,821
Now its more interesting because we can
say is there we

2788
02:40:51,821 --> 02:40:55,211
can ask is there a point In this set O,

2789
02:40:55,211 --> 02:41:04,880
that is comparable to all other points in
O and better than it.

2790
02:41:04,880 --> 02:41:08,312
And the answer to this is there a point
where this, in this set, where every other

2791
02:41:08,312 --> 02:41:13,110
point in this set is up and to the right
and the answer is no, there's not.

2792
02:41:13,110 --> 02:41:14,873
But remember we have a weaker sense.

2793
02:41:14,873 --> 02:41:19,290
This is minimum and this is minimality.

2794
02:41:19,290 --> 02:41:21,770
Right so there's mini, minimum and
minimal.

2795
02:41:21,770 --> 02:41:25,036
And so we'll say that F zero of X is a
minimal value of O of X

2796
02:41:25,036 --> 02:41:29,600
then we're going to give the name Pareto
optimal.

2797
02:41:29,600 --> 02:41:30,949
That goes back about a hundred years.

2798
02:41:30,949 --> 02:41:36,630
Now Pareto optimal, it's subtle, it says
the following.

2799
02:41:36,630 --> 02:41:41,524
It says that there is no point in the set
that is better.

2800
02:41:41,524 --> 02:41:42,156
Okay?

2801
02:41:42,156 --> 02:41:47,190
Now, on the line all two, any two points
on the line are comparable.

2802
02:41:47,190 --> 02:41:52,050
And so these two, these two concepts of
optimality merge into one.

2803
02:41:52,050 --> 02:41:54,966
But in a vector optimization problem
that's actually not true --

2804
02:41:54,966 --> 02:41:56,600
they're different.

2805
02:41:56,600 --> 02:42:00,010
Here for example, in this case this point
is Pareto optimal.

2806
02:42:00,010 --> 02:42:03,618
And the reason is, there is these, if you
look down and

2807
02:42:03,618 --> 02:42:10,700
to the left, again this is with respect to
r-plus squared, left and down.

2808
02:42:10,700 --> 02:42:14,570
Those are all the up the values which are
better than the one you have.

2809
02:42:14,570 --> 02:42:18,322
Better means, by the way another name for
this like in economics is,

2810
02:42:18,322 --> 02:42:21,450
it says that better is dominates.

2811
02:42:21,450 --> 02:42:25,900
So you'd say that, for example this, this
point dominates that one.

2812
02:42:25,900 --> 02:42:29,035
Because it's, it's objective values which
is a vector is less than or

2813
02:42:29,035 --> 02:42:30,800
equal to that one.

2814
02:42:31,850 --> 02:42:34,606
So all of these points on this curve here
are Pareto optimal and

2815
02:42:34,606 --> 02:42:36,605
then from here on down.

2816
02:42:36,605 --> 02:42:37,600
Right?

2817
02:42:37,600 --> 02:42:40,840
These are not, and certainly that's not.

2818
02:42:40,840 --> 02:42:42,570
And one way to say it is something like
this.

2819
02:42:42,570 --> 02:42:50,262
If a point is not Pareto optimal, then
there is a better point in the set.

2820
02:42:50,262 --> 02:42:51,243
Okay?

2821
02:42:51,243 --> 02:42:58,510
So Another name for not Pareto optimal is
dumb.

2822
02:42:58,510 --> 02:43:03,185
It's a dumb choice because it says that I
can find a feasible point X

2823
02:43:03,185 --> 02:43:07,250
which beats yours unambiguously.

2824
02:43:07,250 --> 02:43:10,410
Right, that's it's less than or equal to
in the, the cone.

2825
02:43:11,430 --> 02:43:12,095
Okay.

2826
02:43:12,095 --> 02:43:18,260
Now a very common case of this is just
multicriterion optimization.

2827
02:43:18,260 --> 02:43:22,320
That's that's when you have your comparing
with respect to the cone, non negative or

2828
02:43:22,320 --> 02:43:26,570
than and one way to think of that is
vector optimization.

2829
02:43:26,570 --> 02:43:27,630
That's another name for it.

2830
02:43:27,630 --> 02:43:29,478
The objective is a vector and

2831
02:43:29,478 --> 02:43:34,590
you think of each of these As a separate
objective function.

2832
02:43:34,590 --> 02:43:37,717
Right so, for example these might be you
know in a circuit design,

2833
02:43:37,717 --> 02:43:41,552
this might be power and area or something
like that, you might have two of them,

2834
02:43:41,552 --> 02:43:44,148
you might have two or three, power, area
and delay for

2835
02:43:44,148 --> 02:43:51,990
a circuit and then you'd, well then these
are all things you would want to be small.

2836
02:43:51,990 --> 02:43:53,210
And so that's kind of the idea.

2837
02:43:53,210 --> 02:43:57,152
In finance these would be things like cost
or negative profit and

2838
02:43:57,152 --> 02:44:03,590
the second one might be some kind of
measure of risk or something like that.

2839
02:44:03,590 --> 02:44:06,980
You want low risk and you want high
profit.

2840
02:44:06,980 --> 02:44:08,840
Which isn't low and negative profit.

2841
02:44:08,840 --> 02:44:14,172
So a naturally criterion problem with two
that's called bicriterion Ok so

2842
02:44:14,172 --> 02:44:18,644
you think of these two different
objectives and the idea is you

2843
02:44:18,644 --> 02:44:27,910
want them all to be small and you'd say
that a point is optimal if this holds.

2844
02:44:27,910 --> 02:44:30,575
If whenever x is if x is if x is optimal
if whenever y

2845
02:44:30,575 --> 02:44:33,695
is feasible you have f zero of x is less
than or equal to y and

2846
02:44:33,695 --> 02:44:41,050
what that means is It means that you have
simultaneously minimized all objectives.

2847
02:44:41,050 --> 02:44:44,940
Now that, by the way, rarely happens,
right?

2848
02:44:44,940 --> 02:44:46,292
This is what happens very often.

2849
02:44:46,292 --> 02:44:51,375
A point, which is feasible, is Pareto
optimal if the following is true.

2850
02:44:51,375 --> 02:44:54,705
If you have another feasible point that is
less than or

2851
02:44:54,705 --> 02:44:58,990
equal to this one, That in fact they're
equal.

2852
02:44:58,990 --> 02:44:59,860
And that's the idea.

2853
02:44:59,860 --> 02:45:03,124
So roughly speaking, if you have Pareto
optimal points it

2854
02:45:03,124 --> 02:45:07,380
says that there's a tradeoff between the
objectives.

2855
02:45:07,380 --> 02:45:09,090
That's what it says.

2856
02:45:09,090 --> 02:45:11,960
So let's do a simple case, regularize
these squares.

2857
02:45:11,960 --> 02:45:13,703
That says I would like ax -

2858
02:45:13,703 --> 02:45:18,940
b 2norm squared to be small That means I
want good fit.

2859
02:45:18,940 --> 02:45:22,120
But I also want the norm of x to be small
too.

2860
02:45:22,120 --> 02:45:25,945
Now, in this case we can characterize
exact what o looks like,

2861
02:45:25,945 --> 02:45:30,780
I mean we don't have to do it but here it
is drawn.

2862
02:45:32,330 --> 02:45:33,586
So the idea is -- look!

2863
02:45:33,586 --> 02:45:35,220
-- there's an x that achieves that value.

2864
02:45:35,220 --> 02:45:36,780
Now that's not very interesting, right?

2865
02:45:36,780 --> 02:45:41,226
Because it's basically It achieves a
terrible value of fit right and

2866
02:45:41,226 --> 02:45:44,760
at the same time its quite large.

2867
02:45:44,760 --> 02:45:47,730
So it hasn't done very well on anything.

2868
02:45:47,730 --> 02:45:48,306
Right?
So

2869
02:45:48,306 --> 02:45:52,275
now all our focus is going to end up being
on this little part right here OK and

2870
02:45:52,275 --> 02:45:55,803
on that little part right there this
boundary is Pareto optimal and

2871
02:45:55,803 --> 02:46:00,560
we can even say what the different ones
are.

2872
02:46:00,560 --> 02:46:04,330
For example this point right here, it's
very interesting.

2873
02:46:04,330 --> 02:46:08,018
It achieves a value of the size of x of
zero.

2874
02:46:08,018 --> 02:46:12,050
And so what, what x is that correspond to?

2875
02:46:12,050 --> 02:46:13,770
It can only correspond to X equals zero.

2876
02:46:13,770 --> 02:46:16,443
And so this tells you, at that point, but

2877
02:46:16,443 --> 02:46:20,730
10 is the value of norm squared of b,
okay?

2878
02:46:20,730 --> 02:46:23,300
I mean, the numbers don't matter, but
that's what it is.

2879
02:46:23,300 --> 02:46:26,214
All of these points in here are Pareto
optimal.

2880
02:46:26,214 --> 02:46:30,580
And you would say, there's a trade-off of
fit versus size of x; that's a,

2881
02:46:30,580 --> 02:46:33,330
that's the trade-off.

2882
02:46:33,330 --> 02:46:37,263
And another name for the, this Pare-, this
Pareto op-, this Pareto optimal curve is

2883
02:46:37,263 --> 02:46:41,620
the optimal trade-off curve of fit versus
size, for example.

2884
02:46:41,620 --> 02:46:42,720
So, this is the idea.

2885
02:46:45,801 --> 02:46:48,630
A very famous case of this is in finance.

2886
02:46:48,630 --> 02:46:51,520
So risk, return, trade-off and portfolio
optimization.

2887
02:46:51,520 --> 02:46:54,160
This is due to Markowitz.

2888
02:46:54,160 --> 02:46:56,670
And this is the early 50's, right?

2889
02:46:56,670 --> 02:47:01,540
Very early 50's right, '52, '53, something
like that.

2890
02:47:01,540 --> 02:47:02,548
Okay?
And the idea heere is

2891
02:47:02,548 --> 02:47:04,519
we want to minimize two things.

2892
02:47:04,519 --> 02:47:07,510
This is negative, profit.

2893
02:47:07,510 --> 02:47:08,970
Right.

2894
02:47:08,970 --> 02:47:10,700
Or negative return, mean return.

2895
02:47:10,700 --> 02:47:12,870
And that is return variance.

2896
02:47:12,870 --> 02:47:16,895
So here, x gives you an investment
portfolio.

2897
02:47:16,895 --> 02:47:20,940
So x i is the fraction of things you
invest in, asset i.

2898
02:47:20,940 --> 02:47:25,200
Then p is a vector of These are asset
price changes .It's the, it's a return.

2899
02:47:25,200 --> 02:47:28,780
And that's modeled as a random variable
with mean P bar and covariance.

2900
02:47:28,780 --> 02:47:32,910
So the mean return is P bar transpose X,
that's this one.

2901
02:47:32,910 --> 02:47:34,730
And this is the variance.

2902
02:47:34,730 --> 02:47:40,132
And so what this says is, I want small
variance and I want a large return.

2903
02:47:40,132 --> 02:47:44,228
By the way, it's traditional to put in One
of the assets is cash or T bills or

2904
02:47:44,228 --> 02:47:47,172
something and that's supposed to be 0
variant right, so

2905
02:47:47,172 --> 02:47:52,211
that's the, that's traditional in this
model.

2906
02:47:52,211 --> 02:47:57,370
Okay so here if I solve this problem this
I can work out the trade off curve here

2907
02:47:57,370 --> 02:48:04,950
and we'll see why, how to do that shortly,
but you'd get something like this.

2908
02:48:04,950 --> 02:48:09,270
You'd plot it Here you don't plot the
square root of x transposed sigma x,

2909
02:48:09,270 --> 02:48:12,710
which is the standard deviation.

2910
02:48:12,710 --> 02:48:16,460
That's like the risk, and that is the
return, right?

2911
02:48:16,460 --> 02:48:21,595
And so it would say that, for example,
here's something where by investing all

2912
02:48:21,595 --> 02:48:26,335
of your money in whatever is the most It
the most riskless option that

2913
02:48:26,335 --> 02:48:30,522
appears to be the fourth asset here cause
that's at 0 here's the,

2914
02:48:30,522 --> 02:48:35,025
it's all in X 4 and that gives you a
return of you know 3% and almost 0 and

2915
02:48:35,025 --> 02:48:39,607
maybe even exactly 0 risk so that would be
T bills, not now by the way but

2916
02:48:39,607 --> 02:48:47,656
maybe 15 years ago.

2917
02:48:47,656 --> 02:48:51,976
And then as you move up here you can see
these are the optimal points these

2918
02:48:51,976 --> 02:48:56,440
correspond to different points here
probably.

2919
02:48:56,440 --> 02:48:58,105
These kinks over here.

2920
02:48:58,105 --> 02:49:01,345
And you'd say that this is the preeto
curve by the way it's traditional to

2921
02:49:01,345 --> 02:49:02,209
draw it this way and

2922
02:49:02,209 --> 02:49:07,662
not the usual way, and the reason it goes
up like that and the reason is good.

2923
02:49:07,662 --> 02:49:11,690
Is up and here good is to the left.

2924
02:49:11,690 --> 02:49:14,698
Right?
Because you want low risk, high return.

2925
02:49:14,698 --> 02:49:16,609
Okay and so if you were to switch this
around and

2926
02:49:16,609 --> 02:49:20,675
make it a negative that would be going
kind of the way that you expect.

2927
02:49:20,675 --> 02:49:24,995
Okay, so that's a this is a very classic
example of a two multi-criterion

2928
02:49:24,995 --> 02:49:31,846
optimization with two criteria and in fact
you call that a bicriterion problem.

2929
02:49:31,846 --> 02:49:36,070
Okay now, scalarization.

2930
02:49:36,070 --> 02:49:39,370
How do you find Pareto optimal points, and
the answer's pretty easy.

2931
02:49:39,370 --> 02:49:43,850
You choose a vector, landa, which is
positive in the dual-cone, and

2932
02:49:43,850 --> 02:49:48,986
you solve this ordinary scalar
optimization problem.

2933
02:49:48,986 --> 02:49:52,640
Now what's cool is if this is a convex
problem here The original one was

2934
02:49:52,640 --> 02:49:56,500
a convex vector optimization problem.

2935
02:49:56,500 --> 02:50:00,648
When you scalarize you get a convex scalar
optimization problem which we

2936
02:50:00,648 --> 02:50:04,490
can solve and the meaning is really
simple.

2937
02:50:04,490 --> 02:50:05,588
What it is if you take,

2938
02:50:05,588 --> 02:50:10,752
if you take a value of Lambda, if you take
Lambda like this That's the normal.

2939
02:50:10,752 --> 02:50:13,716
And it says, basically goes as far as you
can in the minus land of

2940
02:50:13,716 --> 02:50:17,380
direction while still being in the O.

2941
02:50:17,380 --> 02:50:20,470
And so what you're going to do is your
going to get the tangent there.

2942
02:50:20,470 --> 02:50:24,940
So lambda sets the slope.

2943
02:50:24,940 --> 02:50:25,773
And then what you do,

2944
02:50:25,773 --> 02:50:29,460
is you find the point that it tangent to
the set of achievable values.

2945
02:50:29,460 --> 02:50:34,048
And here it is for one lambda and here it
is for Another value, lambda one and

2946
02:50:34,048 --> 02:50:36,230
lambda two.

2947
02:50:36,230 --> 02:50:38,575
Now and what is always true, convex or
not,

2948
02:50:38,575 --> 02:50:44,550
is that if you carry out this procedure
you get points that are Pareto optimal.

2949
02:50:44,550 --> 02:50:46,300
That, that happens always.

2950
02:50:46,300 --> 02:50:48,850
Of course if it's not convex you can't
solve that problem, but

2951
02:50:48,850 --> 02:50:52,610
if you could you'd get something that was
Pareto optimal.

2952
02:50:52,610 --> 02:50:55,823
What is very interesting is that when the
problem is, the original problem,

2953
02:50:55,823 --> 02:51:00,680
is a convex vector optimazation problem
you get almost all Pareto-optimal points.

2954
02:51:00,680 --> 02:51:06,560
And the reason is roughly speaking iit's
because o is convex.

2955
02:51:06,560 --> 02:51:08,435
That's actually false.

2956
02:51:08,435 --> 02:51:12,656
O is not necessarily convex but it's
lower, the, we care about the lower left

2957
02:51:12,656 --> 02:51:18,950
part of it, or roughly speaking, and that
actually always is convex.

2958
02:51:18,950 --> 02:51:19,528
We'll get to that.

2959
02:51:19,528 --> 02:51:23,429
Now, for multi-criterion problems when you
scalarize,

2960
02:51:23,429 --> 02:51:28,640
you are simply minimizing a weighted sum
of objectives.

2961
02:51:28,640 --> 02:51:33,780
I mean, this is very old idea, it's so
intuitive that people don't even say it.

2962
02:51:33,780 --> 02:51:38,070
I mean, ever since you took any class on
anything people would say what are we

2963
02:51:38,070 --> 02:51:40,370
going to minimize?

2964
02:51:40,370 --> 02:51:43,040
We'll minimize this thing plus little bit
of that.

2965
02:51:43,040 --> 02:51:44,335
You add some regularization and you add,
and

2966
02:51:44,335 --> 02:51:46,120
someone says what's that coefficient
there?

2967
02:51:46,120 --> 02:51:49,410
And you say that so weight you mess with,
right?

2968
02:51:49,410 --> 02:51:52,418
So, it's weighted minimization, right?

2969
02:51:52,418 --> 02:51:57,332
So here that's the interpretation of land
is it's the vector of weights,

2970
02:51:57,332 --> 02:52:01,442
that relate these objective functions.

2971
02:52:01,442 --> 02:52:06,419
And this you know, nice economic
interpretation for example you can

2972
02:52:06,419 --> 02:52:14,370
think of this F1 up to FQ, these as being
some kind of cost or consumption.

2973
02:52:14,370 --> 02:52:15,890
But they could be in different units.

2974
02:52:15,890 --> 02:52:18,169
I mean they could, one could be in
kilowatt hours and

2975
02:52:18,169 --> 02:52:20,450
another one could be in dollars.

2976
02:52:20,450 --> 02:52:21,820
It could be a direct cost.

2977
02:52:21,820 --> 02:52:23,700
And now you have to add them up.

2978
02:52:23,700 --> 02:52:27,660
And you can actually think of the lambdas
as a set of prices.

2979
02:52:27,660 --> 02:52:29,442
For example, in that case, well,

2980
02:52:29,442 --> 02:52:33,260
if the first one were dollars, lambda 1
would be 1.

2981
02:52:33,260 --> 02:52:38,100
If lambda q, if Fq is in kilowatt hours,
lambda Q has a beautiful interpretation.

2982
02:52:38,100 --> 02:52:40,070
It's a price.

2983
02:52:40,070 --> 02:52:42,686
It's the price in dollars per kilowatt
hour.

2984
02:52:42,686 --> 02:52:46,716
And it's whatever needs to happen if you
want to include the physically units in

2985
02:52:46,716 --> 02:52:49,730
the lamba you're welcome to too.

2986
02:52:49,730 --> 02:52:53,067
But it's whatever has to happen so you can
add these up and

2987
02:52:53,067 --> 02:52:57,327
put them on the same scale another
interrputation is that these weights

2988
02:52:57,327 --> 02:53:05,071
are more abstract they just tell you how
much you care, how irratated it makes you.

2989
02:53:05,071 --> 02:53:07,419
If lambda, if, if the different ones.

2990
02:53:07,419 --> 02:53:09,552
So there if you have lambda 1 as 1,

2991
02:53:09,552 --> 02:53:15,510
and lambda q is 10, that's as someone
says, What's that all about?

2992
02:53:15,510 --> 02:53:19,557
And you say, well that just means that I
find a unit increase in fq to be

2993
02:53:19,557 --> 02:53:24,640
ten times more irritating than a unit
increase in f1.

2994
02:53:24,640 --> 02:53:26,579
So they're, they're just realtive weights.

2995
02:53:26,579 --> 02:53:27,810
Okay.
Now when to apply to

2996
02:53:27,810 --> 02:53:31,410
the regularized least-squares problem,
well you just get this.

2997
02:53:31,410 --> 02:53:32,710
I mean, and there's our,

2998
02:53:32,710 --> 02:53:38,360
there's our friend, well I guess in
statistics you call this ridge regression.

2999
02:53:38,360 --> 02:53:42,660
Because you're minimizing a traditional
least-squares objective.

3000
02:53:42,660 --> 02:53:44,997
And you add plus gamma times the norm
squared of x,

3001
02:53:44,997 --> 02:53:49,890
and that's the least-squares problem, and
for any gamma we can solve this.

3002
02:53:49,890 --> 02:53:52,570
And this will trace of this curve like
this.

3003
02:53:52,570 --> 02:53:55,192
It won't get you exactly that point and
since gamma,

3004
02:53:55,192 --> 02:53:59,125
since we're insisting gamma is positive it
doesn't get you This point, either, but

3005
02:53:59,125 --> 02:54:03,280
as gamma goes to 0, you get closer and
closer.

3006
02:54:03,280 --> 02:54:07,130
And as gamma goes to infinity you get
closer and closer to this point, here.

3007
02:54:07,130 --> 02:54:11,069
That's the, that's the that's the idea
here.

3008
02:54:11,069 --> 02:54:11,867
okay.

3009
02:54:11,867 --> 02:54:16,232
So, that's scalarization.

3010
02:54:16,232 --> 02:54:19,334
And in finance, if you apply it there,
what you end up min,

3011
02:54:19,334 --> 02:54:23,950
you minimize a that's negative return,
mean return.

3012
02:54:23,950 --> 02:54:26,965
Plus gamma times x transpose sigma x
that's risk and so

3013
02:54:26,965 --> 02:54:30,540
people would normally write that this way.

3014
02:54:30,540 --> 02:54:34,210
That you would maximize p bar transpose x.

3015
02:54:34,210 --> 02:54:40,090
That's your that's your mean return minus
x gamma x transpose sigma x and

3016
02:54:40,090 --> 02:54:48,570
this has a beautiful name, this is called
risk adjusted return right?

3017
02:54:48,570 --> 02:54:51,987
There's your return, which is really an
expected return, and

3018
02:54:51,987 --> 02:54:55,672
this is a risk adjustment, meaning that
they are subtracting from

3019
02:54:55,672 --> 02:55:00,465
the expected return something that
penalizes risk.

3020
02:55:00,465 --> 02:55:04,290
And by the way gamma has a beautiful name
in this case: gamma is

3021
02:55:04,290 --> 02:55:08,010
called the risk aversion parameter.

3022
02:55:08,010 --> 02:55:11,120
You turn it to get different portfolios!

3023
02:55:11,120 --> 02:55:14,805
And if you turn it Very low, if gamma's a
small number, you'll end up

3024
02:55:14,805 --> 02:55:20,950
with something that has very high return,
and probably high risk as well.

3025
02:55:20,950 --> 02:55:22,744
And if gamma gets really big,

3026
02:55:22,744 --> 02:55:26,263
you'll end up in this problem, basically
putting all of your,

3027
02:55:26,263 --> 02:55:32,960
concentrating your portfolio in low-risk
investments, or something like that.

3028
02:55:32,960 --> 02:55:34,350
So these are, this is the idea.
