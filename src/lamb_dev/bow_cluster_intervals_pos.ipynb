{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import datetime\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict, Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FMT = '%H:%M:%S,%f'\n",
    "\n",
    "def srt_to_strs(f, interval_length):\n",
    "    '''Convert a .srt file to a dict of strings'''\n",
    "    \n",
    "    # [(text, start_time, end_time)]\n",
    "    intervals = []\n",
    "    while True:\n",
    "        _seq_no = f.readline().strip()\n",
    "        if _seq_no == '': break\n",
    "        start_str, end_str = f.readline().strip().split(' --> ')\n",
    "        start_time = datetime.datetime.strptime(start_str, FMT)\n",
    "        end_time = datetime.datetime.strptime(end_str, FMT)\n",
    "        \n",
    "        text_lines = []\n",
    "        while True:\n",
    "            text_line = f.readline().strip()\n",
    "            if text_line == '': break\n",
    "            text_line = text_line.replace('&#39;', '')\n",
    "            text_line = text_line.replace('&gt;', '')\n",
    "            text_lines.append(text_line)\n",
    "            \n",
    "        text = ' '.join(text_lines)\n",
    "        intervals.append((text, start_time, end_time))\n",
    "        \n",
    "    _text, interval_start_time, _end_time = intervals[0]\n",
    "    \n",
    "    result = OrderedDict()\n",
    "    lecture_name = os.path.basename(f.name)[:-4]\n",
    "    interval_lines = []\n",
    "    for idx, (text, start_time, end_time) in enumerate(intervals):\n",
    "        interval_lines.append(text)\n",
    "        \n",
    "        if idx == len(intervals) - 1 or end_time - interval_start_time > interval_length:\n",
    "            result[(lecture_name, interval_start_time, end_time)] = ' '.join(interval_lines)\n",
    "            interval_start_time = end_time\n",
    "            interval_lines = []\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SRT_FILE_NAMES = [\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/01-01-introduction-redo-correction.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/01-02-structure-of-a-compiler-final.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/01-03-economy-of-Programming-Languages_19m51s_.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/02-01-cool-overview-final.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/02-02-cool-example-ii-final.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/02-03-cool-example-iii-final-correction.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/03-01-Lexical-Analysis-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/03-02-lexical-analysis-examples-final.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/03-03-A+Regular+Languages.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/03-04-formal-languages.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/03-05-lexical-specifications-final-quizupdate.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/04+02+finite+automata+part+1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/04-01-lexical-specification.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/04-03-regular-expressions-to-nfas-final-quizupdate-correction.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/04-04-nfa-to-dfa-quizupdate.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/04-05-implementing-finite-automata-correction.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-01-introduction-to-parsing.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-02-A+Context+Free+Grammars.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-03-Derivations-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-04-A+Ambiguity.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-01-error-handling.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-02-abstract-syntax-trees.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-03-recursive-descent-parsing.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-04-1-recursive-descent-limitations-04-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-04-recursive-descent-algorithm.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-05-A+Left+Recursion.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-01-Predictive-Parsing-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-02-first-sets.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-03-follow-sets.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-04-ll1-parsing-tables.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-05-Bottom-Up-Parsing-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-06-Shift-Reduce-Parsing-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-01-Handles-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-02-recognizing-handles.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-03-recognizing-viable-prefixes.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-04-valid-items.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-05-slr-parsing.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-06-slr-parsing-example.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-07-slr-improvements.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-08-slr-examples-correction.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-01-introduction-to-semantic-analysis.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-02-scope.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-03-symbol-tables.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-04-types.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-05-A+Type+Checking.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-06-A+Type+Environments.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-07-A+Subtyping.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-08-A+Typing+Methods.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-09-implementing-type-checking.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-01-A+Static+vs.+Dynamic+Typing.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-02-self-type.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-03-A+Self+Type+Operations.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-04-self-type-usage.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-05-A+Self+Type+Checking.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-06-error-recovery.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-01-runtime-organization.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-02-A+Activations.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-03-activation-records.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-04-globals-and-heap.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-05-alignment.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-06-stack-machines.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-01-introduction-to-code-generation.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-02-A+Code+Generation+I.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-03-A+Code+Generation+II.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-04-code-generation-example.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-05-A+Temporaries.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-06-A+Object+Layout.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/13-01-semantics-overview.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/13-02-operational-semantics.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/13-03-cool-semantics-i.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/13-04-A+Cool+Semantics+II.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/14-01-intermediate-code.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/14-02-optimization-overview.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/14-03-local-optimization.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/14-04-peephole-optimization.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/15-02-constant-propagation.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/15-03-analysis-of-loops.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/15-04-orderings.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/15-05-A+Liveness+Analysis.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/16-01-register-allocation.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/16-02-A+Graph+Coloring.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/16-03-A+Spilling.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/16-04-managing-caches.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/17-01-automatic-memory-management.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/17-02-A+Mark+and+Sweep.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/17-03-A+Stop+and+Copy.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/17-04-conservative-collection.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/17-05-A+Reference+Counting.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-01-java.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-02-java-arrays.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-03-java-exceptions.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-04-java-interfaces.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-05-java-coercions.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-06-java-threads.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-07-other-topics.srt\",\n",
    "]\n",
    "\n",
    "documents = OrderedDict()\n",
    "for name in SRT_FILE_NAMES:\n",
    "    with open(name) as f:\n",
    "        documents.update(srt_to_strs(f, datetime.timedelta(minutes=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://www.ranks.nl/stopwords\n",
    "with open('ranks_nl_stop_words_long.txt') as f:\n",
    "    stop_words = [line.strip().replace(\"'\", '') for line in f]\n",
    "# A few added stop words\n",
    "stop_words.extend([\n",
    "        'thing',\n",
    "        'things',\n",
    "        'hello', \n",
    "        'going', \n",
    "        'uh', \n",
    "        'gonna', \n",
    "        'jack', \n",
    "        'will', \n",
    "        'alright',\n",
    "        'cuz',\n",
    "        'a0',\n",
    "        'a1',\n",
    "        'e0',\n",
    "        'e1',\n",
    "        'e2',\n",
    "        'forgot',\n",
    "        'graduate',\n",
    "        'hope',\n",
    "        'r1',\n",
    "        's1',\n",
    "        's2',\n",
    "        't0',\n",
    "        't1',\n",
    "        't2',\n",
    "        'x1',\n",
    "        'a2i',\n",
    "        'en',\n",
    "        'bs',\n",
    "        'idea',\n",
    "        'keep',\n",
    "        'sa'\n",
    "    ])\n",
    "# A few removed stop words\n",
    "stop_words.remove('first')\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    stop_words=stop_words,\n",
    "    ngram_range=(1,4),\n",
    "    max_features=1000,\n",
    "    max_df=30\n",
    ")\n",
    "X = tfidf.fit_transform(documents.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents = [nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(' '.join(documents.values()))]\n",
    "tags = []\n",
    "for sent in sents:\n",
    "    try:\n",
    "        tags.append(nltk.pos_tag(sent))\n",
    "    except UnicodeDecodeError:\n",
    "        pass\n",
    "\n",
    "pos_to_tokens = {}\n",
    "for sent in tags:\n",
    "    for token, pos in sent:\n",
    "        if pos not in pos_to_tokens:\n",
    "            pos_to_tokens[pos] = set([token.lower()])\n",
    "        else:\n",
    "            pos_to_tokens[pos].add(token.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter down to about 300 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'abstract': 3,\n",
      " u'abstract syntax': 4,\n",
      " u'abstract syntax tree': 5,\n",
      " u'allocation': 29,\n",
      " u'allocation pointer': 30,\n",
      " u'alpha beta': 35,\n",
      " u'analysis parsing': 41,\n",
      " u'argument type': 54,\n",
      " u'arrays': 57,\n",
      " u'assembly code': 60,\n",
      " u'assembly language': 61,\n",
      " u'attribute': 71,\n",
      " u'attributes class': 72,\n",
      " u'automata': 73,\n",
      " u'automatic': 74,\n",
      " u'automatic memory': 75,\n",
      " u'basic block': 82,\n",
      " u'beta': 86,\n",
      " u'boolean': 95,\n",
      " u'bottom parsing': 96,\n",
      " u'bound': 97,\n",
      " u'call function': 109,\n",
      " u'calls': 112,\n",
      " u'catch block': 117,\n",
      " u'check type': 121,\n",
      " u'choose': 128,\n",
      " u'class method': 130,\n",
      " u'class names': 131,\n",
      " u'class object': 132,\n",
      " u'class type': 133,\n",
      " u'closure': 138,\n",
      " u'code first': 139,\n",
      " u'code program': 140,\n",
      " u'collection': 145,\n",
      " u'compile time': 155,\n",
      " u'computer': 164,\n",
      " u'concrete': 170,\n",
      " u'consistent': 177,\n",
      " u'constant propagation': 179,\n",
      " u'constants': 180,\n",
      " u'context free': 186,\n",
      " u'context free grammar': 187,\n",
      " u'context free grammars': 188,\n",
      " u'control flow graph': 191,\n",
      " u'cool program': 194,\n",
      " u'cool type': 195,\n",
      " u'copy': 197,\n",
      " u'count object': 201,\n",
      " u'counting': 203,\n",
      " u'data structure': 210,\n",
      " u'data structures': 211,\n",
      " u'depending': 229,\n",
      " u'descent': 234,\n",
      " u'deterministic': 242,\n",
      " u'deterministic automata': 243,\n",
      " u'deterministic automaton': 244,\n",
      " u'deterministic finite': 245,\n",
      " u'deterministic machine': 246,\n",
      " u'dfa state': 247,\n",
      " u'dollar': 261,\n",
      " u'dollar sign': 262,\n",
      " u'dynamic type': 267,\n",
      " u'english': 283,\n",
      " u'entry point': 285,\n",
      " u'epsilon closure': 286,\n",
      " u'epsilon first': 288,\n",
      " u'epsilon move': 289,\n",
      " u'epsilon moves': 290,\n",
      " u'epsilon production': 291,\n",
      " u'evaluate first': 298,\n",
      " u'eventually': 304,\n",
      " u'executing': 310,\n",
      " u'expression type': 323,\n",
      " u'field': 338,\n",
      " u'finite': 344,\n",
      " u'finite automata': 345,\n",
      " u'finite automaton': 346,\n",
      " u'first argument': 347,\n",
      " u'first evaluate': 348,\n",
      " u'first follow': 350,\n",
      " u'first position': 351,\n",
      " u'first production': 352,\n",
      " u'first set': 353,\n",
      " u'first sets': 354,\n",
      " u'first statement': 355,\n",
      " u'first step': 356,\n",
      " u'floating point': 360,\n",
      " u'floating point numbers': 361,\n",
      " u'flow graph': 363,\n",
      " u'follow set': 366,\n",
      " u'follow sets': 367,\n",
      " u'follow subset': 368,\n",
      " u'fortran': 372,\n",
      " u'forwarding pointer': 375,\n",
      " u'frame': 377,\n",
      " u'frame pointer': 378,\n",
      " u'free grammar': 379,\n",
      " u'free grammars': 380,\n",
      " u'free variables': 381,\n",
      " u'function call': 384,\n",
      " u'function called': 385,\n",
      " u'function calls': 386,\n",
      " u'garbage collection': 392,\n",
      " u'garbage collector': 393,\n",
      " u'generate code': 395,\n",
      " u'generated': 396,\n",
      " u'generating code': 398,\n",
      " u'generator': 399,\n",
      " u'grammars': 402,\n",
      " u'increment method': 441,\n",
      " u'inner': 456,\n",
      " u'input follow': 457,\n",
      " u'input pointer': 459,\n",
      " u'input shift': 460,\n",
      " u'input state': 461,\n",
      " u'input string': 462,\n",
      " u'input symbol': 463,\n",
      " u'input transition': 464,\n",
      " u'int times': 465,\n",
      " u'integer object': 466,\n",
      " u'interference': 472,\n",
      " u'interference graph': 473,\n",
      " u'intermediate': 474,\n",
      " u'intermediate code': 475,\n",
      " u'intermediate language': 476,\n",
      " u'internet': 477,\n",
      " u'introduce': 479,\n",
      " u'invoke': 480,\n",
      " u'io': 483,\n",
      " u'item dot': 485,\n",
      " u'kay': 490,\n",
      " u'keywords': 493,\n",
      " u'kuhl': 494,\n",
      " u'l1': 495,\n",
      " u'language machine': 499,\n",
      " u'leave': 507,\n",
      " u'left recursive': 510,\n",
      " u'lexical analysis parsing': 517,\n",
      " u'lexical analyzer': 518,\n",
      " u'lexical specification': 519,\n",
      " u'listed': 523,\n",
      " u'literal': 524,\n",
      " u'long time': 534,\n",
      " u'lr': 540,\n",
      " u'machine code': 543,\n",
      " u'main method': 546,\n",
      " u'management': 549,\n",
      " u'mark': 552,\n",
      " u'mark bit': 553,\n",
      " u'match input': 555,\n",
      " u'memory location': 559,\n",
      " u'memory management': 560,\n",
      " u'method class': 564,\n",
      " u'mips': 568,\n",
      " u'modern': 571,\n",
      " u'modify': 572,\n",
      " u'move method': 574,\n",
      " u'nfa': 582,\n",
      " u'nondeterministic': 586,\n",
      " u'number temporaries': 595,\n",
      " u'object class': 597,\n",
      " u'object oriented': 599,\n",
      " u'object store': 600,\n",
      " u'object type': 601,\n",
      " u'omega': 606,\n",
      " u'operator': 609,\n",
      " u'ordering': 614,\n",
      " u'organization': 615,\n",
      " u'oriented': 616,\n",
      " u'parse input': 627,\n",
      " u'parse tree': 628,\n",
      " u'parsing algorithm': 630,\n",
      " u'parsing automaton': 631,\n",
      " u'parsing error': 632,\n",
      " u'parsing table': 633,\n",
      " u'piece code': 645,\n",
      " u'pl': 647,\n",
      " u'point interface': 650,\n",
      " u'point numbers': 651,\n",
      " u'point program': 652,\n",
      " u'point time': 653,\n",
      " u'pointer points': 654,\n",
      " u'points object': 656,\n",
      " u'prints': 677,\n",
      " u'priority': 678,\n",
      " u'production alpha': 685,\n",
      " u'production dot': 686,\n",
      " u'production first': 687,\n",
      " u'program optimization': 689,\n",
      " u'program point': 690,\n",
      " u'program points': 691,\n",
      " u'project': 696,\n",
      " u'push': 705,\n",
      " u'recursion': 726,\n",
      " u'recursive descent': 727,\n",
      " u'reduce conflict': 730,\n",
      " u'reduce moves': 731,\n",
      " u'reference': 737,\n",
      " u'reference count': 738,\n",
      " u'reference counting': 739,\n",
      " u'reference counts': 740,\n",
      " u'register allocation': 743,\n",
      " u'register interference': 744,\n",
      " u'register interference graph': 745,\n",
      " u'regular languages': 746,\n",
      " u'repeat': 750,\n",
      " u'return address': 761,\n",
      " u'return true': 762,\n",
      " u'return type': 763,\n",
      " u'returns true': 765,\n",
      " u'rows': 773,\n",
      " u'runtime': 775,\n",
      " u'semantic analysis': 784,\n",
      " u'sequence instructions': 790,\n",
      " u'set states': 792,\n",
      " u'set strings': 793,\n",
      " u'shift reduce': 795,\n",
      " u'shift reduce conflict': 796,\n",
      " u'simple example': 804,\n",
      " u'simpler': 805,\n",
      " u'single character': 808,\n",
      " u'slr': 814,\n",
      " u'slr parsing': 815,\n",
      " u'stack pointer': 830,\n",
      " u'start state final': 836,\n",
      " u'started': 838,\n",
      " u'state automaton': 841,\n",
      " u'state dfa': 842,\n",
      " u'state input': 845,\n",
      " u'state shift': 847,\n",
      " u'statement block': 849,\n",
      " u'states nfa': 851,\n",
      " u'static type': 853,\n",
      " u'stock object': 857,\n",
      " u'stream': 862,\n",
      " u'string language': 863,\n",
      " u'strings language': 865,\n",
      " u'subset follow': 874,\n",
      " u'summarize': 881,\n",
      " u'sweep': 885,\n",
      " u'symbol start': 888,\n",
      " u'syntax error': 891,\n",
      " u'syntax semantics': 892,\n",
      " u'syntax tree': 893,\n",
      " u'temporary register': 906,\n",
      " u'token class': 927,\n",
      " u'token classes': 928,\n",
      " u'token input': 929,\n",
      " u'tokens': 930,\n",
      " u'transition function': 934,\n",
      " u'translation': 938,\n",
      " u'type check': 944,\n",
      " u'type checker': 946,\n",
      " u'type class': 947,\n",
      " u'type count': 948,\n",
      " u'type environment': 949,\n",
      " u'type expression': 950,\n",
      " u'type int': 951,\n",
      " u'type method': 952,\n",
      " u'type object': 953,\n",
      " u'type rules': 954,\n",
      " u'type subtype': 955,\n",
      " u'type system': 956,\n",
      " u'type systems': 957,\n",
      " u'types type': 960,\n",
      " u'upper': 971,\n",
      " u'upper bound': 972,\n",
      " u'white': 989,\n",
      " u'white space': 990,\n",
      " u'write regular': 995}\n"
     ]
    }
   ],
   "source": [
    "VALID_TAGS = [\n",
    "    'NNP',\n",
    "    'NNPS',\n",
    "]\n",
    "\n",
    "valid_tokens = set()\n",
    "for pos in VALID_TAGS:\n",
    "    valid_tokens = valid_tokens.union(pos_to_tokens[pos])\n",
    "\n",
    "filtered_vocabulary = {\n",
    "    key: value for key, value in tfidf.vocabulary_.items() \n",
    "    if len(set(key.split()).intersection(valid_tokens)) > 0 and\n",
    "    Counter(key.split()).most_common()[0][1] == 1\n",
    "}\n",
    "pprint(filtered_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookup the minutes where \"abstract syntax tree\" and \"recursive descent\" appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-02-abstract-syntax-trees: 00:00:04,799000 --> 00:01:08,590000',\n",
      " '06-02-abstract-syntax-trees: 00:02:13,450000 --> 00:03:13,690000',\n",
      " '06-02-abstract-syntax-trees: 00:03:13,690000 --> 00:03:48,260000',\n",
      " '09-03-symbol-tables: 00:00:03,530000 --> 00:01:05,950000',\n",
      " '09-03-symbol-tables: 00:01:05,950000 --> 00:02:06,859000',\n",
      " '09-03-symbol-tables: 00:02:06,859000 --> 00:03:07,750000',\n",
      " '09-03-symbol-tables: 00:03:07,750000 --> 00:04:10,299000',\n",
      " '09-03-symbol-tables: 00:04:10,299000 --> 00:05:14,180000',\n",
      " '09-04-types: 00:10:29,520000 --> 00:11:20,920000',\n",
      " '09-09-implementing-type-checking: 00:00:05,150000 --> 00:01:09,830000',\n",
      " '10-06-error-recovery: 00:01:06,900000 --> 00:02:08,060000',\n",
      " '10-06-error-recovery: 00:02:08,060000 --> 00:03:13,680000',\n",
      " '10-06-error-recovery: 00:03:13,680000 --> 00:04:15,739000',\n",
      " '10-06-error-recovery: 00:04:15,739000 --> 00:05:20,139000',\n",
      " '10-06-error-recovery: 00:05:20,139000 --> 00:06:25,000000',\n",
      " '12-02-A+Code+Generation+I: 00:12:28,710000 --> 00:13:34,870000',\n",
      " '14-02-optimization-overview: 00:01:05,360000 --> 00:02:08,509000']\n"
     ]
    }
   ],
   "source": [
    "token_to_docs = OrderedDict()\n",
    "for key, column in filtered_vocabulary.items():\n",
    "    document_indices = [idx for idx, count in enumerate(X[:, column].toarray().flatten()) if count > 0]\n",
    "    token_to_docs[key] = sorted(list(set([documents.keys()[idx] for idx in document_indices])))\n",
    "pprint([\n",
    "        '{}: {} --> {}'.format(\n",
    "            lecture_name, start_time.strftime(FMT), end_time.strftime(FMT)\n",
    "        )\n",
    "        for lecture_name, start_time, end_time in token_to_docs['abstract syntax tree']\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-03-recursive-descent-parsing: 00:00:03,949000 --> 00:01:04,720000',\n",
      " '06-03-recursive-descent-parsing: 00:01:04,720000 --> 00:02:08,110000',\n",
      " '06-04-1-recursive-descent-limitations-04-1: 00:00:00,560000 --> 00:01:05,609000',\n",
      " '06-04-1-recursive-descent-limitations-04-1: 00:04:09,370000 --> 00:05:13,000000',\n",
      " '06-04-1-recursive-descent-limitations-04-1: 00:05:13,000000 --> 00:06:17,830000',\n",
      " '06-04-recursive-descent-algorithm: 00:00:04,150000 --> 00:01:06,760000',\n",
      " '06-04-recursive-descent-algorithm: 00:08:32,039000 --> 00:09:36,120000',\n",
      " '06-04-recursive-descent-algorithm: 00:09:36,120000 --> 00:10:36,890000',\n",
      " '06-05-A+Left+Recursion: 00:00:03,570000 --> 00:01:07,810000',\n",
      " '06-05-A+Left+Recursion: 00:02:08,530000 --> 00:03:11,370000',\n",
      " '06-05-A+Left+Recursion: 00:04:12,380000 --> 00:05:14,970000',\n",
      " '07-01-Predictive-Parsing-Part-1: 00:00:03,780000 --> 00:01:04,059000',\n",
      " '07-01-Predictive-Parsing-Part-1: 00:02:06,979000 --> 00:03:12,010000',\n",
      " '07-05-Bottom-Up-Parsing-Part-1: 00:00:03,860000 --> 00:01:06,079000',\n",
      " '09-03-symbol-tables: 00:00:03,530000 --> 00:01:05,950000',\n",
      " '09-03-symbol-tables: 00:01:05,950000 --> 00:02:06,859000',\n",
      " '09-03-symbol-tables: 00:02:06,859000 --> 00:03:07,750000',\n",
      " '09-03-symbol-tables: 00:03:07,750000 --> 00:04:10,299000',\n",
      " '12-02-A+Code+Generation+I: 00:12:28,710000 --> 00:13:34,870000']\n"
     ]
    }
   ],
   "source": [
    "token_to_docs = OrderedDict()\n",
    "for key, column in filtered_vocabulary.items():\n",
    "    document_indices = [idx for idx, count in enumerate(X[:, column].toarray().flatten()) if count > 0]\n",
    "    token_to_docs[key] = sorted(list(set([documents.keys()[idx] for idx in document_indices])))\n",
    "pprint([\n",
    "        '{}: {} --> {}'.format(\n",
    "            lecture_name, start_time.strftime(FMT), end_time.strftime(FMT)\n",
    "        )\n",
    "        for lecture_name, start_time, end_time in token_to_docs['recursive descent']\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
