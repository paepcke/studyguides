{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import datetime\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict, Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FMT = '%H:%M:%S,%f'\n",
    "\n",
    "def srt_to_strs(f, interval_length):\n",
    "    '''Convert a .srt file to a dict of strings'''\n",
    "    \n",
    "    # [(text, start_time, end_time)]\n",
    "    intervals = []\n",
    "    while True:\n",
    "        _seq_no = f.readline().strip()\n",
    "        if _seq_no == '': break\n",
    "        start_str, end_str = f.readline().strip().split(' --> ')\n",
    "        start_time = datetime.datetime.strptime(start_str, FMT)\n",
    "        end_time = datetime.datetime.strptime(end_str, FMT)\n",
    "        \n",
    "        text_lines = []\n",
    "        while True:\n",
    "            text_line = f.readline().strip()\n",
    "            if text_line == '': break\n",
    "            text_line = text_line.replace('&#39;', '')\n",
    "            text_line = text_line.replace('&gt;', '')\n",
    "            text_lines.append(text_line)\n",
    "            \n",
    "        text = ' '.join(text_lines)\n",
    "        intervals.append((text, start_time, end_time))\n",
    "        \n",
    "    _text, interval_start_time, _end_time = intervals[0]\n",
    "    \n",
    "    result = OrderedDict()\n",
    "    lecture_name = os.path.basename(f.name)[:-4]\n",
    "    interval_lines = []\n",
    "    for idx, (text, start_time, end_time) in enumerate(intervals):\n",
    "        interval_lines.append(text)\n",
    "        \n",
    "        if idx == len(intervals) - 1 or end_time - interval_start_time > interval_length:\n",
    "            result[(lecture_name, interval_start_time, end_time)] = ' '.join(interval_lines)\n",
    "            interval_start_time = end_time\n",
    "            interval_lines = []\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SRT_FILE_NAMES = [\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/01-01-introduction-redo-correction.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/01-02-structure-of-a-compiler-final.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/01-03-economy-of-Programming-Languages_19m51s_.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/02-01-cool-overview-final.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/02-02-cool-example-ii-final.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/02-03-cool-example-iii-final-correction.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/03-01-Lexical-Analysis-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/03-02-lexical-analysis-examples-final.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/03-03-A+Regular+Languages.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/03-04-formal-languages.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/03-05-lexical-specifications-final-quizupdate.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/04+02+finite+automata+part+1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/04-01-lexical-specification.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/04-03-regular-expressions-to-nfas-final-quizupdate-correction.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/04-04-nfa-to-dfa-quizupdate.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/04-05-implementing-finite-automata-correction.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-01-introduction-to-parsing.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-02-A+Context+Free+Grammars.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-03-Derivations-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-04-A+Ambiguity.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-01-error-handling.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-02-abstract-syntax-trees.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-03-recursive-descent-parsing.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-04-1-recursive-descent-limitations-04-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-04-recursive-descent-algorithm.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-05-A+Left+Recursion.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-01-Predictive-Parsing-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-02-first-sets.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-03-follow-sets.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-04-ll1-parsing-tables.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-05-Bottom-Up-Parsing-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-06-Shift-Reduce-Parsing-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-01-Handles-Part-1.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-02-recognizing-handles.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-03-recognizing-viable-prefixes.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-04-valid-items.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-05-slr-parsing.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-06-slr-parsing-example.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-07-slr-improvements.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/08-08-slr-examples-correction.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-01-introduction-to-semantic-analysis.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-02-scope.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-03-symbol-tables.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-04-types.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-05-A+Type+Checking.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-06-A+Type+Environments.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-07-A+Subtyping.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-08-A+Typing+Methods.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/09-09-implementing-type-checking.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-01-A+Static+vs.+Dynamic+Typing.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-02-self-type.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-03-A+Self+Type+Operations.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-04-self-type-usage.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-05-A+Self+Type+Checking.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/10-06-error-recovery.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-01-runtime-organization.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-02-A+Activations.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-03-activation-records.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-04-globals-and-heap.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-05-alignment.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/11-06-stack-machines.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-01-introduction-to-code-generation.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-02-A+Code+Generation+I.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-03-A+Code+Generation+II.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-04-code-generation-example.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-05-A+Temporaries.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/12-06-A+Object+Layout.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/13-01-semantics-overview.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/13-02-operational-semantics.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/13-03-cool-semantics-i.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/13-04-A+Cool+Semantics+II.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/14-01-intermediate-code.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/14-02-optimization-overview.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/14-03-local-optimization.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/14-04-peephole-optimization.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/15-02-constant-propagation.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/15-03-analysis-of-loops.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/15-04-orderings.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/15-05-A+Liveness+Analysis.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/16-01-register-allocation.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/16-02-A+Graph+Coloring.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/16-03-A+Spilling.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/16-04-managing-caches.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/17-01-automatic-memory-management.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/17-02-A+Mark+and+Sweep.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/17-03-A+Stop+and+Copy.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/17-04-conservative-collection.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/17-05-A+Reference+Counting.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-01-java.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-02-java-arrays.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-03-java-exceptions.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-04-java-interfaces.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-05-java-coercions.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-06-java-threads.srt\",\n",
    "    \"/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/18-07-other-topics.srt\",\n",
    "]\n",
    "\n",
    "documents = OrderedDict()\n",
    "for name in SRT_FILE_NAMES:\n",
    "    with open(name) as f:\n",
    "        documents.update(srt_to_strs(f, datetime.timedelta(minutes=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents = [nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(' '.join(documents.values()))]\n",
    "tags = []\n",
    "for sent in sents:\n",
    "    try:\n",
    "        tags.append(nltk.pos_tag(sent))\n",
    "    except UnicodeDecodeError:\n",
    "        pass\n",
    "\n",
    "pos_to_tokens = {}\n",
    "for sent in tags:\n",
    "    for token, pos in sent:\n",
    "        if pos not in pos_to_tokens:\n",
    "            pos_to_tokens[pos] = set([token.lower()])\n",
    "        else:\n",
    "            pos_to_tokens[pos].add(token.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://www.ranks.nl/stopwords\n",
    "with open('ranks_nl_stop_words_long.txt') as f:\n",
    "    stop_words = [line.strip().replace(\"'\", '') for line in f]\n",
    "# A few added stop words\n",
    "stop_words.extend([\n",
    "        'thing',\n",
    "        'things',\n",
    "        'hello', \n",
    "        'going', \n",
    "        'uh', \n",
    "        'gonna', \n",
    "        'jack', \n",
    "        'will', \n",
    "        'alright',\n",
    "        'cuz',\n",
    "        'a0',\n",
    "        'a1',\n",
    "        'e0',\n",
    "        'e1',\n",
    "        'e2',\n",
    "        'forgot',\n",
    "        'graduate',\n",
    "        'hope',\n",
    "        'r1',\n",
    "        's1',\n",
    "        's2',\n",
    "        't0',\n",
    "        't1',\n",
    "        't2',\n",
    "        'x1',\n",
    "        'a2i',\n",
    "        'en',\n",
    "        'bs',\n",
    "        'idea',\n",
    "        'keep',\n",
    "        'sa'\n",
    "    ])\n",
    "# A few removed stop words\n",
    "stop_words.remove('first')\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "lemmatized_docs = OrderedDict()\n",
    "for key, doc in documents.items():\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    lemmatized_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            try:\n",
    "                lemmatized_tokens.append(lemmatizer.lemmatize(token))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    lemmatized_docs[key] = ' '.join(lemmatized_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    stop_words=stop_words,\n",
    "    ngram_range=(1,4),\n",
    "    max_features=1000,\n",
    "    max_df=30\n",
    ")\n",
    "X = tfidf.fit_transform(lemmatized_docs.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter down to about 300 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'abstract syntax tree': 4,\n",
      " u'allocate object': 23,\n",
      " u'allocating object': 26,\n",
      " u'allocation pointer': 28,\n",
      " u'alpha beta': 33,\n",
      " u'argument type': 50,\n",
      " u'assembly code': 57,\n",
      " u'assembly language': 58,\n",
      " u'attribute class': 68,\n",
      " u'automata': 69,\n",
      " u'automatic memory': 71,\n",
      " u'basic block': 78,\n",
      " u'boolean': 90,\n",
      " u'bottom parsing': 91,\n",
      " u'call function': 102,\n",
      " u'call method': 103,\n",
      " u'catch block': 109,\n",
      " u'check type': 111,\n",
      " u'choose': 116,\n",
      " u'class attribute': 117,\n",
      " u'class defined': 119,\n",
      " u'class definition': 120,\n",
      " u'class implement': 121,\n",
      " u'class method': 122,\n",
      " u'class object': 123,\n",
      " u'class type': 124,\n",
      " u'code first': 130,\n",
      " u'code program': 131,\n",
      " u'compile time': 146,\n",
      " u'computer': 155,\n",
      " u'concrete': 161,\n",
      " u'consistent': 168,\n",
      " u'constant folding': 170,\n",
      " u'constant propagation': 171,\n",
      " u'context free grammar': 175,\n",
      " u'control flow graph': 178,\n",
      " u'cool program': 183,\n",
      " u'cool type': 184,\n",
      " u'copy object': 187,\n",
      " u'correct program': 188,\n",
      " u'data structure': 200,\n",
      " u'declared type': 209,\n",
      " u'depending': 217,\n",
      " u'deterministic automaton': 228,\n",
      " u'deterministic finite automaton': 230,\n",
      " u'deterministic machine': 231,\n",
      " u'dfa state': 233,\n",
      " u'dollar sign': 249,\n",
      " u'dynamic type': 254,\n",
      " u'english': 267,\n",
      " u'entry point': 270,\n",
      " u'epsilon closure': 272,\n",
      " u'epsilon first': 274,\n",
      " u'epsilon move': 275,\n",
      " u'epsilon production': 276,\n",
      " u'evaluate first': 281,\n",
      " u'eventually': 287,\n",
      " u'executing': 292,\n",
      " u'expression example': 305,\n",
      " u'expression integer': 307,\n",
      " u'expression language': 309,\n",
      " u'expression type': 310,\n",
      " u'first argument': 330,\n",
      " u'first evaluate': 331,\n",
      " u'first position': 333,\n",
      " u'first production': 334,\n",
      " u'first set': 335,\n",
      " u'first statement': 336,\n",
      " u'first step': 337,\n",
      " u'floating point number': 342,\n",
      " u'follow set': 347,\n",
      " u'follow subset': 348,\n",
      " u'formal language': 352,\n",
      " u'fortran': 354,\n",
      " u'forwarding pointer': 357,\n",
      " u'frame pointer': 360,\n",
      " u'free variable': 362,\n",
      " u'function called': 366,\n",
      " u'garbage collection': 371,\n",
      " u'garbage collector': 372,\n",
      " u'generate code': 374,\n",
      " u'generated': 375,\n",
      " u'generating code': 377,\n",
      " u'generator': 378,\n",
      " u'gon follow': 382,\n",
      " u'gon talk': 383,\n",
      " u'increment method': 419,\n",
      " u'inner loop': 436,\n",
      " u'input follow': 437,\n",
      " u'input pointer': 439,\n",
      " u'input shift': 440,\n",
      " u'input state': 441,\n",
      " u'input string': 442,\n",
      " u'input symbol': 443,\n",
      " u'input transition': 444,\n",
      " u'integer object': 447,\n",
      " u'intermediate code': 455,\n",
      " u'intermediate language': 456,\n",
      " u'internet': 457,\n",
      " u'introduce': 459,\n",
      " u'invoke': 460,\n",
      " u'item dot': 465,\n",
      " u'kay': 471,\n",
      " u'keywords': 474,\n",
      " u'kind type': 476,\n",
      " u'kuhl': 477,\n",
      " u'l1': 478,\n",
      " u'language machine': 482,\n",
      " u'language string': 483,\n",
      " u'leave': 491,\n",
      " u'left recursive': 493,\n",
      " u'lexical analysis parsing': 499,\n",
      " u'lexical analyzer': 500,\n",
      " u'lexical specification': 501,\n",
      " u'life time': 503,\n",
      " u'listed': 507,\n",
      " u'literal': 508,\n",
      " u'local optimization': 516,\n",
      " u'long time': 519,\n",
      " u'machine code': 527,\n",
      " u'main method': 529,\n",
      " u'mark bit': 535,\n",
      " u'match input': 537,\n",
      " u'memory location': 540,\n",
      " u'memory management': 541,\n",
      " u'method call': 545,\n",
      " u'method class': 546,\n",
      " u'method interface': 547,\n",
      " u'method return': 549,\n",
      " u'method signature': 550,\n",
      " u'method type': 551,\n",
      " u'mips': 555,\n",
      " u'modern': 558,\n",
      " u'modify': 559,\n",
      " u'move method': 561,\n",
      " u'move shift': 562,\n",
      " u'nondeterministic': 573,\n",
      " u'number temporary': 582,\n",
      " u'object class': 583,\n",
      " u'object copied': 584,\n",
      " u'object oriented': 586,\n",
      " u'object pointer': 588,\n",
      " u'object reachable': 589,\n",
      " u'object space': 590,\n",
      " u'object store': 591,\n",
      " u'object type': 592,\n",
      " u'object unreachable': 593,\n",
      " u'omega': 599,\n",
      " u'operator': 604,\n",
      " u'ordering': 609,\n",
      " u'organization': 610,\n",
      " u'parse input': 619,\n",
      " u'parse tree': 620,\n",
      " u'parsing algorithm': 621,\n",
      " u'parsing automaton': 622,\n",
      " u'parsing error': 623,\n",
      " u'parsing table': 624,\n",
      " u'piece code': 634,\n",
      " u'pl inaudible': 636,\n",
      " u'point interface': 639,\n",
      " u'point object': 641,\n",
      " u'point program': 642,\n",
      " u'point time': 643,\n",
      " u'pointer move': 644,\n",
      " u'pointer object': 645,\n",
      " u'pointer point': 646,\n",
      " u'prefix input': 660,\n",
      " u'priority': 668,\n",
      " u'production alpha': 673,\n",
      " u'production dot': 674,\n",
      " u'production first': 675,\n",
      " u'production left': 676,\n",
      " u'program compiler': 679,\n",
      " u'program optimization': 680,\n",
      " u'program point': 681,\n",
      " u'project': 684,\n",
      " u'push stack': 693,\n",
      " u'r2': 698,\n",
      " u'recursion': 713,\n",
      " u'recursive descent': 714,\n",
      " u'reduce move': 718,\n",
      " u'reference count object': 725,\n",
      " u'reference counting': 726,\n",
      " u'register allocation': 728,\n",
      " u'register interference graph': 730,\n",
      " u'regular language': 732,\n",
      " u'repeat': 738,\n",
      " u'return address': 749,\n",
      " u'return true': 750,\n",
      " u'return type': 751,\n",
      " u'rule type': 760,\n",
      " u'runtime': 761,\n",
      " u'semantic analysis': 770,\n",
      " u'sequence instruction': 776,\n",
      " u'set state': 778,\n",
      " u'set string': 779,\n",
      " u'set symbol': 780,\n",
      " u'shift move': 782,\n",
      " u'shift reduce conflict': 784,\n",
      " u'simple example': 790,\n",
      " u'simple table': 791,\n",
      " u'simpler': 792,\n",
      " u'single character': 795,\n",
      " u'slr parsing': 799,\n",
      " u'stack frame': 813,\n",
      " u'stack pointer': 815,\n",
      " u'start state final': 820,\n",
      " u'started': 822,\n",
      " u'state automaton': 824,\n",
      " u'state dfa': 825,\n",
      " u'state input': 828,\n",
      " u'state nfa': 831,\n",
      " u'state set': 833,\n",
      " u'state shift': 834,\n",
      " u'state start': 836,\n",
      " u'statement block': 838,\n",
      " u'static type': 842,\n",
      " u'stock object': 846,\n",
      " u'stream': 850,\n",
      " u'string language': 851,\n",
      " u'string token': 853,\n",
      " u'subset follow': 860,\n",
      " u'summarize': 870,\n",
      " u'sweep': 874,\n",
      " u'symbol grammar': 877,\n",
      " u'symbol start': 879,\n",
      " u'syntax error': 882,\n",
      " u'syntax semantics': 883,\n",
      " u'temporary register': 892,\n",
      " u'terminal first': 895,\n",
      " u'terminal input': 896,\n",
      " u'token ahead': 917,\n",
      " u'token class': 918,\n",
      " u'token input': 919,\n",
      " u'transition function': 924,\n",
      " u'translation': 927,\n",
      " u'type argument': 932,\n",
      " u'type checker': 935,\n",
      " u'type class': 936,\n",
      " u'type count': 937,\n",
      " u'type environment': 938,\n",
      " u'type error': 939,\n",
      " u'type expression': 940,\n",
      " u'type int': 941,\n",
      " u'type method': 942,\n",
      " u'type object': 943,\n",
      " u'type return': 944,\n",
      " u'type rule': 945,\n",
      " u'type subtype': 946,\n",
      " u'type system': 947,\n",
      " u'type variable': 949,\n",
      " u'typing rule': 953,\n",
      " u'unreachable object': 960,\n",
      " u'upper bound': 965,\n",
      " u'valid program': 967,\n",
      " u'values': 968,\n",
      " u'variable point': 969,\n",
      " u'variable reference': 970,\n",
      " u'variable type': 971,\n",
      " u'video gon': 979,\n",
      " u'white space': 987,\n",
      " u'write regular expression': 995}\n"
     ]
    }
   ],
   "source": [
    "VALID_TAGS = [\n",
    "    'NNP',\n",
    "    'NNPS',\n",
    "]\n",
    "\n",
    "valid_tokens = set()\n",
    "for pos in VALID_TAGS:\n",
    "    valid_tokens = valid_tokens.union(pos_to_tokens[pos])\n",
    "\n",
    "filtered_vocabulary = {\n",
    "    key: value for key, value in tfidf.vocabulary_.items() \n",
    "    if len(set(key.split()).intersection(valid_tokens)) > 0 and\n",
    "    Counter(key.split()).most_common()[0][1] == 1 and\n",
    "    not any([key in other and key != other for other in filtered_vocabulary])\n",
    "}\n",
    "\n",
    "pprint(filtered_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookup the minutes where \"abstract syntax tree\" and \"recursive descent\" appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-02-abstract-syntax-trees: 00:00:04,799000 --> 00:01:08,590000',\n",
      " '06-02-abstract-syntax-trees: 00:02:13,450000 --> 00:03:13,690000',\n",
      " '06-02-abstract-syntax-trees: 00:03:13,690000 --> 00:03:48,260000',\n",
      " '09-03-symbol-tables: 00:00:03,530000 --> 00:01:05,950000',\n",
      " '09-03-symbol-tables: 00:01:05,950000 --> 00:02:06,859000',\n",
      " '09-03-symbol-tables: 00:02:06,859000 --> 00:03:07,750000',\n",
      " '09-03-symbol-tables: 00:03:07,750000 --> 00:04:10,299000',\n",
      " '09-03-symbol-tables: 00:04:10,299000 --> 00:05:14,180000',\n",
      " '09-04-types: 00:10:29,520000 --> 00:11:20,920000',\n",
      " '09-09-implementing-type-checking: 00:00:05,150000 --> 00:01:09,830000',\n",
      " '10-06-error-recovery: 00:01:06,900000 --> 00:02:08,060000',\n",
      " '10-06-error-recovery: 00:02:08,060000 --> 00:03:13,680000',\n",
      " '10-06-error-recovery: 00:03:13,680000 --> 00:04:15,739000',\n",
      " '10-06-error-recovery: 00:04:15,739000 --> 00:05:20,139000',\n",
      " '10-06-error-recovery: 00:05:20,139000 --> 00:06:25,000000',\n",
      " '12-02-A+Code+Generation+I: 00:12:28,710000 --> 00:13:34,870000',\n",
      " '14-02-optimization-overview: 00:01:05,360000 --> 00:02:08,509000']\n"
     ]
    }
   ],
   "source": [
    "token_to_docs = OrderedDict()\n",
    "for key, column in filtered_vocabulary.items():\n",
    "    document_indices = [idx for idx, count in enumerate(X[:, column].toarray().flatten()) if count > 0]\n",
    "    token_to_docs[key] = sorted(list(set([documents.keys()[idx] for idx in document_indices])))\n",
    "pprint([\n",
    "        '{}: {} --> {}'.format(\n",
    "            lecture_name, start_time.strftime(FMT), end_time.strftime(FMT)\n",
    "        )\n",
    "        for lecture_name, start_time, end_time in token_to_docs['abstract syntax tree']\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-03-recursive-descent-parsing: 00:00:03,949000 --> 00:01:04,720000',\n",
      " '06-03-recursive-descent-parsing: 00:01:04,720000 --> 00:02:08,110000',\n",
      " '06-04-1-recursive-descent-limitations-04-1: 00:00:00,560000 --> 00:01:05,609000',\n",
      " '06-04-1-recursive-descent-limitations-04-1: 00:04:09,370000 --> 00:05:13,000000',\n",
      " '06-04-1-recursive-descent-limitations-04-1: 00:05:13,000000 --> 00:06:17,830000',\n",
      " '06-04-recursive-descent-algorithm: 00:00:04,150000 --> 00:01:06,760000',\n",
      " '06-04-recursive-descent-algorithm: 00:08:32,039000 --> 00:09:36,120000',\n",
      " '06-04-recursive-descent-algorithm: 00:09:36,120000 --> 00:10:36,890000',\n",
      " '06-05-A+Left+Recursion: 00:00:03,570000 --> 00:01:07,810000',\n",
      " '06-05-A+Left+Recursion: 00:02:08,530000 --> 00:03:11,370000',\n",
      " '06-05-A+Left+Recursion: 00:04:12,380000 --> 00:05:14,970000',\n",
      " '07-01-Predictive-Parsing-Part-1: 00:00:03,780000 --> 00:01:04,059000',\n",
      " '07-01-Predictive-Parsing-Part-1: 00:02:06,979000 --> 00:03:12,010000',\n",
      " '07-05-Bottom-Up-Parsing-Part-1: 00:00:03,860000 --> 00:01:06,079000',\n",
      " '09-03-symbol-tables: 00:00:03,530000 --> 00:01:05,950000',\n",
      " '09-03-symbol-tables: 00:01:05,950000 --> 00:02:06,859000',\n",
      " '09-03-symbol-tables: 00:02:06,859000 --> 00:03:07,750000',\n",
      " '09-03-symbol-tables: 00:03:07,750000 --> 00:04:10,299000',\n",
      " '12-02-A+Code+Generation+I: 00:12:28,710000 --> 00:13:34,870000']\n"
     ]
    }
   ],
   "source": [
    "token_to_docs = OrderedDict()\n",
    "for key, column in filtered_vocabulary.items():\n",
    "    document_indices = [idx for idx, count in enumerate(X[:, column].toarray().flatten()) if count > 0]\n",
    "    token_to_docs[key] = sorted(list(set([documents.keys()[idx] for idx in document_indices])))\n",
    "pprint([\n",
    "        '{}: {} --> {}'.format(\n",
    "            lecture_name, start_time.strftime(FMT), end_time.strftime(FMT)\n",
    "        )\n",
    "        for lecture_name, start_time, end_time in token_to_docs['recursive descent']\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
