{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FMT = '%H:%M:%S,%f'\n",
    "\n",
    "def srt_to_strs(f, interval_length):\n",
    "    '''Convert a .srt file to a dict of strings'''\n",
    "    \n",
    "    # [(text, start_time, end_time)]\n",
    "    intervals = []\n",
    "    while True:\n",
    "        _seq_no = f.readline().strip()\n",
    "        if _seq_no == '': break\n",
    "        start_str, end_str = f.readline().strip().split(' --> ')\n",
    "        start_time = datetime.datetime.strptime(start_str, FMT)\n",
    "        end_time = datetime.datetime.strptime(end_str, FMT)\n",
    "        \n",
    "        text_lines = []\n",
    "        while True:\n",
    "            text_line = f.readline().strip()\n",
    "            if text_line == '': break\n",
    "            text_line = text_line.replace('&#39;', \"'\")\n",
    "            text_lines.append(text_line)\n",
    "            \n",
    "        text = ' '.join(text_lines)\n",
    "        intervals.append((text, start_time, end_time))\n",
    "        \n",
    "    _text, interval_start_time, _end_time = intervals[0]\n",
    "    \n",
    "    result = {}\n",
    "    lecture_name = os.path.basename(f.name)[:-4]\n",
    "    interval_lines = []\n",
    "    for idx, (text, start_time, end_time) in enumerate(intervals):\n",
    "        \n",
    "        interval_lines.append(text)\n",
    "        \n",
    "        if idx == len(intervals) - 1 or end_time - interval_start_time > interval_length:\n",
    "            result[(lecture_name, interval_start_time, end_time)] = ' '.join(interval_lines)\n",
    "            interval_start_time = end_time\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SRT_FILE_NAMES = [\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-01-introduction-to-parsing.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-02-A+Context+Free+Grammars.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-03-Derivations-Part-1.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/05-04-A+Ambiguity.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-01-error-handling.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-02-abstract-syntax-trees.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-03-recursive-descent-parsing.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-04-1-recursive-descent-limitations-04-1.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-04-recursive-descent-algorithm.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/06-05-A+Left+Recursion.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-01-Predictive-Parsing-Part-1.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-02-first-sets.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-03-follow-sets.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-04-ll1-parsing-tables.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-05-Bottom-Up-Parsing-Part-1.srt',\n",
    "    '/Users/andrewlamb/Google_Drive/Stanford/CS199/CompilersSelfPacedCS1/07-06-Shift-Reduce-Parsing-Part-1.srt',\n",
    "]\n",
    "\n",
    "documents = OrderedDict()\n",
    "for name in SRT_FILE_NAMES:\n",
    "    with open(name) as f:\n",
    "        documents.update(srt_to_strs(f, datetime.timedelta(minutes=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://www.ranks.nl/stopwords default list\n",
    "with open('ranks_nl_stop_words_long.txt') as f:\n",
    "    stop_words = [line.strip() for line in f]\n",
    "# A few added stop words\n",
    "stop_words.extend([\"alright\", \"going\"])\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words)\n",
    "X = tfidf.fit_transform(documents.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05-01-introduction-to-parsing, 00:00:03,830000 --> 00:02:05,860000\n",
      "[u'finite', u'nested', u'parens', u'languages', u'regular']\n",
      "\n",
      "05-01-introduction-to-parsing, 00:02:05,860000 --> 00:04:05,940000\n",
      "[u'count', u'languages', u'machine', u'state', u'regular']\n",
      "\n",
      "05-01-introduction-to-parsing, 00:04:05,940000 --> 00:05:28,279000\n",
      "[u'count', u'languages', u'machine', u'state', u'regular']\n",
      "\n",
      "05-02-A+Context+Free+Grammars, 00:00:03,879000 --> 00:02:08,539000\n",
      "[u'free', u'invalid', u'valid', u'strings', u'expression']\n",
      "\n",
      "05-02-A+Context+Free+Grammars, 00:02:08,539000 --> 00:04:09,850000\n",
      "[u'strings', u'parentheses', u'balanced', u'context', u'free']\n",
      "\n",
      "05-02-A+Context+Free+Grammars, 00:04:09,850000 --> 00:06:10,580000\n",
      "[u'string', u'context', u'hand', u'free', u'side']\n",
      "\n",
      "05-02-A+Context+Free+Grammars, 00:06:10,580000 --> 00:08:14,509000\n",
      "[u'strings', u'alpha', u'string', u'context', u'free']\n",
      "\n",
      "05-02-A+Context+Free+Grammars, 00:08:14,509000 --> 00:10:17,540000\n",
      "[u'hand', u'strings', u'string', u'context', u'free']\n",
      "\n",
      "05-02-A+Context+Free+Grammars, 00:10:17,540000 --> 00:12:21,720000\n",
      "[u'start', u'string', u'expression', u'context', u'free']\n",
      "\n",
      "05-02-A+Context+Free+Grammars, 00:12:21,720000 --> 00:12:35,560000\n",
      "[u'strings', u'string', u'expression', u'context', u'free']\n",
      "\n",
      "05-03-Derivations-Part-1, 00:00:04,690000 --> 00:02:05,030000\n",
      "[u'yn', u'string', u'applied', u'derivation', u'tree']\n",
      "\n",
      "05-03-Derivations-Part-1, 00:02:05,030000 --> 00:04:06,319000\n",
      "[u'children', u'interior', u'derivation', u'leaves', u'tree']\n",
      "\n",
      "05-03-Derivations-Part-1, 00:04:06,319000 --> 00:06:08,360000\n",
      "[u'leaves', u'replace', u'parse', u'derivation', u'tree']\n",
      "\n",
      "05-03-Derivations-Part-1, 00:06:08,360000 --> 00:07:05,349000\n",
      "[u'replace', u'parse', u'derivation', u'rightmost', u'tree']\n",
      "\n",
      "05-04-A+Ambiguity, 00:00:03,780000 --> 00:02:07,200000\n",
      "[u'identifiers', u've', u'productions', u'parse', u'tree']\n",
      "\n",
      "05-04-A+Ambiguity, 00:02:07,200000 --> 00:03:36,110000\n",
      "[u'ambiguous', u'derivations', u'tree', u'trees', u'parse']\n",
      "\n",
      "06-01-error-handling, 00:00:03,709000 --> 00:02:04,390000\n",
      "[u'lexical', u'valid', u'correct', u'program', u'errors']\n",
      "\n",
      "06-01-error-handling, 00:02:04,390000 --> 00:04:04,980000\n",
      "[u'compiler', u'handling', u'program', u'error', u'errors']\n",
      "\n",
      "06-01-error-handling, 00:04:04,980000 --> 00:06:07,779000\n",
      "[u'panic', u'handling', u'program', u'errors', u'error']\n",
      "\n",
      "06-01-error-handling, 00:06:07,779000 --> 00:08:08,089000\n",
      "[u'panic', u'language', u'program', u'errors', u'error']\n",
      "\n",
      "06-01-error-handling, 00:08:08,089000 --> 00:10:11,900000\n",
      "[u'compiler', u'language', u'errors', u'program', u'error']\n",
      "\n",
      "06-01-error-handling, 00:10:11,900000 --> 00:12:16,580000\n",
      "[u'correction', u'compiler', u'errors', u'program', u'error']\n",
      "\n",
      "06-01-error-handling, 00:12:16,580000 --> 00:13:00,510000\n",
      "[u'correction', u'compiler', u'program', u'errors', u'error']\n",
      "\n",
      "06-02-abstract-syntax-trees, 00:00:04,799000 --> 00:02:07,880000\n",
      "[u'syntax', u'representation', u'parse', u'abstract', u'tree']\n",
      "\n",
      "06-02-abstract-syntax-trees, 00:02:07,880000 --> 00:03:48,260000\n",
      "[u'structure', u'parse', u'syntax', u'abstract', u'tree']\n",
      "\n",
      "06-03-recursive-descent-parsing, 00:00:03,949000 --> 00:02:08,110000\n",
      "[u'parse', u'top', u'order', u'descent', u'tree']\n",
      "\n",
      "06-03-recursive-descent-parsing, 00:02:08,110000 --> 00:04:11,209000\n",
      "[u'order', u'root', u'top', u'parse', u'tree']\n",
      "\n",
      "06-03-recursive-descent-parsing, 00:04:11,209000 --> 00:06:15,270000\n",
      "[u'nth', u'compare', u'parse', u'input', u'tree']\n",
      "\n",
      "06-03-recursive-descent-parsing, 00:06:15,270000 --> 00:06:32,020000\n",
      "[u'nth', u'compare', u'parse', u'input', u'tree']\n",
      "\n",
      "06-04-1-recursive-descent-limitations-04-1, 00:00:00,560000 --> 00:02:05,630000\n",
      "[u'will', u't1', u'int', u'e1', u'return']\n",
      "\n",
      "06-04-1-recursive-descent-limitations-04-1, 00:02:05,630000 --> 00:04:09,370000\n",
      "[u'e1', u'int', u'will', u'true', u'return']\n",
      "\n",
      "06-04-1-recursive-descent-limitations-04-1, 00:04:09,370000 --> 00:06:12,750000\n",
      "[u'production', u'will', u'true', u'int', u'return']\n",
      "\n",
      "06-04-1-recursive-descent-limitations-04-1, 00:06:12,750000 --> 00:06:55,809000\n",
      "[u'production', u'true', u'int', u'will', u'return']\n",
      "\n",
      "06-04-recursive-descent-algorithm, 00:00:04,150000 --> 00:02:06,549000\n",
      "[u'pointed', u'boolean', u'matches', u'type', u'token']\n",
      "\n",
      "06-04-recursive-descent-algorithm, 00:02:06,549000 --> 00:04:07,969000\n",
      "[u'token', u'checks', u'production', u'input', u'function']\n",
      "\n",
      "06-04-recursive-descent-algorithm, 00:04:07,969000 --> 00:06:14,180000\n",
      "[u'production', u'input', u'pointer', u'match', u'function']\n",
      "\n",
      "06-04-recursive-descent-algorithm, 00:06:14,180000 --> 00:08:19,490000\n",
      "[u'match', u'true', u'returns', u'pointer', u'function']\n",
      "\n",
      "06-04-recursive-descent-algorithm, 00:08:19,490000 --> 00:10:20,750000\n",
      "[u'input', u'returns', u'match', u'pointer', u'function']\n",
      "\n",
      "06-04-recursive-descent-algorithm, 00:10:20,750000 --> 00:12:22,760000\n",
      "[u'input', u'e1', u'match', u'function', u'pointer']\n",
      "\n",
      "06-04-recursive-descent-algorithm, 00:12:22,760000 --> 00:13:24,930000\n",
      "[u'e1', u'match', u'input', u'function', u'pointer']\n",
      "\n",
      "06-05-A+Left+Recursion, 00:00:03,570000 --> 00:02:08,530000\n",
      "[u'call', u'infinite', u's1', u'succeed', u'function']\n",
      "\n",
      "06-05-A+Left+Recursion, 00:02:08,530000 --> 00:04:12,380000\n",
      "[u'alphas', u'beta', u'alpha', u'recursive', u'function']\n",
      "\n",
      "06-05-A+Left+Recursion, 00:04:12,380000 --> 00:06:17,300000\n",
      "[u'left', u'recursive', u'alphas', u'beta', u'prime']\n",
      "\n",
      "06-05-A+Left+Recursion, 00:06:17,300000 --> 00:08:02,090000\n",
      "[u'beta', u'alphas', u'left', u'recursion', u'prime']\n",
      "\n",
      "07-01-Predictive-Parsing-Part-1, 00:00:03,780000 --> 00:02:06,979000\n",
      "[u'parser', u'successful', u'lead', u'predictive', u'stands']\n",
      "\n",
      "07-01-Predictive-Parsing-Part-1, 00:02:06,979000 --> 00:04:07,099000\n",
      "[u'leftmost', u'stands', u'production', u'predictive', u'parser']\n",
      "\n",
      "07-01-Predictive-Parsing-Part-1, 00:04:07,099000 --> 00:06:10,319000\n",
      "[u'terminal', u'parser', u'prefix', u'predictive', u'production']\n",
      "\n",
      "07-01-Predictive-Parsing-Part-1, 00:06:10,319000 --> 00:07:36,340000\n",
      "[u'predictive', u'suffixes', u'prefix', u'productions', u'production']\n",
      "\n",
      "07-02-first-sets, 00:00:03,689000 --> 00:02:07,370000\n",
      "[u'tables', u'conditions', u'position', u'move', u'alpha']\n",
      "\n",
      "07-02-first-sets, 00:02:07,370000 --> 00:04:10,610000\n",
      "[u'moves', u'derive', u'input', u'situation', u'alpha']\n",
      "\n",
      "07-02-first-sets, 00:04:10,610000 --> 00:06:13,030000\n",
      "[u'conditions', u'derive', u'situation', u'epsilon', u'alpha']\n",
      "\n",
      "07-02-first-sets, 00:06:13,030000 --> 00:08:16,009000\n",
      "[u'symbol', u'produce', u'terminal', u'alpha', u'epsilon']\n",
      "\n",
      "07-02-first-sets, 00:08:16,009000 --> 00:10:16,240000\n",
      "[u'terminals', u'compute', u'terminal', u'epsilon', u'alpha']\n",
      "\n",
      "07-02-first-sets, 00:10:16,240000 --> 00:12:20,740000\n",
      "[u'compute', u'terminals', u'terminal', u'epsilon', u'alpha']\n",
      "\n",
      "07-02-first-sets, 00:12:20,740000 --> 00:14:00,149000\n",
      "[u'terminals', u'sets', u'terminal', u'alpha', u'epsilon']\n",
      "\n",
      "07-03-follow-sets, 00:00:03,620000 --> 00:02:06,110000\n",
      "[u'clearly', u'appear', u'sets', u'symbol', u'follow']\n",
      "\n",
      "07-03-follow-sets, 00:02:06,110000 --> 00:04:07,939000\n",
      "[u'set', u'production', u'start', u'symbol', u'follow']\n",
      "\n",
      "07-03-follow-sets, 00:04:07,939000 --> 00:06:09,639000\n",
      "[u'epsilon', u'beta', u'production', u'symbol', u'follow']\n",
      "\n",
      "07-03-follow-sets, 00:06:09,639000 --> 00:08:10,599000\n",
      "[u'beta', u'production', u'sets', u'symbol', u'follow']\n",
      "\n",
      "07-03-follow-sets, 00:08:10,599000 --> 00:10:15,320000\n",
      "[u'production', u'epsilon', u'sets', u'symbol', u'follow']\n",
      "\n",
      "07-03-follow-sets, 00:10:15,320000 --> 00:12:15,649000\n",
      "[u'production', u'symbol', u'subset', u'sets', u'follow']\n",
      "\n",
      "07-03-follow-sets, 00:12:15,649000 --> 00:14:16,069000\n",
      "[u'production', u'symbol', u'subset', u'sets', u'follow']\n",
      "\n",
      "07-03-follow-sets, 00:14:16,069000 --> 00:16:16,199000\n",
      "[u'subset', u'epsilon', u'symbol', u'sets', u'follow']\n",
      "\n",
      "07-03-follow-sets, 00:16:16,199000 --> 00:17:03,040000\n",
      "[u'subset', u'symbol', u'epsilon', u'sets', u'follow']\n",
      "\n",
      "07-04-ll1-parsing-tables, 00:00:03,889000 --> 00:02:05,229000\n",
      "[u'terminal', u'dollar', u'table', u'situation', u'alpha']\n",
      "\n",
      "07-04-ll1-parsing-tables, 00:02:05,229000 --> 00:04:08,769000\n",
      "[u'leftmost', u'epsilon', u'production', u'table', u'alpha']\n",
      "\n",
      "07-04-ll1-parsing-tables, 00:04:08,769000 --> 00:06:11,870000\n",
      "[u'paren', u'table', u'epsilon', u'production', u'alpha']\n",
      "\n",
      "07-04-ll1-parsing-tables, 00:06:11,870000 --> 00:08:12,180000\n",
      "[u'paren', u'alpha', u'production', u'epsilon', u'follow']\n",
      "\n",
      "07-04-ll1-parsing-tables, 00:08:12,180000 --> 00:10:13,070000\n",
      "[u'alpha', u'production', u'table', u'epsilon', u'follow']\n",
      "\n",
      "07-04-ll1-parsing-tables, 00:10:13,070000 --> 00:12:15,150000\n",
      "[u'production', u'entry', u'epsilon', u'table', u'follow']\n",
      "\n",
      "07-04-ll1-parsing-tables, 00:12:15,150000 --> 00:14:16,630000\n",
      "[u'production', u'entry', u'epsilon', u'follow', u'table']\n",
      "\n",
      "07-04-ll1-parsing-tables, 00:14:16,630000 --> 00:14:38,259000\n",
      "[u'production', u'entry', u'epsilon', u'follow', u'table']\n",
      "\n",
      "07-05-Bottom-Up-Parsing-Part-1, 00:00:03,860000 --> 00:02:08,189000\n",
      "[u'int', u'backwards', u'parsing', u'began', u'bottom']\n",
      "\n",
      "07-05-Bottom-Up-Parsing-Part-1, 00:02:08,189000 --> 00:04:09,790000\n",
      "[u'string', u'began', u'rightmost', u'backwards', u'bottom']\n",
      "\n",
      "07-05-Bottom-Up-Parsing-Part-1, 00:04:09,790000 --> 00:06:10,639000\n",
      "[u'string', u'int', u'rightmost', u'reductions', u'bottom']\n",
      "\n",
      "07-05-Bottom-Up-Parsing-Part-1, 00:06:10,639000 --> 00:07:04,080000\n",
      "[u'tree', u'rightmost', u'int', u'reductions', u'bottom']\n",
      "\n",
      "07-06-Shift-Reduce-Parsing-Part-1, 00:00:03,740000 --> 00:02:06,670000\n",
      "[u'bar', u'rightmost', u'omega', u'bottom', u'innervations']\n",
      "\n",
      "07-06-Shift-Reduce-Parsing-Part-1, 00:02:06,670000 --> 00:04:08,470000\n",
      "[u'moves', u'reduce', u'shift', u'bar', u'vertical']\n",
      "\n",
      "07-06-Shift-Reduce-Parsing-Part-1, 00:04:08,470000 --> 00:05:37,569000\n",
      "[u'moves', u'bar', u'vertical', u'shift', u'reduce']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_voc = {v: k for k, v in tfidf.vocabulary_.items()}\n",
    "most_common_terms = {}\n",
    "\n",
    "for idx, key in enumerate(documents.keys()):\n",
    "    row = X[idx,:].toarray().flatten()\n",
    "    max_indices = row.argsort()[-5:]\n",
    "    most_common_terms[key] = [inverse_voc[voc_idx] for voc_idx in max_indices]\n",
    "\n",
    "for key, terms in sorted(\n",
    "    most_common_terms.items(), \n",
    "    key=lambda ((lecture_name, start_time, _end_time), term): (lecture_name, start_time)\n",
    "):\n",
    "    lecture_name, start_time, end_time = key\n",
    "    print '{}, {} --> {}'.format(\n",
    "        lecture_name, start_time.strftime(FMT), end_time.strftime(FMT)\n",
    "    )\n",
    "    pprint(terms)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10)\n",
    "\n",
    "clusters = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-04-1-recursive-descent-limitations-04-1, 00:00:00,560000 --> 00:02:05,630000',\n",
      " '06-04-1-recursive-descent-limitations-04-1, 00:02:05,630000 --> 00:04:09,370000',\n",
      " '06-04-1-recursive-descent-limitations-04-1, 00:04:09,370000 --> 00:06:12,750000',\n",
      " '06-04-1-recursive-descent-limitations-04-1, 00:06:12,750000 --> 00:06:55,809000',\n",
      " '06-04-recursive-descent-algorithm, 00:00:04,150000 --> 00:02:06,549000',\n",
      " '06-04-recursive-descent-algorithm, 00:02:06,549000 --> 00:04:07,969000',\n",
      " '06-04-recursive-descent-algorithm, 00:04:07,969000 --> 00:06:14,180000',\n",
      " '06-04-recursive-descent-algorithm, 00:06:14,180000 --> 00:08:19,490000',\n",
      " '06-04-recursive-descent-algorithm, 00:08:19,490000 --> 00:10:20,750000',\n",
      " '06-04-recursive-descent-algorithm, 00:10:20,750000 --> 00:12:22,760000',\n",
      " '06-04-recursive-descent-algorithm, 00:12:22,760000 --> 00:13:24,930000',\n",
      " '06-05-A+Left+Recursion, 00:00:03,570000 --> 00:02:08,530000',\n",
      " '06-05-A+Left+Recursion, 00:02:08,530000 --> 00:04:12,380000']\n",
      "\n",
      "['07-03-follow-sets, 00:00:03,620000 --> 00:02:06,110000',\n",
      " '07-03-follow-sets, 00:02:06,110000 --> 00:04:07,939000',\n",
      " '07-03-follow-sets, 00:04:07,939000 --> 00:06:09,639000',\n",
      " '07-03-follow-sets, 00:06:09,639000 --> 00:08:10,599000',\n",
      " '07-03-follow-sets, 00:08:10,599000 --> 00:10:15,320000',\n",
      " '07-03-follow-sets, 00:10:15,320000 --> 00:12:15,649000',\n",
      " '07-03-follow-sets, 00:12:15,649000 --> 00:14:16,069000',\n",
      " '07-03-follow-sets, 00:14:16,069000 --> 00:16:16,199000',\n",
      " '07-03-follow-sets, 00:16:16,199000 --> 00:17:03,040000']\n",
      "\n",
      "['05-03-Derivations-Part-1, 00:00:04,690000 --> 00:02:05,030000',\n",
      " '05-03-Derivations-Part-1, 00:02:05,030000 --> 00:04:06,319000',\n",
      " '05-03-Derivations-Part-1, 00:04:06,319000 --> 00:06:08,360000',\n",
      " '05-03-Derivations-Part-1, 00:06:08,360000 --> 00:07:05,349000',\n",
      " '05-04-A+Ambiguity, 00:00:03,780000 --> 00:02:07,200000',\n",
      " '05-04-A+Ambiguity, 00:02:07,200000 --> 00:03:36,110000',\n",
      " '06-02-abstract-syntax-trees, 00:00:04,799000 --> 00:02:07,880000',\n",
      " '06-02-abstract-syntax-trees, 00:02:07,880000 --> 00:03:48,260000',\n",
      " '06-03-recursive-descent-parsing, 00:00:03,949000 --> 00:02:08,110000',\n",
      " '06-03-recursive-descent-parsing, 00:02:08,110000 --> 00:04:11,209000',\n",
      " '06-03-recursive-descent-parsing, 00:04:11,209000 --> 00:06:15,270000',\n",
      " '06-03-recursive-descent-parsing, 00:06:15,270000 --> 00:06:32,020000']\n",
      "\n",
      "['06-01-error-handling, 00:00:03,709000 --> 00:02:04,390000',\n",
      " '06-01-error-handling, 00:02:04,390000 --> 00:04:04,980000',\n",
      " '06-01-error-handling, 00:04:04,980000 --> 00:06:07,779000',\n",
      " '06-01-error-handling, 00:06:07,779000 --> 00:08:08,089000',\n",
      " '06-01-error-handling, 00:08:08,089000 --> 00:10:11,900000',\n",
      " '06-01-error-handling, 00:10:11,900000 --> 00:12:16,580000',\n",
      " '06-01-error-handling, 00:12:16,580000 --> 00:13:00,510000']\n",
      "\n",
      "['07-04-ll1-parsing-tables, 00:00:03,889000 --> 00:02:05,229000',\n",
      " '07-04-ll1-parsing-tables, 00:02:05,229000 --> 00:04:08,769000',\n",
      " '07-04-ll1-parsing-tables, 00:04:08,769000 --> 00:06:11,870000',\n",
      " '07-04-ll1-parsing-tables, 00:06:11,870000 --> 00:08:12,180000',\n",
      " '07-04-ll1-parsing-tables, 00:08:12,180000 --> 00:10:13,070000',\n",
      " '07-04-ll1-parsing-tables, 00:10:13,070000 --> 00:12:15,150000',\n",
      " '07-04-ll1-parsing-tables, 00:12:15,150000 --> 00:14:16,630000',\n",
      " '07-04-ll1-parsing-tables, 00:14:16,630000 --> 00:14:38,259000']\n",
      "\n",
      "['05-02-A+Context+Free+Grammars, 00:00:03,879000 --> 00:02:08,539000',\n",
      " '05-02-A+Context+Free+Grammars, 00:02:08,539000 --> 00:04:09,850000',\n",
      " '05-02-A+Context+Free+Grammars, 00:04:09,850000 --> 00:06:10,580000',\n",
      " '05-02-A+Context+Free+Grammars, 00:06:10,580000 --> 00:08:14,509000',\n",
      " '05-02-A+Context+Free+Grammars, 00:08:14,509000 --> 00:10:17,540000',\n",
      " '05-02-A+Context+Free+Grammars, 00:10:17,540000 --> 00:12:21,720000',\n",
      " '05-02-A+Context+Free+Grammars, 00:12:21,720000 --> 00:12:35,560000']\n",
      "\n",
      "['05-01-introduction-to-parsing, 00:00:03,830000 --> 00:02:05,860000',\n",
      " '05-01-introduction-to-parsing, 00:02:05,860000 --> 00:04:05,940000',\n",
      " '05-01-introduction-to-parsing, 00:04:05,940000 --> 00:05:28,279000']\n",
      "\n",
      "['06-05-A+Left+Recursion, 00:04:12,380000 --> 00:06:17,300000',\n",
      " '06-05-A+Left+Recursion, 00:06:17,300000 --> 00:08:02,090000',\n",
      " '07-02-first-sets, 00:00:03,689000 --> 00:02:07,370000',\n",
      " '07-02-first-sets, 00:02:07,370000 --> 00:04:10,610000',\n",
      " '07-02-first-sets, 00:04:10,610000 --> 00:06:13,030000',\n",
      " '07-02-first-sets, 00:06:13,030000 --> 00:08:16,009000',\n",
      " '07-02-first-sets, 00:08:16,009000 --> 00:10:16,240000',\n",
      " '07-02-first-sets, 00:10:16,240000 --> 00:12:20,740000',\n",
      " '07-02-first-sets, 00:12:20,740000 --> 00:14:00,149000']\n",
      "\n",
      "['07-05-Bottom-Up-Parsing-Part-1, 00:00:03,860000 --> 00:02:08,189000',\n",
      " '07-05-Bottom-Up-Parsing-Part-1, 00:02:08,189000 --> 00:04:09,790000',\n",
      " '07-05-Bottom-Up-Parsing-Part-1, 00:04:09,790000 --> 00:06:10,639000',\n",
      " '07-05-Bottom-Up-Parsing-Part-1, 00:06:10,639000 --> 00:07:04,080000',\n",
      " '07-06-Shift-Reduce-Parsing-Part-1, 00:00:03,740000 --> 00:02:06,670000',\n",
      " '07-06-Shift-Reduce-Parsing-Part-1, 00:02:06,670000 --> 00:04:08,470000',\n",
      " '07-06-Shift-Reduce-Parsing-Part-1, 00:04:08,470000 --> 00:05:37,569000']\n",
      "\n",
      "['07-01-Predictive-Parsing-Part-1, 00:00:03,780000 --> 00:02:06,979000',\n",
      " '07-01-Predictive-Parsing-Part-1, 00:02:06,979000 --> 00:04:07,099000',\n",
      " '07-01-Predictive-Parsing-Part-1, 00:04:07,099000 --> 00:06:10,319000',\n",
      " '07-01-Predictive-Parsing-Part-1, 00:06:10,319000 --> 00:07:36,340000']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_assignments = {}\n",
    "for idx, cluster_assignment in enumerate(clusters):\n",
    "    if cluster_assignment not in cluster_assignments:\n",
    "        cluster_assignments[cluster_assignment] = [documents.keys()[idx]]\n",
    "    else:\n",
    "        cluster_assignments[cluster_assignment].append(documents.keys()[idx])\n",
    "\n",
    "new_assignments = {}\n",
    "        \n",
    "for idx, keys in cluster_assignments.items():\n",
    "    new_keys = sorted(keys, key=lambda (lecture_name, start_time, _end_time): (lecture_name, start_time))\n",
    "    new_keys = [\n",
    "        '{}, {} --> {}'.format(lecture_name, start_time.strftime(FMT), end_time.strftime(FMT)) \n",
    "        for lecture_name, start_time, end_time in new_keys\n",
    "    ]\n",
    "    new_assignments[idx] = new_keys\n",
    "\n",
    "for cluster in new_assignments.values():\n",
    "    pprint(cluster)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
